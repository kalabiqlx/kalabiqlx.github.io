<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>HUI</title><meta name="author" content="HUI"><meta name="copyright" content="HUI"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="HUI">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="HUI">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/87788970_p0_master1200.jpg">
<meta property="article:author" content="HUI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/87788970_p0_master1200.jpg"><link rel="shortcut icon" href="/img/122061154_p0_master1200.jpg"><link rel="canonical" href="http://example.com/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'HUI',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2024-12-10 20:51:22'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/bronya.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (false) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/87788970_p0_master1200.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">58</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 時間軸</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 標籤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分類</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清單</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音樂</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 電影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友鏈</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 關於</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/121764304_p0.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="HUI"><img class="site-icon" src="/img/319E33068A7ED73BAE7EB48FCE321DD4.jpg"/><span class="site-name">HUI</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 時間軸</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 標籤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分類</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清單</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音樂</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 電影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友鏈</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 關於</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">HUI</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/kalabiqlx" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:kalabiqlx@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2024/12/10/Multimodel/MM-LLMs-survey/" title="MM-LLMs综述(腾讯)"><img class="post-bg" src="/img/image-20241114140927375.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MM-LLMs综述(腾讯)"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/12/10/Multimodel/MM-LLMs-survey/" title="MM-LLMs综述(腾讯)">MM-LLMs综述(腾讯)</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-12-10T12:40:00.000Z" title="发表于 2024-12-10 20:40:00">2024-12-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%B3%BB%E5%88%97/">多模态系列</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2024/12/10/Multimodel/MM-LLMs-survey/#post-comment"><span class="valine-comment-count" data-xid="/2024/12/10/Multimodel/MM-LLMs-survey/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">https://arxiv.org/pdf/2401.13601
 MM-LLMs综述
 摘要

首先，我们概述了模型架构和训练流程的通用设计形式。
随后，我们引入了涵盖126个MM-LLMs的分类体系，每个模型都具有特定的结构。
接着，我们评估了选定MM-LLMs在主流基准上的表现，并总结了关键的训练方法，以提升MM-LLMs的效能。
最后，我们探讨了MM-LLMs的未来发展方向，并维持一个实时跟踪网站，以监控该领域的最新进展

 1. 引言
随着模型和数据集规模的扩展，传统的多模态模型在训练过程中产生了巨大的计算成本，尤其是当采用大规模的模型和数据集进行端到端训练时。认识到多模态研究是在各种模态的交叉点上进行的，一种合理的方法是利用现成的预训练单模态基础模型，特别强调强大的大型语言模型 (LLM)。从而催生了MM-LLM这一领域的出现。
LLMs 具备强大的语言生成、零样本迁移和上下文学习（ICL）等优势。
鉴于不同模态的基础模型是分别预训练的，MM-LLMs 面临的核心挑战在于如何有效地将 LLMs 与其他模态的模型连接，以实现协同推理。该领域的主要研究重点在于通过多模态预训练（ ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/12/10/Multimodel/BiRD/" title="MICCAI2024(2)-BIRD"><img class="post-bg" src="/img/image-20241104164541942.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MICCAI2024(2)-BIRD"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/12/10/Multimodel/BiRD/" title="MICCAI2024(2)-BIRD">MICCAI2024(2)-BIRD</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-12-10T12:36:38.000Z" title="发表于 2024-12-10 20:36:38">2024-12-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%8C%BB%E5%AD%A6%E5%A4%9A%E6%A8%A1%E6%80%81/">医学多模态</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2024/12/10/Multimodel/BiRD/#post-comment"><span class="valine-comment-count" data-xid="/2024/12/10/Multimodel/BiRD/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">论文地址：https://papers.miccai.org/miccai-2024/paper/1279_paper.pdf
代码地址：https://github.com/ShawnHuang497/BiRD
 BiRD
 摘要与引言
生物医学领域的语言和文本不同于自然语言与自然文本，导致常规的视觉助手在生物医学领域表现不佳。这些助手要么无法回答生物医学问题，要么更糟糕的是，提供不准确的回答或完全虚构的信息。
目前生物医学领域的MMLM研究主要集中于图像描述和VQA，在“refer”和“ground”能力方面仍存在显著的缺失，如图1所示：

“refer”要求模型能够准确地理解特定区域的语义内容
“ground”则需要模型根据提供的语义描述对区域进行定位


图 1：BiRD 为生物医学中的多模式大语言模型提供了复杂的refer和ground功能
这些细粒度的多模态能力对于智能生物医学助手与患者之间的交互过程和生物医学教育至关重要。这项能力不仅使信息交换过程更加直观，还显著提高了信息交换的准确性和效率。在生物医学领域缺乏多模态细粒度交互数据集是阻碍这一能力发展的主要因素。
基于此， ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/12/10/Multimodel/LLaVA-V1.5/" title="LLaVA(2)-Improved Baselines with Visual Instruction Tuning"><img class="post-bg" src="/img/image-20241123214150206.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LLaVA(2)-Improved Baselines with Visual Instruction Tuning"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/12/10/Multimodel/LLaVA-V1.5/" title="LLaVA(2)-Improved Baselines with Visual Instruction Tuning">LLaVA(2)-Improved Baselines with Visual Instruction Tuning</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-12-10T12:30:38.000Z" title="发表于 2024-12-10 20:30:38">2024-12-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%B3%BB%E5%88%97/">多模态系列</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2024/12/10/Multimodel/LLaVA-V1.5/#post-comment"><span class="valine-comment-count" data-xid="/2024/12/10/Multimodel/LLaVA-V1.5/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">论文地址：https://arxiv.org/abs/2310.03744
论文代码：https://github.com/haotian-liu/LLaVA
 LLaVA-Improved Baselines with Visual Instruction Tuning(V1.5)
 摘要
本文在LLaVA框架下，首次系统地研究了多模态模型的设计选择，研究是在受控条件下进行的。研究表明，LLaVA中的全连接视觉-语言连接器具有出色的性能和数据效率。在此基础上，通过以下简单改进建立了更强的基准模型：

使用CLIP-ViT-L-336px作为视觉编码器，并配备MLP投影层；
添加面向学术任务的VQA数据集，并优化响应格式提示。

改进后的模型在11项基准测试中达到了最新的性能水平。最终的13B模型仅使用了120万公开数据，在单台8卡A100机器上约1天即可完成训练。此外，我们还在多模态模型的一些开放性问题上进行了初步探索，包括更高分辨率输入的扩展、组合能力以及模型幻觉等问题。
 1. 引言
大规模多模态模型（LMMs）在研究领域中变得越来越流行，因为它们是通用型助手的关键构建模块。最近 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/12/10/Multimodel/LLaVA/" title="LLaVA(1)-Visual Instruction Tuning"><img class="post-bg" src="/img/image-20241122154508143.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LLaVA(1)-Visual Instruction Tuning"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/12/10/Multimodel/LLaVA/" title="LLaVA(1)-Visual Instruction Tuning">LLaVA(1)-Visual Instruction Tuning</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-12-10T12:25:38.000Z" title="发表于 2024-12-10 20:25:38">2024-12-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%B3%BB%E5%88%97/">多模态系列</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2024/12/10/Multimodel/LLaVA/#post-comment"><span class="valine-comment-count" data-xid="/2024/12/10/Multimodel/LLaVA/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">论文 Paper: https://arxiv.org/abs/2304.08485
代码 GitHub: https://github.com/haotian-liu/LLaVA
参考：
https://zhuanlan.zhihu.com/p/622907299
https://hackmd.io/@YungHuiHsu/HyMgBbjSa#Multimodal-LLaVA鍊成術-視覺指令調節-Visual-Instruction-Tuning
 LLaVA-Visual Instruction Tuning
 摘要
使用机器生成的Instruction followling数据对大规模语言模型（LLM）进行指令调优，已经证明可以提高它们在新任务上的zero-shot能力，但这一思想在多模态领域的探索较少。
本文首次尝试使用仅支持语言的GPT-4生成多模态语言-图像Instruction followling数据。通过对这些生成的数据进行指令调优，我们提出了LLaVA：大型语言和视觉助手，这是一个端到端训练的大型多模态模型，结合了视觉编码器和LLM，旨在进行通用的视觉和语言理解。
 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/12/10/Multimodel/PMC-CLIP/" title="MICCAI2024(1)-PMC-CLIP"><img class="post-bg" src="/img/image-20241111141331709.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MICCAI2024(1)-PMC-CLIP"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/12/10/Multimodel/PMC-CLIP/" title="MICCAI2024(1)-PMC-CLIP">MICCAI2024(1)-PMC-CLIP</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-12-10T12:12:38.000Z" title="发表于 2024-12-10 20:12:38">2024-12-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%8C%BB%E5%AD%A6%E5%A4%9A%E6%A8%A1%E6%80%81/">医学多模态</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2024/12/10/Multimodel/PMC-CLIP/#post-comment"><span class="valine-comment-count" data-xid="/2024/12/10/Multimodel/PMC-CLIP/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">论文地址：https://arxiv.org/abs/2303.07240
论文代码：https://github.com/WeixiongLin/PMC-CLIP/
 PMC-CLIP(MICCAI 2024)
 摘要

PMC-OA，一个包含160万图像-描述对的生物医学数据集，数据来自PubMed Central的开放获取子集，规模是之前数据集的8倍。PMC-OA涵盖了多种模式和疾病，绝大多数图像-描述对在更细的层级（如子图和子标题）上对齐。
在PMC-OA上预训练的CLIP风格模型PMC-CLIP，在多个下游任务上实现了当前最优的表现，包括ROCO上的图像-文本检索、MedMNIST图像分类和医学问答（VQA），例如，在图像-文本检索任务中R@10提升了8.1%，在图像分类任务中的准确率提升了3.9%。

 1 引言
生物医学领域在基础模型方面的进展相对缓慢，原因有二：

需要专家标注的专业性要求
数据隐私的限制

因此本文提出了使用公开科学论文来构建一个大规模、高质量的生物医学图像-文本数据集的初步研究，且仅需极少的手动操作。
我们从PubMed Central（美国国立卫生 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/10/28/LLM/MoE/" title="大模型系列(三)- MoE:混合专家模型"><img class="post-bg" src="/img/image-20241028124915950.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大模型系列(三)- MoE:混合专家模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/10/28/LLM/MoE/" title="大模型系列(三)- MoE:混合专家模型">大模型系列(三)- MoE:混合专家模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-10-28T05:31:38.000Z" title="发表于 2024-10-28 13:31:38">2024-10-28</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LLM/">LLM</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2024/10/28/LLM/MoE/#post-comment"><span class="valine-comment-count" data-xid="/2024/10/28/LLM/MoE/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">DeepSeed提出的Moe原论文：2006.16668
参考:图解大模型训练系列之：DeepSpeed-Megatron MoE并行训练（原理篇） - 知乎
混合专家模型 (MoE) 详解 - 知乎
 大模型系列(三)- MoE:混合专家模型
 1. 什么是MoE
MoE(Mixers of Experts)混合专家模型的理念起源于1991年的论文**Adaptive Mixture of Local Experts**。这里不做介绍，仅讨论现代LLM中的MoE.

Switch Transformer 论文中的 MoE Layer

GShard 论文中的 MoE Transformer Encoder
 1.1 MoE原理
原理:将输入通过门控Gate分配给适合处理这类输入的&quot;专家&quot;Experts，而不是把输入交给所有的&quot;专家&quot;Experts进行处理。通过这种方式减小计算量，在有限的计算资源预算下，用更少的训练步数训练一个更大的模型。(只是简单概述，细节后面会讨论)。
优势:

与稠密模型相比， 预训练速度更快
与具有相同参数数量的模型相比 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/10/23/LLM/RLHF/" title="大模型系列(二)- RLHF:基于人类反馈的强化学习"><img class="post-bg" src="/img/image-20241023152702443.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大模型系列(二)- RLHF:基于人类反馈的强化学习"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/10/23/LLM/RLHF/" title="大模型系列(二)- RLHF:基于人类反馈的强化学习">大模型系列(二)- RLHF:基于人类反馈的强化学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-10-23T05:31:38.000Z" title="发表于 2024-10-23 13:31:38">2024-10-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LLM/">LLM</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2024/10/23/LLM/RLHF/#post-comment"><span class="valine-comment-count" data-xid="/2024/10/23/LLM/RLHF/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">参考:图解大模型RLHF系列之：人人都能看懂的PPO原理与源码解读 - 知乎
 大模型系列(二)- RLHF:基于人类反馈的强化学习
Reinforcement Learning from Human Feedback
RLHF有人说提升很大，也有人说效果不明显，究其根本还是系统链路太长自由度太高，不像SFT一样可以通过数据配比、prompt、有限的超参数来可控地调整效果。
也正是因为它的自由度、以目标为导向的学习范式和性价比更高的标注成本，业内往往认为它的上限更高。认为scalable的RLHF（不局限于PPO）就是下一步的大突破所在。
大语言模型的RLHF，实际上是模型先试错再学习的过程。 我们扮演着老师的角色，给出有趣的问题，而模型则会像小学生一样，不断尝试给出答案。模型会对着黑板写下它的答案，有时候是正确的，有时候会有错误。我们会仔细检查每一个答案，如果它表现得好，就会给予它高声赞扬；如果它表现不佳，我们则会给予它耐心的指导和反馈，帮助它不断改进，直到达到令人满意的水平。
 1. RLHF介绍
 1.1 强化学习整体流程

强化学习的两个实体：智能体（Agent）与环境（Env ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/10/22/Multimodel/multimodel_summerize/" title="多模态系列(七)- 总结"><div class="post-bg" style="background: /img/"></div></a></div><div class="recent-post-info"><a class="article-title" href="/2024/10/22/Multimodel/multimodel_summerize/" title="多模态系列(七)- 总结">多模态系列(七)- 总结</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-10-22T08:48:35.000Z" title="发表于 2024-10-22 16:48:35">2024-10-22</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%B3%BB%E5%88%97/">多模态系列</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2024/10/22/Multimodel/multimodel_summerize/#post-comment"><span class="valine-comment-count" data-xid="/2024/10/22/Multimodel/multimodel_summerize/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">转载自：多模态系列论文----最详细的多模态论文总结（BLIP、BEIT、CoCa等）_多模态大模型系列论文-CSDN博客
 多模态系列(七)- 总结
 1. 多模态概述
多模态指的是多种模态的信息数据，包括：文本、图像、视频、音频等。多模态任务是指需要同时处理两种或多种不同类型的数据的任务。近年来，随着深度学习技术的发展，多模态任务取得了显著的进步。特别是VIT（Vision Transformer）和CLIP（Contrastive Language–Image Pre-training）这两种基于Transformer模型的方法，极大地推动了多模态研究的发展。相比于传统的基于CNN（Convolutional Neural Network)的方法，Transformer能够对不同模态的数据进行统一建模，包括参数共享和特征融合。这极大地降低了多模态任务的复杂性和计算成本。
本文主要关注文本、图像两种模态数据的处理。
常见任务

图像描述（image captioning） ：对给定图像生成描述性说明或生成字幕。
视觉定位（visual grounding）：在给定的图像中定位具有指 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/10/22/Multimodel/BEiTv3/" title="多模态系列(六)- BEiTv3"><img class="post-bg" src="/img/image-20241022190456136.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多模态系列(六)- BEiTv3"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/10/22/Multimodel/BEiTv3/" title="多模态系列(六)- BEiTv3">多模态系列(六)- BEiTv3</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-10-22T07:48:38.000Z" title="发表于 2024-10-22 15:48:38">2024-10-22</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%B3%BB%E5%88%97/">多模态系列</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2024/10/22/Multimodel/BEiTv3/#post-comment"><span class="valine-comment-count" data-xid="/2024/10/22/Multimodel/BEiTv3/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">论文地址：Image as a Foreign Language: BEIT Pretraining for All Vision and Vision-Language Tasks
论文代码：BEiT-3
转载自：多模态系列论文–BEiT-3 详细解析_beitv3 github-CSDN博客
 多模态系列(六)- BEiTv3
 摘要
BEiTv3的目标非常明确，就是想做一个更大一统的框架，不论是从模型上统一，而且从训练的目标函数上要统一，还有模型大小，数据集大小，如何scale也要统一，作者称之为Big Convergence。BEiTv3就是把图像也看成了是一种语言（这就是他们题目的意思叫做Image as a Foreign Language），文章把Image叫做Imagelish，文本叫做English，然后把图像文本对叫做Parallel Sentence。因为不论是图像还是文本都可以用Mask Modeling去做,所以就不需要ITC，ITM ，Language Modeling或者Word Patch Alignment等各种Loss，只用一个Loss----- M ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/10/22/Multimodel/COCA/" title="多模态系列(五)- COCA"><img class="post-bg" src="/img/image-20241022153206496.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多模态系列(五)- COCA"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/10/22/Multimodel/COCA/" title="多模态系列(五)- COCA">多模态系列(五)- COCA</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-10-22T06:51:38.000Z" title="发表于 2024-10-22 14:51:38">2024-10-22</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%B3%BB%E5%88%97/">多模态系列</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2024/10/22/Multimodel/COCA/#post-comment"><span class="valine-comment-count" data-xid="/2024/10/22/Multimodel/COCA/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">论文地址：CoCa: Contrastive Captioners are Image-Text Foundation Models
代码地址：CoCa
转载自：多模态系列论文–CoCa 详细解析_coca paper-CSDN博客
 多模态系列(五)- COCA
 1 摘要
CoCa代表Contrastive Captioners的缩写，代表模型用两个目标函数训练出来的，一个是Contrastive Loss，一个是Captioning Loss。本文因为数据集更大，模型也更大，所以它的效果很好，在多模态所有的任务均SOTA，而且在单模态里，在ImageNet上也得到了90以上的Top1准确度，在视频动作识别领域，在Paper with Code上CoCa在K400、K600、K700这些数据集上排名前三。
 2. 网络结构

CoCa是ALBEF的一个后续工作，它与ALBEF的模型类似，左边是一个Image Encoder，右边是一个Text Decoder，注意，这里是Decoder不是Encoder。从左右来看还是左边图像分支，右边文本分支，文本分支分两部分，下面用来抽取Uni ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/#content-inner">6</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/87788970_p0_master1200.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">HUI</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">58</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/kalabiqlx" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:kalabiqlx@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/12/10/Multimodel/MM-LLMs-survey/" title="MM-LLMs综述(腾讯)"><img src="/img/image-20241114140927375.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MM-LLMs综述(腾讯)"/></a><div class="content"><a class="title" href="/2024/12/10/Multimodel/MM-LLMs-survey/" title="MM-LLMs综述(腾讯)">MM-LLMs综述(腾讯)</a><time datetime="2024-12-10T12:40:00.000Z" title="发表于 2024-12-10 20:40:00">2024-12-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/10/Multimodel/BiRD/" title="MICCAI2024(2)-BIRD"><img src="/img/image-20241104164541942.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MICCAI2024(2)-BIRD"/></a><div class="content"><a class="title" href="/2024/12/10/Multimodel/BiRD/" title="MICCAI2024(2)-BIRD">MICCAI2024(2)-BIRD</a><time datetime="2024-12-10T12:36:38.000Z" title="发表于 2024-12-10 20:36:38">2024-12-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/10/Multimodel/LLaVA-V1.5/" title="LLaVA(2)-Improved Baselines with Visual Instruction Tuning"><img src="/img/image-20241123214150206.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LLaVA(2)-Improved Baselines with Visual Instruction Tuning"/></a><div class="content"><a class="title" href="/2024/12/10/Multimodel/LLaVA-V1.5/" title="LLaVA(2)-Improved Baselines with Visual Instruction Tuning">LLaVA(2)-Improved Baselines with Visual Instruction Tuning</a><time datetime="2024-12-10T12:30:38.000Z" title="发表于 2024-12-10 20:30:38">2024-12-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/10/Multimodel/LLaVA/" title="LLaVA(1)-Visual Instruction Tuning"><img src="/img/image-20241122154508143.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LLaVA(1)-Visual Instruction Tuning"/></a><div class="content"><a class="title" href="/2024/12/10/Multimodel/LLaVA/" title="LLaVA(1)-Visual Instruction Tuning">LLaVA(1)-Visual Instruction Tuning</a><time datetime="2024-12-10T12:25:38.000Z" title="发表于 2024-12-10 20:25:38">2024-12-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/10/Multimodel/PMC-CLIP/" title="MICCAI2024(1)-PMC-CLIP"><img src="/img/image-20241111141331709.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MICCAI2024(1)-PMC-CLIP"/></a><div class="content"><a class="title" href="/2024/12/10/Multimodel/PMC-CLIP/" title="MICCAI2024(1)-PMC-CLIP">MICCAI2024(1)-PMC-CLIP</a><time datetime="2024-12-10T12:12:38.000Z" title="发表于 2024-12-10 20:12:38">2024-12-10</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DeepLearning/"><span class="card-category-list-name">DeepLearning</span><span class="card-category-list-count">5</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DeepLearning/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"><span class="card-category-list-name">基础知识</span><span class="card-category-list-count">4</span></a></li></ul></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Hexo/"><span class="card-category-list-name">Hexo</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/HuggingFace/"><span class="card-category-list-name">HuggingFace</span><span class="card-category-list-count">14</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/HuggingFace/Audio/"><span class="card-category-list-name">Audio</span><span class="card-category-list-count">5</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/HuggingFace/Diffusion/"><span class="card-category-list-name">Diffusion</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/HuggingFace/NLP/"><span class="card-category-list-name">NLP</span><span class="card-category-list-count">8</span></a></li></ul></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/LLM/"><span class="card-category-list-name">LLM</span><span class="card-category-list-count">3</span></a></li>
            </ul></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/12/"><span class="card-archive-list-date">十二月 2024</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">十月 2024</span><span class="card-archive-list-count">29</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">24</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">58</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2024-09-12T16:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">314.9k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2024-12-10T12:51:21.467Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/121764304_p0.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2024 By HUI</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="chat-btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  function loadValine () {
    function initValine () {
      let initData = {
        el: '#vcomment',
        appId: '',
        appKey: '',
        serverURLs: ''
      }
      
      const valine = new Valine(initData)
    }

    if (typeof Valine === 'function') initValine() 
    else getScript('https://cdn.jsdelivr.net/npm/valine@1.5.1/dist/Valine.min.js').then(initValine)
  }

  window.pjax ? loadValine() : window.addEventListener('load', loadValine)
})()</script><script>window.typedJSFn = {
  init: (str) => {
    window.typed = new Typed('#subtitle', Object.assign({
      strings: str,
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50,
    }, null))
  },
  run: (subtitleType) => {
    if (true) {
      if (typeof Typed === 'function') {
        subtitleType()
      } else {
        getScript('https://cdn.jsdelivr.net/npm/typed.js@2.1.0/dist/typed.umd.min.js').then(subtitleType)
      }
    } else {
      subtitleType()
    }
  }
}
</script><script>function subtitleType () {
  if (true) {
    typedJSFn.init(["Patient and Passion","天行健，君子以自强不息；地势坤，君子以厚德载物","万物负阴而抱阳，冲气以为和","Courage, Ambition, Cognition and Execution"])
  } else {
    document.getElementById("subtitle").textContent = "Patient and Passion"
  }
}
typedJSFn.run(subtitleType)</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>