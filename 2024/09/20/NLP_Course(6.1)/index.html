<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>NLPè¯¾ç¨‹ï¼ˆå…­-ä¸Šï¼‰- Tokenizeråº“ | HUI</title><meta name="author" content="HUI"><meta name="copyright" content="HUI"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="è½¬è½½è‡ªï¼šhttps:&#x2F;&#x2F;huggingface.co&#x2F;learn&#x2F;nlp-course&#x2F;zh-CN&#x2F; åŸä¸­æ–‡æ–‡æ¡£æœ‰å¾ˆå¤šåœ°æ–¹ç¿»è¯‘çš„å¤ªæ•·è¡äº†ï¼Œå› æ­¤æ‰æœ‰æ­¤ç³»åˆ—æ–‡ç« ã€‚  NLPè¯¾ç¨‹ï¼ˆå…­-ä¸Šï¼‰- Tokenizeråº“  æ ¹æ®å·²æœ‰çš„tokenizerè®­ç»ƒæ–°çš„tokenizer  1.å‡†å¤‡è¯­æ–™åº“  âš ï¸ è®­ç»ƒæ ‡è®°å™¨ä¸è®­ç»ƒæ¨¡å‹ä¸åŒï¼æ¨¡å‹è®­ç»ƒä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ä½¿æ¯ä¸ªbatchçš„losså°ä¸€ç‚¹ã€‚å®ƒæœ¬è´¨ä¸Šæ˜¯éšæœºçš„ï¼ˆè¿™æ„å‘³">
<meta property="og:type" content="article">
<meta property="og:title" content="NLPè¯¾ç¨‹ï¼ˆå…­-ä¸Šï¼‰- Tokenizeråº“">
<meta property="og:url" content="http://example.com/2024/09/20/NLP_Course(6.1)/index.html">
<meta property="og:site_name" content="HUI">
<meta property="og:description" content="è½¬è½½è‡ªï¼šhttps:&#x2F;&#x2F;huggingface.co&#x2F;learn&#x2F;nlp-course&#x2F;zh-CN&#x2F; åŸä¸­æ–‡æ–‡æ¡£æœ‰å¾ˆå¤šåœ°æ–¹ç¿»è¯‘çš„å¤ªæ•·è¡äº†ï¼Œå› æ­¤æ‰æœ‰æ­¤ç³»åˆ—æ–‡ç« ã€‚  NLPè¯¾ç¨‹ï¼ˆå…­-ä¸Šï¼‰- Tokenizeråº“  æ ¹æ®å·²æœ‰çš„tokenizerè®­ç»ƒæ–°çš„tokenizer  1.å‡†å¤‡è¯­æ–™åº“  âš ï¸ è®­ç»ƒæ ‡è®°å™¨ä¸è®­ç»ƒæ¨¡å‹ä¸åŒï¼æ¨¡å‹è®­ç»ƒä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ä½¿æ¯ä¸ªbatchçš„losså°ä¸€ç‚¹ã€‚å®ƒæœ¬è´¨ä¸Šæ˜¯éšæœºçš„ï¼ˆè¿™æ„å‘³">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/87788970_p0_master1200.jpg">
<meta property="article:published_time" content="2024-09-20T14:34:33.000Z">
<meta property="article:modified_time" content="2024-09-21T09:02:45.382Z">
<meta property="article:author" content="HUI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/87788970_p0_master1200.jpg"><link rel="shortcut icon" href="/img/122061154_p0_master1200.jpg"><link rel="canonical" href="http://example.com/2024/09/20/NLP_Course(6.1)/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}","hits_stats":"å…±æ‰¾åˆ° ${hits} ç¯‡æ–‡ç« "}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶é”™è¯¯',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'å¤©',
  dateSuffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'åŠ è½½æ›´å¤š'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'NLPè¯¾ç¨‹ï¼ˆå…­-ä¸Šï¼‰- Tokenizeråº“',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-09-21 17:02:45'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/bronya.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">åŠ è½½ä¸­...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (false) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/87788970_p0_master1200.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é </span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ™‚é–“è»¸</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ¨™ç±¤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†é¡</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> æ¸…å–®</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> éŸ³æ¨‚</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> ç…§ç‰‡</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> é›»å½±</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹éˆ</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> é—œæ–¼</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="HUI"><img class="site-icon" src="/img/319E33068A7ED73BAE7EB48FCE321DD4.jpg"/><span class="site-name">HUI</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> æœç´¢</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é </span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ™‚é–“è»¸</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ¨™ç±¤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†é¡</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> æ¸…å–®</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> éŸ³æ¨‚</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> ç…§ç‰‡</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> é›»å½±</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹éˆ</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> é—œæ–¼</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">NLPè¯¾ç¨‹ï¼ˆå…­-ä¸Šï¼‰- Tokenizeråº“</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2024-09-20T14:34:33.000Z" title="å‘è¡¨äº 2024-09-20 22:34:33">2024-09-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2024-09-21T09:02:45.382Z" title="æ›´æ–°äº 2024-09-21 17:02:45">2024-09-21</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/HuggingFace/">HuggingFace</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/HuggingFace/NLP/">NLP</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">å­—æ•°æ€»è®¡:</span><span class="word-count">12.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»æ—¶é•¿:</span><span>50åˆ†é’Ÿ</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="NLPè¯¾ç¨‹ï¼ˆå…­-ä¸Šï¼‰- Tokenizeråº“"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»é‡:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">è¯„è®ºæ•°:</span><a href="/2024/09/20/NLP_Course(6.1)/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2024/09/20/NLP_Course(6.1)/" itemprop="commentCount"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>è½¬è½½è‡ªï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/zh-CN/">https://huggingface.co/learn/nlp-course/zh-CN/</a></p>
<p><strong>åŸä¸­æ–‡æ–‡æ¡£æœ‰å¾ˆå¤šåœ°æ–¹ç¿»è¯‘çš„å¤ªæ•·è¡äº†ï¼Œå› æ­¤æ‰æœ‰æ­¤ç³»åˆ—æ–‡ç« ã€‚</strong></p>
<h1 id="nlpè¯¾ç¨‹å…­-ä¸Š-tokenizeråº“"><a class="markdownIt-Anchor" href="#nlpè¯¾ç¨‹å…­-ä¸Š-tokenizeråº“"></a> NLPè¯¾ç¨‹ï¼ˆå…­-ä¸Šï¼‰- Tokenizeråº“</h1>
<h2 id="æ ¹æ®å·²æœ‰çš„tokenizerè®­ç»ƒæ–°çš„tokenizer"><a class="markdownIt-Anchor" href="#æ ¹æ®å·²æœ‰çš„tokenizerè®­ç»ƒæ–°çš„tokenizer"></a> æ ¹æ®å·²æœ‰çš„tokenizerè®­ç»ƒæ–°çš„tokenizer</h2>
<h3 id="1å‡†å¤‡è¯­æ–™åº“"><a class="markdownIt-Anchor" href="#1å‡†å¤‡è¯­æ–™åº“"></a> 1.å‡†å¤‡è¯­æ–™åº“</h3>
<blockquote>
<p>âš ï¸ <font color="red">è®­ç»ƒæ ‡è®°å™¨ä¸è®­ç»ƒæ¨¡å‹ä¸åŒï¼æ¨¡å‹è®­ç»ƒä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ä½¿æ¯ä¸ªbatchçš„losså°ä¸€ç‚¹ã€‚å®ƒæœ¬è´¨ä¸Šæ˜¯éšæœºçš„ï¼ˆè¿™æ„å‘³ç€åœ¨è¿›è¡Œä¸¤æ¬¡ç›¸åŒçš„è®­ç»ƒæ—¶ï¼Œæ‚¨å¿…é¡»è®¾ç½®ä¸€äº›éšæœºæ•°ç§å­æ‰èƒ½è·å¾—ç›¸åŒçš„ç»“æœï¼‰ã€‚è®­ç»ƒæ ‡è®°å™¨æ˜¯ä¸€ä¸ªç»Ÿè®¡è¿‡ç¨‹ï¼Œå®ƒè¯•å›¾ç¡®å®šå“ªäº›å­è¯æœ€é€‚åˆä¸ºç»™å®šçš„è¯­æ–™åº“é€‰æ‹©ï¼Œç”¨äºé€‰æ‹©å®ƒä»¬çš„ç¡®åˆ‡è§„åˆ™å–å†³äºåˆ†è¯ç®—æ³•ã€‚å®ƒæ˜¯ç¡®å®šæ€§çš„ï¼Œè¿™æ„å‘³ç€åœ¨ç›¸åŒçš„è¯­æ–™åº“ä¸Šä½¿ç”¨ç›¸åŒçš„ç®—æ³•è¿›è¡Œè®­ç»ƒæ—¶ï¼Œæ‚¨æ€»æ˜¯ä¼šå¾—åˆ°ç›¸åŒçš„ç»“æœã€‚</font></p>
</blockquote>
<p>Transformers ä¸­æœ‰ä¸€ä¸ªéå¸¸ç®€å•çš„ APIï¼Œä½ å¯ä»¥ç”¨å®ƒæ¥è®­ç»ƒä¸€ä¸ªæ–°çš„æ ‡è®°å™¨ï¼Œä½¿å®ƒä¸ç°æœ‰æ ‡è®°å™¨ç›¸åŒçš„ç‰¹å¾ï¼š <code>AutoTokenizer.train_new_from_iterator() </code></p>
<p>é¦–è¦ä»»åŠ¡æ˜¯åœ¨è®­ç»ƒè¯­æ–™åº“ä¸­æ”¶é›†è¯¥è¯­è¨€çš„å¤§é‡æ•°æ®ã€‚ä¸ºäº†æä¾›æ¯ä¸ªäººéƒ½èƒ½ç†è§£çš„ç¤ºä¾‹ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œä¸ä¼šä½¿ç”¨ä¿„è¯­æˆ–ä¸­æ–‡ä¹‹ç±»çš„è¯­è¨€ï¼Œè€Œæ˜¯ä½¿ç”¨åœ¨ç‰¹å®šé¢†åŸŸçš„è‹±è¯­è¯­è¨€ï¼šPython ä»£ç ã€‚</p>
<p><a target="_blank" rel="noopener" href="https://github.com/huggingface/datasets">ğŸ¤— Datasets</a>åº“å¯ä»¥å¸®åŠ©æˆ‘ä»¬ç»„è£…ä¸€ä¸ª Python æºä»£ç è¯­æ–™åº“ã€‚æˆ‘ä»¬å°†ä½¿ç”¨**load_dataset()**åŠŸèƒ½ä¸‹è½½å’Œç¼“å­˜<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/code_search_net">CodeSearchNet</a>æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†æ˜¯ä¸º<a target="_blank" rel="noopener" href="https://wandb.ai/github/CodeSearchNet/benchmark">CodeSearchNet æŒ‘æˆ˜</a>è€Œåˆ›å»ºçš„å¹¶åŒ…å«æ¥è‡ª GitHub ä¸Šå¼€æºåº“çš„æ•°ç™¾ä¸‡ç§ç¼–ç¨‹è¯­è¨€çš„å‡½æ•°ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†åŠ è½½æ­¤æ•°æ®é›†çš„ Python éƒ¨åˆ†ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># This can take a few minutes to load, so grab a coffee or tea while you wait!</span></span><br><span class="line">raw_datasets = load_dataset(<span class="string">&quot;code_search_net&quot;</span>, <span class="string">&quot;python&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹è®­ç»ƒé›†çš„éƒ¨åˆ†ï¼Œä»¥æŸ¥çœ‹æˆ‘ä»¬æ•°æ®é›†ä¸­æœ‰å“ªäº›åˆ—ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">raw_datasets[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">Dataset(&#123;</span><br><span class="line">    features: [<span class="string">&#x27;repository_name&#x27;</span>, <span class="string">&#x27;func_path_in_repository&#x27;</span>, <span class="string">&#x27;func_name&#x27;</span>, <span class="string">&#x27;whole_func_string&#x27;</span>, <span class="string">&#x27;language&#x27;</span>, </span><br><span class="line">      <span class="string">&#x27;func_code_string&#x27;</span>, <span class="string">&#x27;func_code_tokens&#x27;</span>, <span class="string">&#x27;func_documentation_string&#x27;</span>, <span class="string">&#x27;func_documentation_tokens&#x27;</span>, <span class="string">&#x27;split_name&#x27;</span>, </span><br><span class="line">      <span class="string">&#x27;func_code_url&#x27;</span></span><br><span class="line">    ],</span><br><span class="line">    num_rows: <span class="number">412178</span></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ•°æ®é›†å°†æ–‡æ¡£å­—ç¬¦ä¸²ä¸ä»£ç åˆ†å¼€ï¼Œå¹¶ä¸”æœ‰ä»–ä»¬å„è‡ªçš„æ ‡è®°åŒ–åçš„ç»“æœã€‚</p>
<p>è¿™é‡Œã€‚ æˆ‘ä»¬å°†åªä½¿ç”¨ <code>whole_func_string</code> åˆ—æ¥è®­ç»ƒæˆ‘ä»¬çš„æ ‡è®°å™¨ã€‚ æˆ‘ä»¬å¯ä»¥é€šè¿‡æŒ‡å®šåˆ° <code>train</code> ä¸­çš„ä¸€éƒ¨åˆ†æ¥æŸ¥çœ‹è¿™äº›å‡½æ•°çš„ä¸€ä¸ªç¤ºä¾‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(raw_datasets[<span class="string">&quot;train&quot;</span>][<span class="number">123456</span>][<span class="string">&quot;whole_func_string&quot;</span>])</span><br></pre></td></tr></table></figure>
<p>åº”è¯¥æ‰“å°ä»¥ä¸‹å†…å®¹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">handle_simple_responses</span>(<span class="params"></span></span><br><span class="line"><span class="params">      self, timeout_ms=<span class="literal">None</span>, info_cb=DEFAULT_MESSAGE_CALLBACK</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Accepts normal responses from the device.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      timeout_ms: Timeout in milliseconds to wait for each response.</span></span><br><span class="line"><span class="string">      info_cb: Optional callback for text sent from the bootloader.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      OKAY packet&#x27;s message.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>._accept_responses(<span class="string">&#x27;OKAY&#x27;</span>, info_cb, timeout_ms=timeout_ms)</span><br></pre></td></tr></table></figure>
<p><font color="red">æˆ‘ä»¬éœ€è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯å°†æ•°æ®é›†è½¬æ¢ä¸ºè¿­ä»£å™¨æ–‡æœ¬åˆ—è¡¨ - ä¾‹å¦‚ï¼Œæ–‡æœ¬åˆ—è¡¨ã€‚</font>ä½¿ç”¨æ–‡æœ¬åˆ—è¡¨å°†ä½¿æˆ‘ä»¬çš„æ ‡è®°å™¨è¿è¡Œå¾—æ›´å¿«ï¼ˆè®­ç»ƒæˆæ‰¹æ–‡æœ¬è€Œä¸æ˜¯ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°å¤„ç†å•ä¸ªæ–‡æœ¬ï¼‰ï¼Œå¦‚æœæˆ‘ä»¬æƒ³é¿å…ä¸€æ¬¡å°†æ‰€æœ‰å†…å®¹éƒ½æ”¾åœ¨å†…å­˜ä¸­ï¼Œå®ƒåº”è¯¥æ˜¯ä¸€ä¸ªè¿­ä»£å™¨ã€‚<font color="red">å¦‚æœä½ çš„è¯­æ–™åº“å¾ˆå¤§ï¼Œä½ ä¼šæƒ³è¦åˆ©ç”¨è¿™æ ·ä¸€ä¸ªç‰¹æ€§ï¼šDatasetsä¸ä¼šå°†æ‰€æœ‰å†…å®¹éƒ½åŠ è½½åˆ° RAM ä¸­ï¼Œè€Œæ˜¯å°†æ•°æ®é›†çš„å…ƒç´ å­˜å‚¨åœ¨ç£ç›˜ä¸Šã€‚</font></p>
<p><font size="5">åˆ›å»ºä¸€ä¸ªåŒ…å«1,000ä¸ªæ–‡æœ¬çš„åˆ—è¡¨</font></p>
<p><font color="red">æ‰§è¡Œä»¥ä¸‹æ“ä½œå°†åˆ›å»ºä¸€ä¸ªåŒ…å« 1,000 ä¸ªæ–‡æœ¬çš„åˆ—è¡¨çš„åˆ—è¡¨ï¼Œä½†ä¼šå°†æ‰€æœ‰å†…å®¹åŠ è½½åˆ°å†…å­˜ä¸­ï¼š</font></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Don&#x27;t uncomment the following line unless your dataset is small!</span></span><br><span class="line">training_corpus = [raw_datasets[<span class="string">&quot;train&quot;</span>][i: i + <span class="number">1000</span>][<span class="string">&quot;whole_func_string&quot;</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(raw_datasets[<span class="string">&quot;train&quot;</span>]), <span class="number">1000</span>)]</span><br></pre></td></tr></table></figure>
<p><font color="red">ä½¿ç”¨ Python ç”Ÿæˆå™¨ï¼Œæˆ‘ä»¬å¯ä»¥é¿å… Python å°†ä»»ä½•å†…å®¹åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œç›´åˆ°çœŸæ­£éœ€è¦ä¸ºæ­¢ã€‚</font>è¦åˆ›å»ºè¿™æ ·çš„ç”Ÿæˆå™¨ï¼Œæ‚¨åªéœ€è¦å°†æ‹¬å·æ›¿æ¢ä¸ºåœ†æ‹¬å·ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">training_corpus = (</span><br><span class="line">    raw_datasets[<span class="string">&quot;train&quot;</span>][i : i + <span class="number">1000</span>][<span class="string">&quot;whole_func_string&quot;</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(raw_datasets[<span class="string">&quot;train&quot;</span>]), <span class="number">1000</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><font color="red">è¿™è¡Œä»£ç ä¸ä¼šè·å–æ•°æ®é›†çš„ä»»ä½•å…ƒç´ ï¼›å®ƒåªæ˜¯åˆ›å»ºäº†ä¸€ä¸ªå¯ä»¥åœ¨ Python ä¸­ä½¿ç”¨çš„å¯¹è±¡<strong>for</strong>ç¯å½¢ã€‚æ–‡æœ¬åªä¼šåœ¨æ‚¨éœ€è¦æ—¶åŠ è½½ï¼ˆå³ï¼Œå½“æ‚¨å¤„äº<strong>for</strong>éœ€è¦å®ƒä»¬çš„å¾ªç¯ï¼‰ï¼Œå¹¶ä¸”ä¸€æ¬¡åªä¼šåŠ è½½ 1,000 ä¸ªæ–‡æœ¬ã€‚è¿™æ ·ï¼Œå³ä½¿æ‚¨æ­£åœ¨å¤„ç†åºå¤§çš„æ•°æ®é›†ï¼Œä¹Ÿä¸ä¼šè€—å°½æ‰€æœ‰å†…å­˜ã€‚</font></p>
<p>ç”Ÿæˆå™¨å¯¹è±¡çš„é—®é¢˜åœ¨äºå®ƒåªèƒ½ä½¿ç”¨ä¸€æ¬¡ï¼Œæ¯æ¬¡è®¿é—®å®ƒå°†ç»™å‡ºä¸‹ä¸€ä¸ªå€¼ã€‚ ä¸‹é¢æ˜¯ä¸€ä¸ªä¾‹å­ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gen = (i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(gen))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(gen))</span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬ç¬¬ä¸€æ¬¡å¾—åˆ°äº†è¿™ä¸ªåˆ—è¡¨ï¼Œç„¶åæ˜¯ä¸€ä¸ªç©ºåˆ—è¡¨ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br><span class="line">[]python</span><br></pre></td></tr></table></figure>
<p><strong>æ–¹æ³•1ï¼š</strong></p>
<p>è¿™å°±æ˜¯æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªè¿”å›ç”Ÿæˆå™¨çš„å‡½æ•°çš„åŸå› ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_training_corpus</span>():</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        raw_datasets[<span class="string">&quot;train&quot;</span>][i : i + <span class="number">1000</span>][<span class="string">&quot;whole_func_string&quot;</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(raw_datasets[<span class="string">&quot;train&quot;</span>]), <span class="number">1000</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">training_corpus = get_training_corpus()</span><br></pre></td></tr></table></figure>
<p><strong>æ–¹æ³•2ï¼š</strong></p>
<p>æ‚¨è¿˜å¯ä»¥åœ¨ä¸€ä¸ª <strong>for</strong> å¾ªç¯å†…éƒ¨ä½¿ç”¨ <strong>yield</strong> å…³é”®å­—å®šä¹‰æ‚¨çš„ç”Ÿæˆå™¨ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_training_corpus</span>():</span><br><span class="line">    dataset = raw_datasets[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">    <span class="keyword">for</span> start_idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(dataset), <span class="number">1000</span>):</span><br><span class="line">        samples = dataset[start_idx : start_idx + <span class="number">1000</span>]</span><br><span class="line">        <span class="keyword">yield</span> samples[<span class="string">&quot;whole_func_string&quot;</span>]</span><br></pre></td></tr></table></figure>
<p>è¿™å°†äº§ç”Ÿä¸ä»¥å‰å®Œå…¨ç›¸åŒçš„ç”Ÿæˆå™¨ï¼Œä½†å…è®¸æ‚¨ä½¿ç”¨æ¯”åˆ—è¡¨ç”Ÿæˆå¼ä¸­æ›´å¤æ‚çš„é€»è¾‘ã€‚</p>
<h3 id="2è®­ç»ƒä¸€ä¸ªæ–°çš„tokenizer"><a class="markdownIt-Anchor" href="#2è®­ç»ƒä¸€ä¸ªæ–°çš„tokenizer"></a> 2.è®­ç»ƒä¸€ä¸ªæ–°çš„Tokenizer</h3>
<blockquote>
<p><font color="red">è¿™ä¸€èŠ‚æ˜¯åœ¨å·²æœ‰Tokenizerçš„åŸºç¡€ä¸Šï¼Œåˆ©ç”¨æ–°çš„è¯­æ–™åº“è®­ç»ƒä¸€ä¸ªæ–°çš„Tokenizerï¼Œè¿™ä»£è¡¨Tokenizerçš„åˆ†å‰²ç®—æ³•å¹¶æ²¡æœ‰å˜ã€‚</font></p>
</blockquote>
<p>ç°åœ¨æˆ‘ä»¬çš„è¯­æ–™åº“æ˜¯æ–‡æœ¬æ‰¹é‡è¿­ä»£å™¨çš„å½¢å¼ï¼Œæˆ‘ä»¬å‡†å¤‡è®­ç»ƒä¸€ä¸ªæ–°çš„æ ‡è®°å™¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦åŠ è½½è¦ä¸æ¨¡å‹é…å¯¹çš„æ ‡è®°å™¨ï¼ˆæ­¤å¤„ä¸ºGPT-2ï¼‰ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">old_tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;gpt2&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><font color="red">å³ä½¿æˆ‘ä»¬è¦è®­ç»ƒä¸€ä¸ªæ–°çš„æ ‡è®°å™¨ï¼Œæœ€å¥½è¿˜æ˜¯è¿™æ ·åšä»¥é¿å…å®Œå…¨ä»å¤´å¼€å§‹ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å°±ä¸å¿…æŒ‡å®šä»»ä½•å…³äºæ ‡è®°åŒ–ç®—æ³•æˆ–æˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„ç‰¹æ®Šæ ‡è®°ï¼›æˆ‘ä»¬çš„æ–°æ ‡è®°å™¨å°†ä¸ GPT-2 å®Œå…¨ç›¸åŒï¼Œå”¯ä¸€ä¼šæ”¹å˜çš„æ˜¯è¾“å…¥çš„æ•°æ®ï¼Œè¿™å°†å–å†³äºæˆ‘ä»¬è®­ç»ƒçš„è¯­æ–™ã€‚</font></p>
<p>é¦–å…ˆè®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªæ ‡è®°å™¨å°†å¦‚ä½•å¤„ç†ç¤ºä¾‹çš„æ•°æ®ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">example = <span class="string">&#x27;&#x27;&#x27;def add_numbers(a, b):</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;Add the two numbers `a` and `b`.&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    return a + b&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">tokens = old_tokenizer.tokenize(example)</span><br><span class="line">tokens</span><br><span class="line">[<span class="string">&#x27;def&#x27;</span>, <span class="string">&#x27;Ä add&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;umbers&#x27;</span>, <span class="string">&#x27;(&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;Ä b&#x27;</span>, <span class="string">&#x27;):&#x27;</span>, <span class="string">&#x27;ÄŠ&#x27;</span>, <span class="string">&#x27;Ä &#x27;</span>, <span class="string">&#x27;Ä &#x27;</span>, <span class="string">&#x27;Ä &#x27;</span>, <span class="string">&#x27;Ä &quot;&quot;&quot;&#x27;</span>, <span class="string">&#x27;Add&#x27;</span>, <span class="string">&#x27;Ä the&#x27;</span>, <span class="string">&#x27;Ä two&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Ä numbers&#x27;</span>, <span class="string">&#x27;Ä `&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;`&#x27;</span>, <span class="string">&#x27;Ä and&#x27;</span>, <span class="string">&#x27;Ä `&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;`&#x27;</span>, <span class="string">&#x27;.&quot;&#x27;</span>, <span class="string">&#x27;&quot;&quot;&#x27;</span>, <span class="string">&#x27;ÄŠ&#x27;</span>, <span class="string">&#x27;Ä &#x27;</span>, <span class="string">&#x27;Ä &#x27;</span>, <span class="string">&#x27;Ä &#x27;</span>, <span class="string">&#x27;Ä return&#x27;</span>, <span class="string">&#x27;Ä a&#x27;</span>, <span class="string">&#x27;Ä +&#x27;</span>, <span class="string">&#x27;Ä b&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>è¿™ä¸ªæ ‡è®°å™¨æœ‰ä¸€äº›ç‰¹æ®Šçš„ç¬¦å·ï¼Œæ¯”å¦‚ <strong>ÄŠ</strong> å’Œ <strong>Ä </strong> ï¼Œåˆ†åˆ«è¡¨ç¤ºç©ºæ ¼å’Œæ¢è¡Œç¬¦ã€‚æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œè¿™ä¸æ˜¯å¤ªæœ‰æ•ˆï¼šæ ‡è®°å™¨ä¸ºæ¯ä¸ªç©ºæ ¼è¿”å›å•ç‹¬çš„æ ‡è®°ï¼Œå½“å®ƒå¯ä»¥å°†ç¼©è¿›çº§åˆ«ç»„åˆåœ¨ä¸€èµ·æ—¶ï¼ˆå› ä¸ºåœ¨ä»£ç ä¸­å…·æœ‰å››ä¸ªæˆ–å…«ä¸ªç©ºæ ¼çš„é›†åˆå°†éå¸¸æ™®éï¼‰ã€‚å®ƒä¹Ÿæœ‰ç‚¹å¥‡æ€ªåœ°æ‹†åˆ†äº†å‡½æ•°åç§°ï¼Œè€Œä¹ æƒ¯ä½¿ç”¨**_**çš„å‡½æ•°å‘½åçš„æ–¹æ³•ã€‚</p>
<p>è®©æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªæ–°çš„æ ‡è®°å™¨ï¼Œçœ‹çœ‹å®ƒæ˜¯å¦èƒ½è§£å†³è¿™äº›é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ <strong>train_new_from_iterator()</strong> æ–¹æ³•ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, <span class="number">52000</span>)</span><br></pre></td></tr></table></figure>
<p>å¦‚æœæ‚¨çš„è¯­æ–™åº“éå¸¸å¤§ï¼Œæ­¤å‘½ä»¤å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œä½†å¯¹äºè¿™ä¸ª 1.6 GB æ–‡æœ¬æ•°æ®é›†ï¼Œå®ƒçš„é€Ÿåº¦éå¸¸å¿«ï¼ˆåœ¨å…·æœ‰ 12 ä¸ªå†…æ ¸çš„ AMD Ryzen 9 3900X CPU ä¸Šä¸º 1 åˆ† 16 ç§’ï¼‰ã€‚</p>
<blockquote>
<p><font color="red">æ³¨æ„**AutoTokenizer.train_new_from_iterator()**ä»…å½“æ‚¨ä½¿ç”¨çš„æ ‡è®°å™¨æ˜¯â€œå¿«é€Ÿï¼ˆfastï¼‰â€æ ‡è®°å™¨æ—¶æ‰æœ‰æ•ˆã€‚</font>æ­£å¦‚æ‚¨å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­çœ‹åˆ°çš„ï¼ŒğŸ¤— Transformers åº“åŒ…å«ä¸¤ç§ç±»å‹çš„æ ‡è®°å™¨ï¼šä¸€äº›å®Œå…¨ç”¨ Python ç¼–å†™ï¼Œè€Œå¦ä¸€äº›ï¼ˆå¿«é€Ÿçš„ï¼‰ç”± ğŸ¤— Tokenizers åº“æ”¯æŒï¼Œè¯¥åº“ç”¨<a target="_blank" rel="noopener" href="https://www.rust-lang.org/">Rust</a>ç¼–ç¨‹è¯­è¨€ç¼–å†™ã€‚ Python æ˜¯æœ€å¸¸ç”¨äºæ•°æ®ç§‘å­¦å’Œæ·±åº¦å­¦ä¹ åº”ç”¨ç¨‹åºçš„è¯­è¨€ï¼Œä½†æ˜¯å½“éœ€è¦å¹¶è¡ŒåŒ–ä»¥æé«˜é€Ÿåº¦æ—¶ï¼Œå¿…é¡»ç”¨å¦ä¸€ç§è¯­è¨€ç¼–å†™ã€‚ä¾‹å¦‚ï¼Œæ¨¡å‹è®¡ç®—æ ¸å¿ƒçš„çŸ©é˜µä¹˜æ³•æ˜¯ç”¨ CUDA ç¼–å†™çš„ï¼ŒCUDA æ˜¯ä¸€ä¸ªé’ˆå¯¹ GPU çš„ä¼˜åŒ– C åº“ã€‚</p>
<p>ç”¨çº¯ Python è®­ç»ƒä¸€ä¸ªå…¨æ–°çš„æ ‡è®°å™¨ä¼šéå¸¸ç¼“æ…¢ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬å¼€å‘ ğŸ¤— Tokenizersåº“çš„åŸå› ã€‚è¯·æ³¨æ„ï¼Œæ­£å¦‚æ‚¨æ— éœ€å­¦ä¹  CUDA è¯­è¨€å³å¯åœ¨ GPU ä¸Šæ‰§è¡Œæ‚¨çš„æ¨¡å‹ä¸€æ ·ï¼Œæ‚¨ä¹Ÿæ— éœ€å­¦ä¹  Rust å³å¯ä½¿ç”¨å¿«é€Ÿæ ‡è®°å™¨ã€‚ ğŸ¤— Tokenizers åº“ä¸ºè®¸å¤šå†…éƒ¨è°ƒç”¨ Rust ä»£ç çš„æ–¹æ³•æä¾› Python ç»‘å®šï¼›ä¾‹å¦‚ï¼Œå¹¶è¡ŒåŒ–æ–°æ ‡è®°å™¨çš„è®­ç»ƒï¼Œæˆ–è€…ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/course/chapter3">ç¬¬ä¸‰ç« </a>ä¸­çœ‹åˆ°çš„ï¼Œå¯¹ä¸€æ‰¹è¾“å…¥è¿›è¡Œæ ‡è®°åŒ–ã€‚</p>
</blockquote>
<p><font color="red">å¤§å¤šæ•° Transformer æ¨¡å‹éƒ½æœ‰å¯ç”¨çš„å¿«é€Ÿæ ‡è®°å™¨ï¼ˆæ‚¨å¯ä»¥</font><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/#supported-frameworks">åœ¨è¿™é‡Œ</a><font color="red">æ£€æŸ¥ä¸€äº›ä¾‹å¤–æƒ…å†µ)ï¼Œå¦‚æœ <strong>AutoTokenizer</strong> å¯ç”¨ï¼ŒAPI æ€»æ˜¯ä¸ºæ‚¨é€‰æ‹©å¿«é€Ÿæ ‡è®°å™¨ã€‚</font>åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹å¿«é€Ÿæ ‡è®°å™¨å…·æœ‰çš„å…¶ä»–ä¸€äº›ç‰¹æ®ŠåŠŸèƒ½ï¼Œè¿™äº›åŠŸèƒ½å¯¹äºæ ‡è®°åˆ†ç±»å’Œé—®ç­”ç­‰ä»»åŠ¡éå¸¸æœ‰ç”¨ã€‚ç„¶è€Œï¼Œåœ¨æ·±å…¥ç ”ç©¶ä¹‹å‰ï¼Œè®©æˆ‘ä»¬åœ¨ä¸Šä¸€ä¸ªç¤ºä¾‹ä¸­å°è¯•æˆ‘ä»¬å…¨æ–°çš„æ ‡è®°å™¨ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tokens = tokenizer.tokenize(example)</span><br><span class="line">tokens</span><br><span class="line">[<span class="string">&#x27;def&#x27;</span>, <span class="string">&#x27;Ä add&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;numbers&#x27;</span>, <span class="string">&#x27;(&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;Ä b&#x27;</span>, <span class="string">&#x27;):&#x27;</span>, <span class="string">&#x27;ÄŠÄ Ä Ä &#x27;</span>, <span class="string">&#x27;Ä &quot;&quot;&quot;&#x27;</span>, <span class="string">&#x27;Add&#x27;</span>, <span class="string">&#x27;Ä the&#x27;</span>, <span class="string">&#x27;Ä two&#x27;</span>, <span class="string">&#x27;Ä numbers&#x27;</span>, <span class="string">&#x27;Ä `&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;`&#x27;</span>, <span class="string">&#x27;Ä and&#x27;</span>, <span class="string">&#x27;Ä `&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;`.&quot;&quot;&quot;&#x27;</span>, <span class="string">&#x27;ÄŠÄ Ä Ä &#x27;</span>, <span class="string">&#x27;Ä return&#x27;</span>, <span class="string">&#x27;Ä a&#x27;</span>, <span class="string">&#x27;Ä +&#x27;</span>, <span class="string">&#x27;Ä b&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p><font color="red">åœ¨è¿™é‡Œæˆ‘ä»¬å†æ¬¡çœ‹åˆ°ç‰¹æ®Šç¬¦å·<strong>ÄŠ</strong>å’Œ<strong>Ä </strong>è¡¨ç¤ºç©ºæ ¼å’Œæ¢è¡Œç¬¦ï¼Œä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ ‡è®°å™¨å­¦ä¹ äº†ä¸€äº›é«˜åº¦ç‰¹å®šäº Python å‡½æ•°è¯­æ–™åº“çš„æ ‡è®°ï¼šä¾‹å¦‚ï¼Œæœ‰ä¸€ä¸ª<strong>ÄŠÄ Ä Ä </strong>è¡¨ç¤ºç¼©è¿›çš„æ ‡è®°ï¼Œä»¥åŠ<strong>Ä </strong>è¡¨ç¤ºå¼€å§‹æ–‡æ¡£å­—ç¬¦ä¸²çš„ä¸‰ä¸ªå¼•å·çš„æ ‡è®°</font>ã€‚æ ‡è®°å™¨è¿˜æ­£ç¡®ä½¿ç”¨**_**å‘½åçš„è§„èŒƒå°†å‡½æ•°åç§°æ‹†åˆ†ä¸ºã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸ç´§å‡‘çš„è¡¨ç¤ºï¼›ç›¸æ¯”ä¹‹ä¸‹ï¼Œåœ¨åŒä¸€ä¸ªä¾‹å­ä¸­ä½¿ç”¨ç®€å•çš„è‹±è¯­æ ‡è®°å™¨ä¼šç»™æˆ‘ä»¬ä¸€ä¸ªæ›´é•¿çš„å¥å­ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(tokens))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(old_tokenizer.tokenize(example)))</span><br><span class="line"><span class="number">27</span></span><br><span class="line"><span class="number">36</span></span><br></pre></td></tr></table></figure>
<p>è®©æˆ‘ä»¬å†çœ‹ä¸€ä¸ªä¾‹å­ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">example = <span class="string">&quot;&quot;&quot;class LinearLayer():</span></span><br><span class="line"><span class="string">    def __init__(self, input_size, output_size):</span></span><br><span class="line"><span class="string">        self.weight = torch.randn(input_size, output_size)</span></span><br><span class="line"><span class="string">        self.bias = torch.zeros(output_size)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def __call__(self, x):</span></span><br><span class="line"><span class="string">        return x @ self.weights + self.bias</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">tokenizer.tokenize(example)</span><br><span class="line">[<span class="string">&#x27;class&#x27;</span>, <span class="string">&#x27;Ä Linear&#x27;</span>, <span class="string">&#x27;Layer&#x27;</span>, <span class="string">&#x27;():&#x27;</span>, <span class="string">&#x27;ÄŠÄ Ä Ä &#x27;</span>, <span class="string">&#x27;Ä def&#x27;</span>, <span class="string">&#x27;Ä __&#x27;</span>, <span class="string">&#x27;init&#x27;</span>, <span class="string">&#x27;__(&#x27;</span>, <span class="string">&#x27;self&#x27;</span>, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;Ä input&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;size&#x27;</span>, <span class="string">&#x27;,&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Ä output&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;size&#x27;</span>, <span class="string">&#x27;):&#x27;</span>, <span class="string">&#x27;ÄŠÄ Ä Ä Ä Ä Ä Ä &#x27;</span>, <span class="string">&#x27;Ä self&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;Ä =&#x27;</span>, <span class="string">&#x27;Ä torch&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;randn&#x27;</span>, <span class="string">&#x27;(&#x27;</span>, <span class="string">&#x27;input&#x27;</span>, <span class="string">&#x27;_&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;size&#x27;</span>, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;Ä output&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;size&#x27;</span>, <span class="string">&#x27;)&#x27;</span>, <span class="string">&#x27;ÄŠÄ Ä Ä Ä Ä Ä Ä &#x27;</span>, <span class="string">&#x27;Ä self&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;bias&#x27;</span>, <span class="string">&#x27;Ä =&#x27;</span>, <span class="string">&#x27;Ä torch&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;zeros&#x27;</span>, <span class="string">&#x27;(&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;output&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;size&#x27;</span>, <span class="string">&#x27;)&#x27;</span>, <span class="string">&#x27;ÄŠÄŠÄ Ä Ä &#x27;</span>, <span class="string">&#x27;Ä def&#x27;</span>, <span class="string">&#x27;Ä __&#x27;</span>, <span class="string">&#x27;call&#x27;</span>, <span class="string">&#x27;__(&#x27;</span>, <span class="string">&#x27;self&#x27;</span>, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;Ä x&#x27;</span>, <span class="string">&#x27;):&#x27;</span>, <span class="string">&#x27;ÄŠÄ Ä Ä Ä Ä Ä Ä &#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Ä return&#x27;</span>, <span class="string">&#x27;Ä x&#x27;</span>, <span class="string">&#x27;Ä @&#x27;</span>, <span class="string">&#x27;Ä self&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;weights&#x27;</span>, <span class="string">&#x27;Ä +&#x27;</span>, <span class="string">&#x27;Ä self&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;bias&#x27;</span>, <span class="string">&#x27;ÄŠÄ Ä Ä Ä &#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>é™¤äº†ä¸€ä¸ªç¼©è¿›å¯¹åº”çš„tokenï¼Œè¿™é‡Œæˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°ä¸€ä¸ª<strong>åŒç¼©è¿›çš„tokenï¼š</strong> <strong>ÄŠÄ Ä Ä Ä Ä Ä Ä </strong> .ç‰¹æ®Šçš„ Python è¯å¦‚ <strong>class</strong> , <strong>init</strong> , <strong>call</strong> , <strong>self</strong> ï¼Œ å’Œ <strong>return</strong> æ¯ä¸ªéƒ½è¢«æ ‡è®°ä¸ºä¸€ä¸ªæ ‡è®°ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä»¥åŠåˆ†è£‚ <strong>_</strong> å’Œ <strong>.</strong> æ ‡è®°å™¨ç”šè‡³å¯ä»¥æ­£ç¡®æ‹†åˆ†é©¼å³°å¼åç§°ï¼š <strong>LinearLayer</strong> è¢«æ ‡è®°ä¸º <strong>[Ä Linear, Layer]</strong> .</p>
<h3 id="3ä¿å­˜tokenizer"><a class="markdownIt-Anchor" href="#3ä¿å­˜tokenizer"></a> 3.ä¿å­˜Tokenizer</h3>
<p>ä¸ºäº†ç¡®ä¿æˆ‘ä»¬ä»¥åå¯ä»¥ä½¿ç”¨å®ƒï¼Œæˆ‘ä»¬éœ€è¦ä¿å­˜æˆ‘ä»¬çš„æ–°æ ‡è®°å™¨ã€‚å°±åƒæ¨¡å‹ä¸€æ ·ï¼Œæ˜¯é€šè¿‡ <strong>save_pretrained()</strong> æ–¹æ³•ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.save_pretrained(<span class="string">&quot;code-search-net-tokenizer&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>è¿™å°†åˆ›å»ºä¸€ä¸ªåä¸ºçš„<em><strong>code-search-net-tokenizer</strong></em>çš„æ–°æ–‡ä»¶å¤¹ï¼Œå®ƒå°†åŒ…å«é‡æ–°åŠ è½½æ ‡è®°å™¨æ‰€éœ€è¦çš„æ‰€æœ‰æ–‡ä»¶ã€‚å¦‚æœæ‚¨æƒ³ä¸æ‚¨çš„åŒäº‹å’Œæœ‹å‹åˆ†äº«è¿™ä¸ªæ ‡è®°å™¨ï¼Œæ‚¨å¯ä»¥é€šè¿‡ç™»å½•æ‚¨çš„å¸æˆ·å°†å…¶ä¸Šä¼ åˆ° Hubã€‚å¦‚æœæ‚¨åœ¨notebookä¸Šå·¥ä½œï¼Œæœ‰ä¸€ä¸ªæ–¹ä¾¿çš„åŠŸèƒ½å¯ä»¥å¸®åŠ©æ‚¨ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> huggingface_hub <span class="keyword">import</span> notebook_login</span><br><span class="line"></span><br><span class="line">notebook_login()</span><br></pre></td></tr></table></figure>
<p>è¿™å°†æ˜¾ç¤ºä¸€ä¸ªå°éƒ¨ä»¶ï¼Œæ‚¨å¯ä»¥åœ¨å…¶ä¸­è¾“å…¥æ‚¨çš„ Hugging Face ç™»å½•å‡­æ®ã€‚å¦‚æœæ‚¨ä¸æ˜¯åœ¨notebookä¸Šå·¥ä½œï¼Œåªéœ€åœ¨ç»ˆç«¯ä¸­è¾“å…¥ä»¥ä¸‹è¡Œï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">huggingface-cli login</span><br></pre></td></tr></table></figure>
<p>ç™»å½•åï¼Œæ‚¨å¯ä»¥é€šè¿‡æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ¥æ¨é€æ‚¨çš„æ ‡è®°å™¨ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.push_to_hub(<span class="string">&quot;code-search-net-tokenizer&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>è¿™å°†åœ¨æ‚¨çš„å‘½åç©ºé—´ä¸­åˆ›å»ºä¸€ä¸ªåä¸º<strong>code-search-net-tokenizer</strong>çš„æ–°å­˜å‚¨åº“ ï¼ŒåŒ…å«æ ‡è®°å™¨æ–‡ä»¶ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä»ä»»ä½•åœ°æ–¹åŠ è½½æ ‡è®°å™¨çš„ <strong>from_pretrained()</strong> æ–¹æ³•</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Replace &quot;huggingface-course&quot; below with your actual namespace to use your own tokenizer</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;huggingface-course/code-search-net-tokenizer&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="å¿«é€Ÿæ ‡è®°å™¨çš„ç‰¹æ®Šèƒ½åŠ›"><a class="markdownIt-Anchor" href="#å¿«é€Ÿæ ‡è®°å™¨çš„ç‰¹æ®Šèƒ½åŠ›"></a> å¿«é€Ÿæ ‡è®°å™¨çš„ç‰¹æ®Šèƒ½åŠ›</h2>
<p>æ…¢é€Ÿåˆ†è¯å™¨æ˜¯åœ¨ ğŸ¤— Transformers åº“ä¸­ç”¨ Python ç¼–å†™çš„ï¼Œè€Œå¿«é€Ÿç‰ˆæœ¬æ˜¯ç”± ğŸ¤— åˆ†è¯å™¨æä¾›çš„ï¼Œå®ƒä»¬æ˜¯ç”¨ Rust ç¼–å†™çš„ã€‚</p>
<blockquote>
<p>âš ï¸ å¯¹å•ä¸ªå¥å­è¿›è¡Œåˆ†è¯æ—¶ï¼Œæ‚¨ä¸ä¼šæ€»æ˜¯çœ‹åˆ°ç›¸åŒåˆ†è¯å™¨çš„æ…¢é€Ÿå’Œå¿«é€Ÿç‰ˆæœ¬ä¹‹é—´çš„é€Ÿåº¦å·®å¼‚ã€‚äº‹å®ä¸Šï¼Œå¿«é€Ÿç‰ˆæœ¬å®é™…ä¸Šå¯èƒ½æ›´æ…¢ï¼åªæœ‰åŒæ—¶å¯¹å¤§é‡æ–‡æœ¬è¿›è¡Œæ ‡è®°æ—¶ï¼Œæ‚¨æ‰èƒ½æ¸…æ¥šåœ°çœ‹åˆ°å·®å¼‚ã€‚</p>
</blockquote>
<h3 id="1æ‰¹é‡ç¼–ç "><a class="markdownIt-Anchor" href="#1æ‰¹é‡ç¼–ç "></a> 1.æ‰¹é‡ç¼–ç </h3>
<p>åˆ†è¯å™¨çš„è¾“å‡ºä¸æ˜¯ç®€å•çš„ Python å­—å…¸ï¼›æˆ‘ä»¬å¾—åˆ°çš„å®é™…ä¸Šæ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ <strong>BatchEncoding</strong> objectã€‚å®ƒæ˜¯å­—å…¸çš„å­ç±»ï¼ˆè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬ä¹‹å‰èƒ½å¤Ÿæ¯«æ— é—®é¢˜åœ°ç´¢å¼•åˆ°è¯¥ç»“æœä¸­çš„åŸå› ï¼‰ï¼Œä½†å…·æœ‰ä¸»è¦ç”±å¿«é€Ÿæ ‡è®°å™¨ä½¿ç”¨çš„é™„åŠ æ–¹æ³•ã€‚</p>
<p>é™¤äº†å®ƒä»¬çš„å¹¶è¡ŒåŒ–èƒ½åŠ›ä¹‹å¤–ï¼Œå¿«é€Ÿæ ‡è®°å™¨çš„å…³é”®åŠŸèƒ½æ˜¯å®ƒä»¬å§‹ç»ˆè·Ÿè¸ªæœ€ç»ˆæ ‡è®°æ¥è‡ªçš„åŸå§‹æ–‡æœ¬èŒƒå›´â€”â€”æˆ‘ä»¬ç§°ä¹‹ä¸º<strong>åç§»æ˜ å°„.</strong></p>
<p>æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;bert-base-cased&quot;</span>)</span><br><span class="line">example = <span class="string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span></span><br><span class="line">encoding = tokenizer(example)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(encoding))</span><br></pre></td></tr></table></figure>
<p>å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ª <strong>BatchEncoding</strong> æ ‡è®°å™¨è¾“å‡ºä¸­çš„å¯¹è±¡ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;transformers.tokenization_utils_base.BatchEncoding&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>
<p>ç”±äº <strong>AutoTokenizer</strong> ç±»é»˜è®¤é€‰æ‹©å¿«é€Ÿæ ‡è®°å™¨ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é™„åŠ æ–¹æ³• this <strong>BatchEncoding</strong> å¯¹è±¡æä¾›ã€‚</p>
<p><font size="5">æ£€æŸ¥æˆ‘ä»¬çš„åˆ†è¯å™¨æ˜¯å¿«çš„è¿˜æ˜¯æ…¢çš„ã€‚</font></p>
<p>**æ–¹æ³•ä¸€ï¼š**æˆ‘ä»¬å¯ä»¥æ£€æŸ¥ <strong>is_fast</strong> çš„å±æ€§ <strong>tokenizer</strong> ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.is_fast</span><br><span class="line"></span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>**æ–¹æ³•äºŒï¼š**æ£€æŸ¥æˆ‘ä»¬çš„ç›¸åŒå±æ€§ <strong>encoding</strong> ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">encoding.is_fast</span><br><span class="line"></span><br><span class="line">True</span><br></pre></td></tr></table></figure>
<p><font size="5">å¿«é€Ÿæ ‡è®°å™¨ä½¿æˆ‘ä»¬èƒ½å¤Ÿåšä»€ä¹ˆ</font></p>
<p><strong>1.é¦–å…ˆï¼Œæˆ‘ä»¬å¯ä»¥è®¿é—®ä»¤ç‰Œè€Œæ— éœ€å°† ID è½¬æ¢å›ä»¤ç‰Œï¼š</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">encoding.tokens()</span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;[CLS]&#x27;</span>, <span class="string">&#x27;My&#x27;</span>, <span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;##yl&#x27;</span>, <span class="string">&#x27;##va&#x27;</span>, <span class="string">&#x27;##in&#x27;</span>, <span class="string">&#x27;and&#x27;</span>, <span class="string">&#x27;I&#x27;</span>, <span class="string">&#x27;work&#x27;</span>, <span class="string">&#x27;at&#x27;</span>, <span class="string">&#x27;Hu&#x27;</span>, <span class="string">&#x27;##gging&#x27;</span>, <span class="string">&#x27;Face&#x27;</span>, <span class="string">&#x27;in&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Brooklyn&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;[SEP]&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç´¢å¼• 5 å¤„çš„ä»¤ç‰Œæ˜¯ <strong>##yl</strong> ï¼Œå®ƒæ˜¯åŸå§‹å¥å­ä¸­â€œSylvainâ€ä¸€è¯çš„ä¸€éƒ¨åˆ†ã€‚</p>
<p><strong>2.æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨ word_ids() è·å–æ¯ä¸ªæ ‡è®°æ¥è‡ªçš„å•è¯ç´¢å¼•çš„æ–¹æ³•ï¼š</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">encoding.word_ids()</span><br><span class="line"></span><br><span class="line">[<span class="literal">None</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="literal">None</span>]</span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°åˆ†è¯å™¨çš„ç‰¹æ®Šæ ‡è®° <strong>[CLS]</strong> å’Œ <strong>[SEP]</strong> è¢«æ˜ å°„åˆ° <strong>None</strong> ï¼Œç„¶åæ¯ä¸ªæ ‡è®°éƒ½æ˜ å°„åˆ°å®ƒèµ·æºçš„å•è¯ã€‚è¿™å¯¹äºç¡®å®šä¸€ä¸ªæ ‡è®°æ˜¯å¦åœ¨å•è¯çš„å¼€å¤´æˆ–ä¸¤ä¸ªæ ‡è®°æ˜¯å¦åœ¨åŒä¸€ä¸ªå•è¯ä¸­ç‰¹åˆ«æœ‰ç”¨ã€‚æˆ‘ä»¬å¯ä»¥ä¾é  <strong>##</strong> å‰ç¼€ï¼Œä½†å®ƒä»…é€‚ç”¨äºç±»ä¼¼ BERT çš„åˆ†è¯å™¨ï¼›<font color="red">è¿™ç§æ–¹æ³•é€‚ç”¨äºä»»ä½•ç±»å‹çš„æ ‡è®°å™¨ï¼Œåªè¦å®ƒæ˜¯å¿«é€Ÿçš„ã€‚</font></p>
<p><font color="red">ä¸€ä¸ªè¯æ˜¯ä»€ä¹ˆçš„æ¦‚å¿µå¾ˆå¤æ‚ã€‚ä¾‹å¦‚ï¼Œâ€œIâ€™llâ€ï¼ˆâ€œI willâ€çš„ç¼©å†™ï¼‰ç®—ä¸€ä¸¤ä¸ªè¯å—ï¼Ÿå®ƒå®é™…ä¸Šå–å†³äºåˆ†è¯å™¨å’Œå®ƒåº”ç”¨çš„é¢„åˆ†è¯æ“ä½œã€‚ä¸€äº›æ ‡è®°å™¨åªæ˜¯åœ¨ç©ºæ ¼ä¸Šæ‹†åˆ†ï¼Œå› æ­¤ä»–ä»¬ä¼šå°†å…¶è§†ä¸ºä¸€ä¸ªè¯ã€‚å…¶ä»–äººåœ¨ç©ºæ ¼é¡¶éƒ¨ä½¿ç”¨æ ‡ç‚¹ç¬¦å·ï¼Œå› æ­¤å°†å…¶è§†ä¸ºä¸¤ä¸ªè¯ã€‚</font></p>
<p>åŒæ ·ï¼Œæœ‰ä¸€ä¸ª <strong>sentence_ids()</strong> æˆ‘ä»¬å¯ä»¥ç”¨æ¥å°†æ ‡è®°æ˜ å°„åˆ°å®ƒæ¥è‡ªçš„å¥å­çš„æ–¹æ³•ï¼ˆå°½ç®¡åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ <strong>token_type_ids</strong> åˆ†è¯å™¨è¿”å›çš„ä¿¡æ¯å¯ä»¥ä¸ºæˆ‘ä»¬æä¾›ç›¸åŒçš„ä¿¡æ¯ï¼‰ã€‚</p>
<p><strong>3.æœ€åï¼Œæˆ‘ä»¬å¯ä»¥å°†ä»»ä½•å•è¯æˆ–æ ‡è®°æ˜ å°„åˆ°åŸå§‹æ–‡æœ¬ä¸­çš„å­—ç¬¦ã€‚</strong></p>
<p>åä¹‹äº¦ç„¶ï¼Œé€šè¿‡ <strong>word_to_chars()</strong> æˆ–è€… <strong>token_to_chars()</strong> å’Œ <strong>char_to_word()</strong> æˆ–è€… <strong>char_to_token()</strong> æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œ <strong>word_ids()</strong> æ–¹æ³•å‘Šè¯‰æˆ‘ä»¬ <strong>##yl</strong> æ˜¯ç´¢å¼• 3 å¤„å•è¯çš„ä¸€éƒ¨åˆ†ï¼Œä½†å®ƒæ˜¯å¥å­ä¸­çš„å“ªä¸ªå•è¯ï¼Ÿæˆ‘ä»¬å¯ä»¥è¿™æ ·å‘ç°ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">start, end = encoding.word_to_chars(<span class="number">3</span>)</span><br><span class="line">example[start:end]</span><br><span class="line"></span><br><span class="line">Sylvain</span><br></pre></td></tr></table></figure>
<p>æ­£å¦‚æˆ‘ä»¬ä¹‹å‰æåˆ°çš„ï¼Œè¿™ä¸€åˆ‡éƒ½æ˜¯ç”±å¿«é€Ÿåˆ†è¯å™¨è·Ÿè¸ªæ¯ä¸ªæ ‡è®°æ¥è‡ª<em>åç§»é‡</em>åˆ—è¡¨çš„æ–‡æœ¬èŒƒå›´è¿™ä¸€äº‹å®æä¾›çš„ã€‚ä¸ºäº†è¯´æ˜å®ƒä»¬çš„ç”¨é€”ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•æ‰‹åŠ¨å¤åˆ¶<code>token-classification</code>ç®¡é“çš„ç»“æœã€‚</p>
<h3 id="2tokenåˆ†ç±»ç®¡é“å†…éƒ¨"><a class="markdownIt-Anchor" href="#2tokenåˆ†ç±»ç®¡é“å†…éƒ¨"></a> 2.tokenåˆ†ç±»ç®¡é“å†…éƒ¨</h3>
<h4 id="é€šè¿‡ç®¡é“è·å¾—åŸºæœ¬ç»“æœ"><a class="markdownIt-Anchor" href="#é€šè¿‡ç®¡é“è·å¾—åŸºæœ¬ç»“æœ"></a> é€šè¿‡ç®¡é“è·å¾—åŸºæœ¬ç»“æœ</h4>
<p>é¦–å…ˆï¼Œè®©æˆ‘ä»¬è·å–ä¸€ä¸ªtokenåˆ†ç±»ç®¡é“ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥æ‰‹åŠ¨æ¯”è¾ƒä¸€äº›ç»“æœã€‚é»˜è®¤ä½¿ç”¨çš„æ¨¡å‹æ˜¯<a target="_blank" rel="noopener" href="https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english">dbmdz/bert-large-cased-finetuned-conll03-english</a>;å®ƒå¯¹å¥å­æ‰§è¡Œ NERï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">token_classifier = pipeline(<span class="string">&quot;token-classification&quot;</span>)</span><br><span class="line">token_classifier(<span class="string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span>)</span><br><span class="line"></span><br><span class="line">[&#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-PER&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.9993828</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">11</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">12</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-PER&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.99815476</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;##yl&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">12</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">14</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-PER&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.99590725</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;##va&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">14</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">16</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-PER&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.9992327</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;##in&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">18</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-ORG&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.97389334</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">12</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;Hu&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">33</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">35</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-ORG&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.976115</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">13</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;##gging&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">35</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">40</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-ORG&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.98879766</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">14</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;Face&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">41</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">45</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-LOC&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.99321055</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;Brooklyn&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">49</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">57</span>&#125;]</span><br></pre></td></tr></table></figure>
<p>è¯¥æ¨¡å‹æ­£ç¡®åœ°å°†â€œSylvainâ€ç”Ÿæˆçš„æ¯ä¸ªæ ‡è®°è¯†åˆ«ä¸º<strong>ä¸€ä¸ªäºº</strong>ï¼Œå°†â€œHugging Faceâ€ç”Ÿæˆçš„æ¯ä¸ªæ ‡è®°è¯†åˆ«ä¸ºä¸€ä¸ª<strong>ç»„ç»‡</strong>ï¼Œå°†â€œBrooklynâ€ç”Ÿæˆçš„æ ‡è®°è¯†åˆ«ä¸ºä¸€ä¸ª<strong>ä½ç½®</strong>ã€‚</p>
<p><font size="5">å°†å¯¹åº”äºåŒä¸€å®ä½“çš„tokenç»„åˆåœ¨ä¸€èµ·</font></p>
<p>æˆ‘ä»¬è¿˜å¯ä»¥è¦æ±‚ç®¡é“å°†å¯¹åº”äºåŒä¸€å®ä½“çš„tokenç»„åˆåœ¨ä¸€èµ·ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">token_classifier = pipeline(<span class="string">&quot;token-classification&quot;</span>, aggregation_strategy=<span class="string">&quot;simple&quot;</span>)</span><br><span class="line">token_classifier(<span class="string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span>)</span><br><span class="line">[&#123;<span class="string">&#x27;entity_group&#x27;</span>: <span class="string">&#x27;PER&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.9981694</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;Sylvain&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">11</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">18</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity_group&#x27;</span>: <span class="string">&#x27;ORG&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.97960204</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;Hugging Face&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">33</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">45</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity_group&#x27;</span>: <span class="string">&#x27;LOC&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.99321055</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;Brooklyn&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">49</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">57</span>&#125;]</span><br></pre></td></tr></table></figure>
<p>é€‰æ‹©çš„<code>aggregation_strategy</code>å°†æ›´æ”¹ä¸ºæ¯ä¸ªåˆ†ç»„å®ä½“è®¡ç®—çš„åˆ†æ•°ã€‚å¯¹äº<code>&quot;simple&quot;</code>åˆ†æ•°åªæ˜¯ç»™å®šå®ä½“ä¸­æ¯ä¸ªæ ‡è®°çš„åˆ†æ•°çš„å¹³å‡å€¼ï¼šä¾‹å¦‚ï¼Œâ€œSylvainâ€çš„åˆ†æ•°æ˜¯æˆ‘ä»¬åœ¨å‰é¢çš„ç¤ºä¾‹ä¸­çœ‹åˆ°çš„æ ‡è®°<code>S</code> ã€ <code>##yl</code>åˆ†æ•°çš„å¹³å‡å€¼ã€ <code>##va</code>å’Œ<code>##in</code> ã€‚å…¶ä»–å¯ç”¨çš„ç­–ç•¥æœ‰ï¼š</p>
<ul>
<li><code>&quot;first&quot;</code>, å…¶ä¸­æ¯ä¸ªå®ä½“çš„åˆ†æ•°æ˜¯è¯¥å®ä½“çš„ç¬¬ä¸€ä¸ªæ ‡è®°çš„åˆ†æ•°ï¼ˆå› æ­¤å¯¹äºâ€œSylvainâ€ï¼Œå®ƒå°†æ˜¯ 0.993828ï¼Œæ ‡è®°çš„åˆ†æ•°)</li>
<li><code>&quot;max&quot;</code>,å…¶ä¸­æ¯ä¸ªå®ä½“çš„åˆ†æ•°æ˜¯è¯¥å®ä½“ä¸­æ ‡è®°çš„æœ€å¤§åˆ†æ•°ï¼ˆå› æ­¤å¯¹äºâ€œHugging Faceâ€ï¼Œå®ƒå°†æ˜¯ 0.98879766ï¼Œå³â€œFaceâ€çš„åˆ†æ•°ï¼‰</li>
<li><code>&quot;average&quot;</code>, å…¶ä¸­æ¯ä¸ªå®ä½“çš„åˆ†æ•°æ˜¯ç»„æˆè¯¥å®ä½“çš„å•è¯åˆ†æ•°çš„å¹³å‡å€¼ï¼Œå…¶ä¸­æ¯ä¸ªå®ä½“çš„åˆ†æ•°æ˜¯ç»„æˆè¯¥å®ä½“çš„å•è¯åˆ†æ•°çš„å¹³å‡å€¼ï¼ˆå› æ­¤å¯¹äºâ€œSylvainâ€ï¼Œä¸<code>&quot;simple&quot;</code>ç­–ç•¥æ²¡æœ‰åŒºåˆ«ï¼Œä½†â€œHugging Faceâ€çš„åˆ†æ•°ä¸º0.9819ï¼Œâ€œæ‹¥æŠ±â€å¾—åˆ†çš„å¹³å‡å€¼ï¼Œ0.975ï¼Œâ€œè„¸â€å¾—åˆ†çš„å¹³å‡å€¼ï¼Œ0.98879ï¼‰</li>
</ul>
<p>ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•åœ¨ä¸ä½¿ç”¨pipelineï¼ˆï¼‰å‡½æ•°çš„æƒ…å†µä¸‹è·å¾—è¿™äº›ç»“æœï¼</p>
<h4 id="ä»è¾“å…¥åˆ°é¢„æµ‹"><a class="markdownIt-Anchor" href="#ä»è¾“å…¥åˆ°é¢„æµ‹"></a> ä»è¾“å…¥åˆ°é¢„æµ‹</h4>
<p>é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æ ‡è®°æˆ‘ä»¬çš„è¾“å…¥å¹¶å°†å…¶ä¼ é€’ç»™æ¨¡å‹ã€‚è¿™æ˜¯å®Œå…¨æŒ‰ç…§<a target="_blank" rel="noopener" href="https://huggingface.co/course/chapter2">Chapter 2</a>;æˆ‘ä»¬ä½¿ç”¨ <strong>AutoXxx</strong> ç±»ï¼Œç„¶ååœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ä½¿ç”¨å®ƒä»¬ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForTokenClassification</span><br><span class="line"></span><br><span class="line">model_checkpoint = <span class="string">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)</span><br><span class="line">model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)</span><br><span class="line"></span><br><span class="line">example = <span class="string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span></span><br><span class="line">inputs = tokenizer(example, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">outputs = model(**inputs)</span><br></pre></td></tr></table></figure>
<p>ç”±äºæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨ <strong>AutoModelForTokenClassification</strong> åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸ºè¾“å…¥åºåˆ—ä¸­çš„æ¯ä¸ªæ ‡è®°è·å¾—ä¸€ç»„ logitsï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(inputs[<span class="string">&quot;input_ids&quot;</span>].shape)</span><br><span class="line"><span class="built_in">print</span>(outputs.logits.shape)</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">19</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">19</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure>
<p><font color="red">æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å« 19 ä¸ªæ ‡è®°çš„ 1 ä¸ªåºåˆ—çš„æ‰¹æ¬¡ï¼Œæ¨¡å‹æœ‰ 9 ä¸ªä¸åŒçš„æ ‡ç­¾ï¼Œå› æ­¤æ¨¡å‹çš„è¾“å‡ºå…·æœ‰ 1 x 19 x 9 çš„å½¢çŠ¶ã€‚</font>ä¸æ–‡æœ¬åˆ†ç±»ç®¡é“ä¸€æ ·ï¼Œæˆ‘ä»¬ä½¿ç”¨ softmax å‡½æ•°æ¥è½¬æ¢è¿™äº› logitsåˆ°æ¦‚ç‡ï¼Œæˆ‘ä»¬é‡‡ç”¨ argmax æ¥è·å¾—é¢„æµ‹ï¼ˆè¯·æ³¨æ„ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ logits ä¸Šé‡‡ç”¨ argmaxï¼Œå› ä¸º softmax ä¸ä¼šæ”¹å˜é¡ºåºï¼‰ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">probabilities = torch.nn.functional.softmax(outputs.logits, dim=-<span class="number">1</span>)[<span class="number">0</span>].tolist() <span class="comment"># (19,9)</span></span><br><span class="line"></span><br><span class="line">predictions = outputs.logits.argmax(dim=-<span class="number">1</span>)[<span class="number">0</span>].tolist() <span class="comment">#(19,1)</span></span><br><span class="line"><span class="built_in">print</span>(predictions)</span><br><span class="line"></span><br><span class="line">[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>model.config.id2label</strong> å±æ€§åŒ…å«ç´¢å¼•åˆ°æ ‡ç­¾çš„æ˜ å°„ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥ç†è§£é¢„æµ‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model.config.id2label</span><br><span class="line">&#123;<span class="number">0</span>: <span class="string">&#x27;O&#x27;</span>,</span><br><span class="line"><span class="number">1</span>: <span class="string">&#x27;B-MISC&#x27;</span>,</span><br><span class="line"><span class="number">2</span>: <span class="string">&#x27;I-MISC&#x27;</span>,</span><br><span class="line"><span class="number">3</span>: <span class="string">&#x27;B-PER&#x27;</span>,</span><br><span class="line"><span class="number">4</span>: <span class="string">&#x27;I-PER&#x27;</span>,</span><br><span class="line"><span class="number">5</span>: <span class="string">&#x27;B-ORG&#x27;</span>,</span><br><span class="line"><span class="number">6</span>: <span class="string">&#x27;I-ORG&#x27;</span>,</span><br><span class="line"><span class="number">7</span>: <span class="string">&#x27;B-LOC&#x27;</span>,</span><br><span class="line"><span class="number">8</span>: <span class="string">&#x27;I-LOC&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>æ­£å¦‚æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ï¼Œæœ‰ 9 ä¸ªæ ‡ç­¾ï¼š <strong>O</strong> æ˜¯ä¸åœ¨ä»»ä½•å‘½åå®ä½“ä¸­çš„æ ‡è®°çš„æ ‡ç­¾ï¼ˆå®ƒä»£è¡¨â€œå¤–éƒ¨â€ï¼‰ï¼Œç„¶åæˆ‘ä»¬ä¸ºæ¯ç§ç±»å‹çš„å®ä½“ï¼ˆæ‚é¡¹ã€äººå‘˜ã€ç»„ç»‡å’Œä½ç½®ï¼‰æä¾›ä¸¤ä¸ªæ ‡ç­¾ã€‚æ ‡ç­¾ <strong>B-XXX</strong> è¡¨ç¤ºä»¤ç‰Œåœ¨å®ä½“çš„å¼€å¤´ <strong>XXX</strong> å’Œæ ‡ç­¾ <strong>I-XXX</strong> è¡¨ç¤ºä»¤ç‰Œåœ¨å®ä½“å†… <strong>XXX</strong> ã€‚<font color="red">ä¾‹å¦‚ï¼Œåœ¨å½“å‰ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„æ¨¡å‹å¯¹ä»¤ç‰Œè¿›è¡Œåˆ†ç±» <strong>S</strong> ä½œä¸º <strong>B-PER</strong> ï¼ˆä¸€ä¸ªäººå®ä½“çš„å¼€å§‹ï¼‰å’Œä»¤ç‰Œ <strong>##yl</strong> , <strong>##va</strong> å’Œ <strong>##in</strong> ä½œä¸º <strong>I-PER</strong> ï¼ˆåœ¨ä¸ªäººå®ä½“å†…ï¼‰</font></p>
<p><font color="red">åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½è®¤ä¸ºæ¨¡å‹æ˜¯é”™è¯¯çš„ï¼Œå› ä¸ºå®ƒç»™å‡ºäº†æ ‡ç­¾ <strong>I-PER</strong> å¯¹æ‰€æœ‰è¿™å››ä¸ªä»¤ç‰Œï¼Œä½†è¿™å¹¶ä¸å®Œå…¨æ­£ç¡®ã€‚å®é™…ä¸Šæœ‰ä¸¤ç§æ ¼å¼ <strong>B-</strong> å’Œ <strong>I-</strong> æ ‡ç­¾ï¼š<strong>IOB1</strong>å’Œ<strong>IOB2</strong>ã€‚<strong>IOB2</strong> æ ¼å¼ï¼ˆä¸‹é¢ç²‰çº¢è‰²ï¼‰æ˜¯æˆ‘ä»¬ä»‹ç»çš„æ ¼å¼ï¼Œè€Œåœ¨ <strong>IOB1</strong> æ ¼å¼ï¼ˆè“è‰²ï¼‰ä¸­ï¼Œæ ‡ç­¾ä»¥ <strong>B-</strong> ä»…ç”¨äºåˆ†éš”ç›¸åŒç±»å‹çš„ä¸¤ä¸ªç›¸é‚»å®ä½“ã€‚æˆ‘ä»¬ä½¿ç”¨çš„æ¨¡å‹åœ¨ä½¿ç”¨è¯¥æ ¼å¼çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¾®è°ƒï¼Œè¿™å°±æ˜¯å®ƒåˆ†é…æ ‡ç­¾çš„åŸå›  <strong>I-PER</strong> åˆ° <strong>S</strong> ä»¤ç‰Œã€‚</font></p>
<p><img src="en_chapter6_IOB_versions.svg" alt></p>
<p>æœ‰äº†è¿™å¼ åœ°å›¾ï¼Œæˆ‘ä»¬å·²ç»å‡†å¤‡å¥½ï¼ˆå‡ ä¹å®Œå…¨ï¼‰é‡ç°ç¬¬ä¸€ä¸ªç®¡é“çš„ç»“æœâ€”â€”æˆ‘ä»¬å¯ä»¥è·å–æ¯ä¸ªæœªè¢«å½’ç±»ä¸ºçš„æ ‡è®°çš„åˆ†æ•°å’Œæ ‡ç­¾ <strong>O</strong> ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">results = []</span><br><span class="line">tokens = inputs.tokens()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(predictions):</span><br><span class="line">    label = model.config.id2label[pred]</span><br><span class="line">    <span class="keyword">if</span> label != <span class="string">&quot;O&quot;</span>:</span><br><span class="line">        results.append(</span><br><span class="line">            &#123;<span class="string">&quot;entity&quot;</span>: label, <span class="string">&quot;score&quot;</span>: probabilities[idx][pred], <span class="string">&quot;index&quot;</span>:idx, word<span class="string">&quot;: tokens[idx]&#125;</span></span><br><span class="line"><span class="string">        )</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">print(results)</span></span><br><span class="line"><span class="string">[&#123;&#x27;entity&#x27;: &#x27;I-PER&#x27;, &#x27;score&#x27;: 0.9993828, &#x27;index&#x27;: 4, &#x27;word&#x27;: &#x27;S&#x27;&#125;,</span></span><br><span class="line"><span class="string"> &#123;&#x27;entity&#x27;: &#x27;I-PER&#x27;, &#x27;score&#x27;: 0.99815476, &#x27;index&#x27;: 5, &#x27;word&#x27;: &#x27;##yl&#x27;&#125;,</span></span><br><span class="line"><span class="string"> &#123;&#x27;entity&#x27;: &#x27;I-PER&#x27;, &#x27;score&#x27;: 0.99590725, &#x27;index&#x27;: 6, &#x27;word&#x27;: &#x27;##va&#x27;&#125;,</span></span><br><span class="line"><span class="string"> &#123;&#x27;entity&#x27;: &#x27;I-PER&#x27;, &#x27;score&#x27;: 0.9992327, &#x27;index&#x27;: 7, &#x27;word&#x27;: &#x27;##in&#x27;&#125;,</span></span><br><span class="line"><span class="string"> &#123;&#x27;entity&#x27;: &#x27;I-ORG&#x27;, &#x27;score&#x27;: 0.97389334, &#x27;index&#x27;: 12, &#x27;word&#x27;: &#x27;Hu&#x27;&#125;,</span></span><br><span class="line"><span class="string"> &#123;&#x27;entity&#x27;: &#x27;I-ORG&#x27;, &#x27;score&#x27;: 0.976115, &#x27;index&#x27;: 13, &#x27;word&#x27;: &#x27;##gging&#x27;&#125;,</span></span><br><span class="line"><span class="string"> &#123;&#x27;entity&#x27;: &#x27;I-ORG&#x27;, &#x27;score&#x27;: 0.98879766, &#x27;index&#x27;: 14, &#x27;word&#x27;: &#x27;Face&#x27;&#125;,</span></span><br><span class="line"><span class="string"> &#123;&#x27;entity&#x27;: &#x27;I-LOC&#x27;, &#x27;score&#x27;: 0.99321055, &#x27;index&#x27;: 16, &#x27;word&#x27;: &#x27;Brooklyn&#x27;&#125;]</span></span><br></pre></td></tr></table></figure>
<p>è¿™ä¸æˆ‘ä»¬ä¹‹å‰çš„æƒ…å†µéå¸¸ç›¸ä¼¼ï¼Œåªæœ‰ä¸€ä¸ªä¾‹å¤–ï¼šç®¡é“è¿˜ä¸ºæˆ‘ä»¬æä¾›äº†æœ‰å…³ <strong>start</strong> å’Œ <strong>end</strong> åŸå§‹å¥å­ä¸­çš„æ¯ä¸ªå®ä½“ã€‚è¿™æ˜¯æˆ‘ä»¬çš„åç§»æ˜ å°„å°†å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚è¦è·å¾—åç§»é‡ï¼Œæˆ‘ä»¬åªéœ€è¦è®¾ç½® <strong>return_offsets_mapping=True</strong> å½“æˆ‘ä»¬å°†åˆ†è¯å™¨åº”ç”¨äºæˆ‘ä»¬çš„è¾“å…¥æ—¶ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">inputs_with_offsets = tokenizer(example, return_offsets_mapping=<span class="literal">True</span>)</span><br><span class="line">inputs_with_offsets[<span class="string">&quot;offset_mapping&quot;</span>]</span><br><span class="line"></span><br><span class="line">[(<span class="number">0</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">2</span>), (<span class="number">3</span>, <span class="number">7</span>), (<span class="number">8</span>, <span class="number">10</span>), (<span class="number">11</span>, <span class="number">12</span>), (<span class="number">12</span>, <span class="number">14</span>), (<span class="number">14</span>, <span class="number">16</span>), (<span class="number">16</span>, <span class="number">18</span>), (<span class="number">19</span>, <span class="number">22</span>), (<span class="number">23</span>, <span class="number">24</span>), (<span class="number">25</span>, <span class="number">29</span>), (<span class="number">30</span>, <span class="number">32</span>),</span><br><span class="line"> (<span class="number">33</span>, <span class="number">35</span>), (<span class="number">35</span>, <span class="number">40</span>), (<span class="number">41</span>, <span class="number">45</span>), (<span class="number">46</span>, <span class="number">48</span>), (<span class="number">49</span>, <span class="number">57</span>), (<span class="number">57</span>, <span class="number">58</span>), (<span class="number">0</span>, <span class="number">0</span>)]</span><br></pre></td></tr></table></figure>
<p>æ¯ä¸ªå…ƒç»„æ˜¯å¯¹åº”äºæ¯ä¸ªæ ‡è®°çš„æ–‡æœ¬è·¨åº¦ï¼Œå…¶ä¸­ <strong>(0, 0)</strong> ä¿ç•™ç”¨äºç‰¹æ®Šä»¤ç‰Œã€‚æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°ç´¢å¼• 5 å¤„çš„ä»¤ç‰Œæ˜¯ <strong>##yl</strong> ï¼Œ å…¶ä¸­æœ‰ <strong>(12, 14)</strong> ä½œä¸ºè¿™é‡Œçš„æŠµæ¶ˆã€‚å¦‚æœæˆ‘ä»¬åœ¨ç¤ºä¾‹ä¸­æŠ“å–ç›¸åº”çš„åˆ‡ç‰‡ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">example[<span class="number">12</span>:<span class="number">14</span>]</span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬å¾—åˆ°äº†æ­£ç¡®çš„æ–‡æœ¬è·¨åº¦ï¼Œè€Œæ²¡æœ‰ <strong>##</strong> ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yl</span><br></pre></td></tr></table></figure>
<p>ä½¿ç”¨è¿™ä¸ªï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥å®Œæˆä¹‹å‰çš„ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">results = []</span><br><span class="line">inputs_with_offsets = tokenizer(example, return_offsets_mapping=<span class="literal">True</span>)</span><br><span class="line">tokens = inputs_with_offsets.tokens()</span><br><span class="line">offsets = inputs_with_offsets[<span class="string">&quot;offset_mapping&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(predictions):</span><br><span class="line">    label = model.config.id2label[pred]</span><br><span class="line">    <span class="keyword">if</span> label != <span class="string">&quot;O&quot;</span>:</span><br><span class="line">        start, end = offsets[idx]</span><br><span class="line">        results.append(</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;entity&quot;</span>: label,</span><br><span class="line">                <span class="string">&quot;score&quot;</span>: probabilities[idx][pred],</span><br><span class="line">                <span class="string">&quot;word&quot;</span>: tokens[idx],</span><br><span class="line">                <span class="string">&quot;start&quot;</span>: start,</span><br><span class="line">                <span class="string">&quot;end&quot;</span>: end,</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(results)</span><br><span class="line">[&#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-PER&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.9993828</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">11</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">12</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-PER&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.99815476</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;##yl&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">12</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">14</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-PER&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.99590725</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;##va&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">14</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">16</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-PER&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.9992327</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;##in&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">18</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-ORG&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.97389334</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">12</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;Hu&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">33</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">35</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-ORG&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.976115</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">13</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;##gging&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">35</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">40</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-ORG&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.98879766</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">14</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;Face&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">41</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">45</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity&#x27;</span>: <span class="string">&#x27;I-LOC&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.99321055</span>, <span class="string">&#x27;index&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;Brooklyn&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">49</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">57</span>&#125;]</span><br></pre></td></tr></table></figure>
<p>è¿™å’Œæˆ‘ä»¬ä»ç¬¬ä¸€ä¸ªç®¡é“ä¸­å¾—åˆ°çš„ä¸€æ ·ï¼</p>
<h4 id="åˆ†ç»„å®ä½“"><a class="markdownIt-Anchor" href="#åˆ†ç»„å®ä½“"></a> åˆ†ç»„å®ä½“</h4>
<p><font color="red">ä½¿ç”¨åç§»é‡æ¥ç¡®å®šæ¯ä¸ªå®ä½“çš„å¼€å§‹å’Œç»“æŸé”®å¾ˆæ–¹ä¾¿ï¼Œä½†è¯¥ä¿¡æ¯å¹¶ä¸æ˜¯ç»å¯¹å¿…è¦çš„ã€‚ç„¶è€Œï¼Œå½“æˆ‘ä»¬æƒ³è¦å°†å®ä½“ç»„åˆåœ¨ä¸€èµ·æ—¶ï¼Œåç§»é‡å°†ä¸ºæˆ‘ä»¬èŠ‚çœå¤§é‡æ··ä¹±çš„ä»£ç ã€‚</font>å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦å°†æ ‡è®°<code>Hu</code> ã€ <code>##gging</code>å’Œ<code>Face</code>ç»„åˆåœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬å¯ä»¥åˆ¶å®šç‰¹æ®Šè§„åˆ™ï¼Œè§„å®šåœ¨åˆ é™¤<code>##</code>æ—¶åº”é™„åŠ å‰ä¸¤ä¸ªæ ‡è®°ï¼Œå¹¶ä¸”åº”åœ¨<code>Face</code>ä¸Šæ·»åŠ ä¸€ä¸ªç©ºæ ¼ï¼Œå› ä¸ºå®ƒä¸ä»¥<code>##</code>å¼€å¤´ â€” ä½†è¿™ä»…é€‚ç”¨äºè¿™ç§ç‰¹å®šç±»å‹çš„åˆ†è¯å™¨ã€‚æˆ‘ä»¬å¿…é¡»ä¸º SentencePiece æˆ–å­—èŠ‚å¯¹ç¼–ç åˆ†è¯å™¨ç¼–å†™å¦ä¸€ç»„è§„åˆ™ï¼ˆæœ¬ç« ç¨åè®¨è®ºï¼‰ã€‚</p>
<p>æœ‰äº†åç§»é‡ï¼Œæ‰€æœ‰è‡ªå®šä¹‰ä»£ç éƒ½ä¼šæ¶ˆå¤±ï¼šæˆ‘ä»¬åªéœ€è·å–åŸå§‹æ–‡æœ¬ä¸­ä»ç¬¬ä¸€ä¸ªæ ‡è®°å¼€å§‹åˆ°æœ€åä¸€ä¸ªæ ‡è®°ç»“æŸçš„èŒƒå›´ã€‚å› æ­¤ï¼Œå¯¹äºæ ‡è®°<code>Hu</code> ã€ <code>##gging</code>å’Œ<code>Face</code> ï¼Œæˆ‘ä»¬åº”è¯¥ä»å­—ç¬¦ 33 ï¼ˆ <code>Hu</code>çš„å¼€å¤´ï¼‰å¼€å§‹ï¼Œå¹¶åœ¨å­—ç¬¦ 45 ï¼ˆ <code>Face</code>çš„ç»“å°¾ï¼‰ä¹‹å‰ç»“æŸï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">example[<span class="number">33</span>:<span class="number">45</span>]</span><br><span class="line"></span><br><span class="line">Hugging Face</span><br></pre></td></tr></table></figure>
<p>ä¸ºäº†ç¼–å†™åœ¨å¯¹å®ä½“è¿›è¡Œåˆ†ç»„æ—¶å¯¹é¢„æµ‹è¿›è¡Œåå¤„ç†çš„ä»£ç ï¼Œæˆ‘ä»¬å°†æŠŠè¿ç»­å¹¶æ ‡è®°ä¸º<code>I-XXX</code>çš„å®ä½“åˆ†ç»„åœ¨ä¸€èµ·ï¼Œç¬¬ä¸€ä¸ªå®ä½“é™¤å¤–ï¼Œå®ƒå¯ä»¥æ ‡è®°ä¸º<code>B-XXX</code>æˆ–<code>I-XXX</code> ï¼ˆå› æ­¤ï¼Œå½“æˆ‘ä»¬å¾—åˆ°<code>O</code> ï¼ˆä¸€ç§æ–°ç±»å‹çš„å®ä½“ï¼‰æˆ–<code>B-XXX</code> ï¼ˆå‘Šè¯‰æˆ‘ä»¬ç›¸åŒç±»å‹çš„å®ä½“æ­£åœ¨å¯åŠ¨ï¼‰æ—¶ï¼Œæˆ‘ä»¬åœæ­¢å¯¹å®ä½“è¿›è¡Œåˆ†ç»„ï¼‰ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">results = []</span><br><span class="line">inputs_with_offsets = tokenizer(example, return_offsets_mapping=<span class="literal">True</span>)</span><br><span class="line">tokens = inputs_with_offsets.tokens()</span><br><span class="line">offsets = inputs_with_offsets[<span class="string">&quot;offset_mapping&quot;</span>]</span><br><span class="line"></span><br><span class="line">idx = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> idx &lt; <span class="built_in">len</span>(predictions):</span><br><span class="line">    pred = predictions[idx]</span><br><span class="line">    label = model.config.id2label[pred]</span><br><span class="line">    <span class="keyword">if</span> label != <span class="string">&quot;O&quot;</span>:</span><br><span class="line">        <span class="comment"># Remove the B- or I-</span></span><br><span class="line">        label = label[<span class="number">2</span>:]</span><br><span class="line">        start, _ = offsets[idx]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Grab all the tokens labeled with I-label</span></span><br><span class="line">        all_scores = []</span><br><span class="line">        <span class="keyword">while</span> (</span><br><span class="line">            idx &lt; <span class="built_in">len</span>(predictions)</span><br><span class="line">            <span class="keyword">and</span> model.config.id2label[predictions[idx]] == <span class="string">f&quot;I-<span class="subst">&#123;label&#125;</span>&quot;</span></span><br><span class="line">        ):</span><br><span class="line">            all_scores.append(probabilities[idx][pred])</span><br><span class="line">            _, end = offsets[idx]</span><br><span class="line">            idx += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># The score is the mean of all the scores of the tokens in that grouped entity</span></span><br><span class="line">        score = np.mean(all_scores).item()</span><br><span class="line">        word = example[start:end]</span><br><span class="line">        results.append(</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;entity_group&quot;</span>: label,</span><br><span class="line">                <span class="string">&quot;score&quot;</span>: score,</span><br><span class="line">                <span class="string">&quot;word&quot;</span>: word,</span><br><span class="line">                <span class="string">&quot;start&quot;</span>: start,</span><br><span class="line">                <span class="string">&quot;end&quot;</span>: end,</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">    idx += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(results)</span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬å¾—åˆ°äº†ä¸ç¬¬äºŒæ¡ç®¡é“ç›¸åŒçš„ç»“æœï¼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="string">&#x27;entity_group&#x27;</span>: <span class="string">&#x27;PER&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.9981694</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;Sylvain&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">11</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">18</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity_group&#x27;</span>: <span class="string">&#x27;ORG&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.97960204</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;Hugging Face&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">33</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">45</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity_group&#x27;</span>: <span class="string">&#x27;LOC&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.99321055</span>, <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;Brooklyn&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">49</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">57</span>&#125;]</span><br></pre></td></tr></table></figure>
<p>è¿™äº›åç§»é‡éå¸¸æœ‰ç”¨çš„å¦ä¸€ä¸ªä»»åŠ¡ç¤ºä¾‹æ˜¯é—®ç­”ã€‚æ·±å…¥ç ”ç©¶è¿™ä¸ªç®¡é“ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­è¿›è¡Œï¼Œä¹Ÿå°†ä½¿æˆ‘ä»¬èƒ½å¤Ÿäº†è§£ ğŸ¤— Transformers åº“ä¸­æ ‡è®°å™¨çš„æœ€åä¸€ä¸ªåŠŸèƒ½ï¼š<font color="red">å½“æˆ‘ä»¬å°†è¾“å…¥æˆªæ–­ä¸ºç»™å®šé•¿åº¦æ—¶å¤„ç†æº¢å‡ºçš„æ ‡è®°ã€‚</font></p>
<h2 id="qa-ç®¡é“ä¸­çš„å¿«é€Ÿæ ‡è®°å™¨"><a class="markdownIt-Anchor" href="#qa-ç®¡é“ä¸­çš„å¿«é€Ÿæ ‡è®°å™¨"></a> QA ç®¡é“ä¸­çš„å¿«é€Ÿæ ‡è®°å™¨</h2>
<h3 id="1-ä½¿ç”¨é—®ç­”ç®¡é“"><a class="markdownIt-Anchor" href="#1-ä½¿ç”¨é—®ç­”ç®¡é“"></a> 1. ä½¿ç”¨é—®ç­”ç®¡é“</h3>
<p>æ­£å¦‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/course/chapter1">ç¬¬ 1 ç« </a>ä¸­çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™æ ·çš„<code>question-answering</code>ç®¡é“æ¥è·å–é—®é¢˜çš„ç­”æ¡ˆï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">question_answerer = pipeline(<span class="string">&quot;question-answering&quot;</span>)</span><br><span class="line">context = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">ğŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch, and TensorFlow â€” with a seamless integration</span></span><br><span class="line"><span class="string">between them. It&#x27;s straightforward to train your models with one before loading them for inference with the other.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">question = <span class="string">&quot;Which deep learning libraries back ğŸ¤— Transformers?&quot;</span></span><br><span class="line">question_answerer(question=question, context=context)</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;score&#x27;</span>: <span class="number">0.97773</span>,</span><br><span class="line"> <span class="string">&#x27;start&#x27;</span>: <span class="number">78</span>,</span><br><span class="line"> <span class="string">&#x27;end&#x27;</span>: <span class="number">105</span>,</span><br><span class="line"> <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;Jax, PyTorch and TensorFlow&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<p><font color="red">ä¸å…¶ä»–ç®¡é“ä¸åŒï¼Œå…¶ä»–ç®¡é“æ— æ³•æˆªæ–­å’Œåˆ†å‰²é•¿äºæ¨¡å‹æ¥å—çš„æœ€å¤§é•¿åº¦çš„æ–‡æœ¬ï¼ˆå› æ­¤å¯èƒ½ä¼šä¸¢å¤±æ–‡æ¡£æœ«å°¾çš„ä¿¡æ¯ï¼‰ï¼Œè¯¥ç®¡é“å¯ä»¥å¤„ç†éå¸¸é•¿çš„ä¸Šä¸‹æ–‡ï¼Œå¹¶å°†è¿”å›å›ç­”é—®é¢˜ï¼Œå³ä½¿å®ƒåœ¨æœ€åï¼š</font></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">long_context = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">ğŸ¤— Transformers: State of the Art NLP</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ğŸ¤— Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,</span></span><br><span class="line"><span class="string">question answering, summarization, translation, text generation and more in over 100 languages.</span></span><br><span class="line"><span class="string">Its aim is to make cutting-edge NLP easier to use for everyone.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ğŸ¤— Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and</span></span><br><span class="line"><span class="string">then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and</span></span><br><span class="line"><span class="string">can be modified to enable quick research experiments.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Why should I use transformers?</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. Easy-to-use state-of-the-art models:</span></span><br><span class="line"><span class="string">  - High performance on NLU and NLG tasks.</span></span><br><span class="line"><span class="string">  - Low barrier to entry for educators and practitioners.</span></span><br><span class="line"><span class="string">  - Few user-facing abstractions with just three classes to learn.</span></span><br><span class="line"><span class="string">  - A unified API for using all our pretrained models.</span></span><br><span class="line"><span class="string">  - Lower compute costs, smaller carbon footprint:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">2. Researchers can share trained models instead of always retraining.</span></span><br><span class="line"><span class="string">  - Practitioners can reduce compute time and production costs.</span></span><br><span class="line"><span class="string">  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">3. Choose the right framework for every part of a model&#x27;s lifetime:</span></span><br><span class="line"><span class="string">  - Train state-of-the-art models in 3 lines of code.</span></span><br><span class="line"><span class="string">  - Move a single model between TF2.0/PyTorch frameworks at will.</span></span><br><span class="line"><span class="string">  - Seamlessly pick the right framework for training, evaluation and production.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">4. Easily customize a model or an example to your needs:</span></span><br><span class="line"><span class="string">  - We provide examples for each architecture to reproduce the results published by its original authors.</span></span><br><span class="line"><span class="string">  - Model internals are exposed as consistently as possible.</span></span><br><span class="line"><span class="string">  - Model files can be used independently of the library for quick experiments.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ğŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration</span></span><br><span class="line"><span class="string">between them. It&#x27;s straightforward to train your models with one before loading them for inference with the other.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">question_answerer(question=question, context=long_context)</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;score&#x27;</span>: <span class="number">0.97149</span>,</span><br><span class="line"> <span class="string">&#x27;start&#x27;</span>: <span class="number">1892</span>,</span><br><span class="line"> <span class="string">&#x27;end&#x27;</span>: <span class="number">1919</span>,</span><br><span class="line"> <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;Jax, PyTorch and TensorFlow&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2ä½¿ç”¨æ¨¡å‹è¿›è¡Œé—®ç­”"><a class="markdownIt-Anchor" href="#2ä½¿ç”¨æ¨¡å‹è¿›è¡Œé—®ç­”"></a> 2.ä½¿ç”¨æ¨¡å‹è¿›è¡Œé—®ç­”</h3>
<p>ä¸ä»»ä½•å…¶ä»–ç®¡é“ä¸€æ ·ï¼Œæˆ‘ä»¬é¦–å…ˆå¯¹è¾“å…¥è¿›è¡Œæ ‡è®°ï¼Œç„¶åé€šè¿‡æ¨¡å‹å‘é€å®ƒã€‚ <code>question-answering</code>ç®¡é“é»˜è®¤ä½¿ç”¨çš„æ£€æŸ¥ç‚¹æ˜¯ <a target="_blank" rel="noopener" href="https://huggingface.co/distilbert-base-cased-distilled-squad">distilbert-base-cased-distilled-squad</a> ï¼ˆåç§°ä¸­çš„â€œsquadâ€æ¥è‡ªæ¨¡å‹å¾®è°ƒçš„æ•°æ®é›†ï¼›æˆ‘ä»¬å°†åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/course/chapter7/7">ç¬¬ 7 ç« </a>ä¸­è¯¦ç»†è®¨è®º SQuAD æ•°æ®é›†ï¼‰ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForQuestionAnswering</span><br><span class="line"></span><br><span class="line">model_checkpoint = <span class="string">&quot;distilbert-base-cased-distilled-squad&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)</span><br><span class="line">model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)</span><br><span class="line"></span><br><span class="line">inputs = tokenizer(question, context, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">outputs = model(**inputs)</span><br></pre></td></tr></table></figure>
<p><font size="5">å±è”½äº†ä¸æˆ‘ä»¬ä¸æƒ³é¢„æµ‹çš„ä½ç½®ç›¸å¯¹åº”çš„ logits</font></p>
<p>è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å°†é—®é¢˜å’Œä¸Šä¸‹æ–‡æ ‡è®°ä¸ºä¸€å¯¹ï¼Œé¦–å…ˆæ˜¯é—®é¢˜ã€‚</p>
<p><img src="en_chapter6_question_tokens.svg" alt></p>
<p>é—®ç­”æ¨¡å‹çš„å·¥ä½œåŸç†ä¸æˆ‘ä»¬è¿„ä»Šä¸ºæ­¢çœ‹åˆ°çš„æ¨¡å‹ç•¥æœ‰ä¸åŒã€‚<font color="red">ä»¥ä¸Šå›¾ä¸ºä¾‹ï¼Œæ¨¡å‹ç»è¿‡è®­ç»ƒå¯ä»¥é¢„æµ‹ç­”æ¡ˆå¼€å§‹çš„tokenç´¢å¼•ï¼ˆæ­¤å¤„ä¸º 21ï¼‰å’Œç­”æ¡ˆç»“æŸå¤„çš„æ ‡è®°ç´¢å¼•ï¼ˆæ­¤å¤„ä¸º 24ï¼‰ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆè¿™äº›æ¨¡å‹ä¸è¿”å›ä¸€ä¸ª logits å¼ é‡ï¼Œè€Œæ˜¯è¿”å›ä¸¤ä¸ªï¼šä¸€ä¸ªç”¨äºå¯¹åº”äºç­”æ¡ˆçš„å¼€å§‹æ ‡è®°çš„ logitsï¼Œå¦ä¸€ä¸ªç”¨äºå¯¹åº”äºç­”æ¡ˆçš„ç»“æŸæ ‡è®°çš„ logitsã€‚</font>ç”±äºåœ¨æœ¬ä¾‹ä¸­æˆ‘ä»¬åªæœ‰ä¸€ä¸ªåŒ…å« 66 ä¸ªæ ‡è®°çš„è¾“å…¥ï¼Œå› æ­¤æˆ‘ä»¬å¾—åˆ°ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">start_logits = outputs.start_logits</span><br><span class="line">end_logits = outputs.end_logits</span><br><span class="line"><span class="built_in">print</span>(start_logits.shape, end_logits.shape)</span><br><span class="line"></span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">66</span>]) torch.Size([<span class="number">1</span>, <span class="number">66</span>])</span><br></pre></td></tr></table></figure>
<p><font color="red">ä¸ºäº†å°†è¿™äº› logits è½¬æ¢ä¸ºæ¦‚ç‡ï¼Œæˆ‘ä»¬å°†åº”ç”¨ä¸€ä¸ª softmax å‡½æ•° - ä½†åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿å±è”½ä¸å±äºä¸Šä¸‹æ–‡çš„ç´¢å¼•ã€‚æˆ‘ä»¬çš„è¾“å…¥æ˜¯ <code>[CLS] question [SEP] context [SEP]</code> ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å±è”½é—®é¢˜çš„æ ‡è®°ä»¥åŠ<code>[SEP]</code>æ ‡è®°ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å°†ä¿ç•™<code>[CLS]</code>æ ‡è®°ï¼Œå› ä¸ºæŸäº›æ¨¡å‹ä½¿ç”¨å®ƒæ¥æŒ‡ç¤ºç­”æ¡ˆä¸åœ¨ä¸Šä¸‹æ–‡ä¸­ã€‚</font></p>
<p><font color="red">ç”±äºæˆ‘ä»¬éšåå°†åº”ç”¨ softmaxï¼Œå› æ­¤æˆ‘ä»¬åªéœ€è¦å°†è¦å±è”½çš„ logits æ›¿æ¢ä¸ºä¸€ä¸ªå¤§çš„è´Ÿæ•°å³å¯ã€‚</font>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨<code>-10000</code> ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">sequence_ids = inputs.sequence_ids() <span class="comment"># è¡¨ç¤ºä¸æ¯ä¸ªæ ‡è®°å…³è”çš„è¾“å…¥åºåˆ—çš„ç´¢å¼•,[CLS]ä¸[SEP]çš„ç´¢å¼•æ˜¯None</span></span><br><span class="line"><span class="comment"># Mask everything apart from the tokens of the context</span></span><br><span class="line">mask = [i != <span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> sequence_ids]</span><br><span class="line"><span class="comment"># Unmask the [CLS] token</span></span><br><span class="line">mask[<span class="number">0</span>] = <span class="literal">False</span></span><br><span class="line">mask = torch.tensor(mask)[<span class="literal">None</span>]</span><br><span class="line"></span><br><span class="line">start_logits[mask] = -<span class="number">10000</span></span><br><span class="line">end_logits[mask] = -<span class="number">10000</span></span><br></pre></td></tr></table></figure>
<p>ç°åœ¨æˆ‘ä»¬å·²ç»æ­£ç¡®å±è”½äº†ä¸æˆ‘ä»¬ä¸æƒ³é¢„æµ‹çš„ä½ç½®ç›¸å¯¹åº”çš„ logitsï¼Œæˆ‘ä»¬å¯ä»¥åº”ç”¨ softmaxï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start_probabilities = torch.nn.functional.softmax(start_logits, dim=-<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">end_probabilities = torch.nn.functional.softmax(end_logits, dim=-<span class="number">1</span>)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p><font color="red">åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨å¼€å§‹å’Œç»“æŸæ¦‚ç‡çš„ argmaxï¼Œä½†æˆ‘ä»¬æœ€ç»ˆå¯èƒ½ä¼šå¾—åˆ°ä¸€ä¸ªå¤§äºç»“æŸç´¢å¼•çš„å¼€å§‹ç´¢å¼•ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦é‡‡å–æ›´å¤šé¢„é˜²æªæ–½:</font>æˆ‘ä»¬å°†è®¡ç®—æ¯ä¸ªå¯èƒ½çš„<code>start_index</code>å’Œ<code>end_index</code>çš„æ¦‚ç‡ï¼Œå…¶ä¸­<code>start_index &lt;= end_index</code> ï¼Œç„¶åé‡‡ç”¨æ¦‚ç‡æœ€é«˜çš„å…ƒç»„<code>(start_index, end_index)</code> ã€‚</p>
<blockquote>
<p>å‡è®¾äº‹ä»¶â€œç­”æ¡ˆä»<code>start_index</code>å¼€å§‹â€å’Œâ€œç­”æ¡ˆåœ¨<code>end_index</code>ç»“æŸâ€æ˜¯ç‹¬ç«‹çš„ï¼Œåˆ™ç­”æ¡ˆä»<code>start_index</code>å¼€å§‹å¹¶åœ¨<code>end_index</code>ç»“æŸçš„æ¦‚ç‡ä¸ºï¼š</p>
<center>start_probabilities[start_index]Ã—end_probabilities[end_index]</center>
<p>å› æ­¤ï¼Œè¦è®¡ç®—æ‰€æœ‰åˆ†æ•°ï¼Œæˆ‘ä»¬åªéœ€è¦è®¡ç®—æ‰€æœ‰ä¹˜ç§¯**start_probabilities[start_index]Ã—end_probabilities[end_index]**å…¶ä¸­<code>start_index &lt;= end_index</code> ã€‚</p>
</blockquote>
<p>é¦–å…ˆè®©æˆ‘ä»¬è®¡ç®—æ‰€æœ‰å¯èƒ½çš„äº§å“ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scores = start_probabilities[:, <span class="literal">None</span>] * end_probabilities[<span class="literal">None</span>, :]</span><br></pre></td></tr></table></figure>
<p>ç„¶åæˆ‘ä»¬å°†<code>start_index &gt; end_index</code>çš„å€¼è®¾ç½®ä¸º<code>0</code> ï¼ˆå…¶ä»–æ¦‚ç‡å‡ä¸ºæ­£æ•°ï¼‰æ¥å±è”½å®ƒä»¬ã€‚ <code>torch.triu()</code>å‡½æ•°è¿”å›ä½œä¸ºå‚æ•°ä¼ é€’çš„ 2D å¼ é‡çš„ä¸Šä¸‰è§’éƒ¨åˆ†ï¼Œå› æ­¤å®ƒå°†ä¸ºæˆ‘ä»¬è¿›è¡Œæ©è”½ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scores = torch.triu(scores)</span><br></pre></td></tr></table></figure>
<p>ç°åœ¨æˆ‘ä»¬åªéœ€è¦è·å–æœ€å¤§å€¼çš„ç´¢å¼•å³å¯ã€‚ç”±äº PyTorch å°†è¿”å›å±•å¹³å¼ é‡ä¸­çš„ç´¢å¼•ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä½¿ç”¨å‘ä¸‹é™¤æ³•<code>//</code>å’Œæ¨¡<code>%</code>è¿ç®—æ¥è·å–<code>start_index</code>å’Œ<code>end_index</code> ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">max_index = scores.argmax().item()</span><br><span class="line">start_index = max_index // scores.shape[<span class="number">1</span>]</span><br><span class="line">end_index = max_index % scores.shape[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(scores[start_index, end_index])</span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬è¿˜æ²¡æœ‰å®Œå…¨å®Œæˆï¼Œä½†è‡³å°‘æˆ‘ä»¬å·²ç»æœ‰äº†ç­”æ¡ˆçš„æ­£ç¡®åˆ†æ•°ï¼ˆæ‚¨å¯ä»¥é€šè¿‡å°†å…¶ä¸ä¸Šä¸€èŠ‚ä¸­çš„ç¬¬ä¸€ä¸ªç»“æœè¿›è¡Œæ¯”è¾ƒæ¥æ£€æŸ¥è¿™ä¸€ç‚¹ï¼‰ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.97773</span></span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬æœ‰ä»¥æ ‡è®°è¡¨ç¤ºçš„ç­”æ¡ˆçš„<code>start_index</code>å’Œ<code>end_index</code> ï¼Œæ‰€ä»¥ç°åœ¨æˆ‘ä»¬åªéœ€è¦è½¬æ¢ä¸ºä¸Šä¸‹æ–‡ä¸­çš„å­—ç¬¦ç´¢å¼•ã€‚è¿™å°±æ˜¯åç§»é‡éå¸¸æœ‰ç”¨çš„åœ°æ–¹ã€‚æˆ‘ä»¬å¯ä»¥åƒåœ¨ä»¤ç‰Œåˆ†ç±»ä»»åŠ¡ä¸­é‚£æ ·è·å–å¹¶ä½¿ç”¨å®ƒä»¬ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">inputs_with_offsets = tokenizer(question, context, return_offsets_mapping=<span class="literal">True</span>)</span><br><span class="line">offsets = inputs_with_offsets[<span class="string">&quot;offset_mapping&quot;</span>]</span><br><span class="line"></span><br><span class="line">start_char, _ = offsets[start_index]</span><br><span class="line">_, end_char = offsets[end_index]</span><br><span class="line">answer = context[start_char:end_char]</span><br></pre></td></tr></table></figure>
<p>ç°åœ¨æˆ‘ä»¬åªéœ€æ ¼å¼åŒ–æ‰€æœ‰å†…å®¹å³å¯è·å¾—ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">result = &#123;</span><br><span class="line">    <span class="string">&quot;answer&quot;</span>: answer,</span><br><span class="line">    <span class="string">&quot;start&quot;</span>: start_char,</span><br><span class="line">    <span class="string">&quot;end&quot;</span>: end_char,</span><br><span class="line">    <span class="string">&quot;score&quot;</span>: scores[start_index, end_index],</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line">&#123;<span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;Jax, PyTorch and TensorFlow&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;start&#x27;</span>: <span class="number">78</span>,</span><br><span class="line"> <span class="string">&#x27;end&#x27;</span>: <span class="number">105</span>,</span><br><span class="line"> <span class="string">&#x27;score&#x27;</span>: <span class="number">0.97773</span>&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3å¤„ç†é•¿ä¸Šä¸‹æ–‡"><a class="markdownIt-Anchor" href="#3å¤„ç†é•¿ä¸Šä¸‹æ–‡"></a> 3.å¤„ç†é•¿ä¸Šä¸‹æ–‡</h3>
<p><font size="5">ä»¥æœ€å¤§é•¿åº¦æˆªæ–­è¾“å…¥</font></p>
<p>å¦‚æœæˆ‘ä»¬å°è¯•å¯¹ä¹‹å‰ç”¨ä½œç¤ºä¾‹çš„é—®é¢˜å’Œé•¿ä¸Šä¸‹æ–‡è¿›è¡Œæ ‡è®°ï¼Œæˆ‘ä»¬å°†è·å¾—æ¯”<code>question-answering</code>ç®¡é“ä¸­ä½¿ç”¨çš„æœ€å¤§é•¿åº¦æ›´é«˜çš„æ ‡è®°æ•°é‡ï¼ˆå³ 384ï¼‰ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">inputs = tokenizer(question, long_context)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(inputs[<span class="string">&quot;input_ids&quot;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="number">461</span></span><br></pre></td></tr></table></figure>
<p>å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä»¥æœ€å¤§é•¿åº¦æˆªæ–­è¾“å…¥ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å¤šç§æ–¹æ³•æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½†æˆ‘ä»¬ä¸æƒ³æˆªæ–­é—®é¢˜ï¼Œè€Œåªæƒ³æˆªæ–­ä¸Šä¸‹æ–‡ã€‚ç”±äºä¸Šä¸‹æ–‡æ˜¯ç¬¬äºŒä¸ªå¥å­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<code>&quot;only_second&quot;</code>æˆªæ–­ç­–ç•¥ã€‚<font color="red">é‚£ä¹ˆå‡ºç°çš„é—®é¢˜æ˜¯é—®é¢˜çš„ç­”æ¡ˆå¯èƒ½ä¸åœ¨è¢«æˆªæ–­çš„ä¸Šä¸‹æ–‡ä¸­ã€‚</font>ä¾‹å¦‚ï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªé—®é¢˜ï¼Œå…¶ç­”æ¡ˆä½äºä¸Šä¸‹æ–‡æœ«å°¾ï¼Œè€Œå½“æˆ‘ä»¬æˆªæ–­å®ƒæ—¶ï¼Œç­”æ¡ˆä¸å­˜åœ¨ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">inputs = tokenizer(question, long_context, max_length=<span class="number">384</span>, truncation=<span class="string">&quot;only_second&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(tokenizer.decode(inputs[<span class="string">&quot;input_ids&quot;</span>]))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">[CLS] Which deep learning libraries back [UNK] Transformers? [SEP] [UNK] Transformers : State of the Art NLP</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[UNK] Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,</span></span><br><span class="line"><span class="string">question answering, summarization, translation, text generation and more in over 100 languages.</span></span><br><span class="line"><span class="string">Its aim is to make cutting-edge NLP easier to use for everyone.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[UNK] Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and</span></span><br><span class="line"><span class="string">then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and</span></span><br><span class="line"><span class="string">can be modified to enable quick research experiments.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Why should I use transformers?</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. Easy-to-use state-of-the-art models:</span></span><br><span class="line"><span class="string">  - High performance on NLU and NLG tasks.</span></span><br><span class="line"><span class="string">  - Low barrier to entry for educators and practitioners.</span></span><br><span class="line"><span class="string">  - Few user-facing abstractions with just three classes to learn.</span></span><br><span class="line"><span class="string">  - A unified API for using all our pretrained models.</span></span><br><span class="line"><span class="string">  - Lower compute costs, smaller carbon footprint:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">2. Researchers can share trained models instead of always retraining.</span></span><br><span class="line"><span class="string">  - Practitioners can reduce compute time and production costs.</span></span><br><span class="line"><span class="string">  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">3. Choose the right framework for every part of a model&#x27;s lifetime:</span></span><br><span class="line"><span class="string">  - Train state-of-the-art models in 3 lines of code.</span></span><br><span class="line"><span class="string">  - Move a single model between TF2.0/PyTorch frameworks at will.</span></span><br><span class="line"><span class="string">  - Seamlessly pick the right framework for training, evaluation and production.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">4. Easily customize a model or an example to your needs:</span></span><br><span class="line"><span class="string">  - We provide examples for each architecture to reproduce the results published by its original authors.</span></span><br><span class="line"><span class="string">  - Model internal [SEP]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>è¿™æ„å‘³ç€æ¨¡å‹å°†å¾ˆéš¾é€‰æ‹©æ­£ç¡®çš„ç­”æ¡ˆã€‚<font color="red"></font></p>
<p><font size="5">å•ä¸ªå¥å­æˆªæ–­æˆå¤šå—</font></p>
<p><font color="red">ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œ <code>question-answering</code>ç®¡é“å…è®¸æˆ‘ä»¬å°†ä¸Šä¸‹æ–‡åˆ†å‰²æˆæ›´å°çš„å—ï¼Œå¹¶æŒ‡å®šæœ€å¤§é•¿åº¦ã€‚ä¸ºäº†ç¡®ä¿æˆ‘ä»¬ä¸ä¼šåœ¨é”™è¯¯çš„ä½ç½®åˆ†å‰²ä¸Šä¸‹æ–‡ä»¥æ‰¾åˆ°ç­”æ¡ˆï¼Œå®ƒè¿˜åŒ…æ‹¬å—ä¹‹é—´çš„ä¸€äº›é‡å ã€‚</font></p>
<p>æˆ‘ä»¬å¯ä»¥è®©åˆ†è¯å™¨ï¼ˆå¿«æˆ–æ…¢ï¼‰é€šè¿‡æ·»åŠ <code>return_overflowing_tokens=True</code> æ¥ä¸ºæˆ‘ä»¬åšåˆ°è¿™ä¸€ç‚¹ ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨<code>stride</code>å‚æ•°æŒ‡å®šæˆ‘ä»¬æƒ³è¦çš„é‡å ã€‚è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨è¾ƒå°å¥å­çš„ç¤ºä¾‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sentence = <span class="string">&quot;This sentence is not too long but we are going to split it anyway.&quot;</span></span><br><span class="line">inputs = tokenizer(</span><br><span class="line">    sentence, truncation=<span class="literal">True</span>, return_overflowing_tokens=<span class="literal">True</span>, max_length=<span class="number">6</span>, stride=<span class="number">2</span> <span class="comment"># æœ€å¤§é•¿åº¦ä¸º6ï¼Œé‡å çš„tokenä¸º2</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ids <span class="keyword">in</span> inputs[<span class="string">&quot;input_ids&quot;</span>]:</span><br><span class="line">    <span class="built_in">print</span>(tokenizer.decode(ids))</span><br><span class="line"><span class="string">&#x27;[CLS] This sentence is not [SEP]&#x27;</span></span><br><span class="line"><span class="string">&#x27;[CLS] is not too long [SEP]&#x27;</span></span><br><span class="line"><span class="string">&#x27;[CLS] too long but we [SEP]&#x27;</span></span><br><span class="line"><span class="string">&#x27;[CLS] but we are going [SEP]&#x27;</span></span><br><span class="line"><span class="string">&#x27;[CLS] are going to split [SEP]&#x27;</span></span><br><span class="line"><span class="string">&#x27;[CLS] to split it anyway [SEP]&#x27;</span></span><br><span class="line"><span class="string">&#x27;[CLS] it anyway. [SEP]&#x27;</span></span><br></pre></td></tr></table></figure>
<p>æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œè¯¥å¥å­å·²è¢«åˆ†å‰²æˆå¤šä¸ªå—ï¼Œä½¿å¾—<code>inputs[&quot;input_ids&quot;]</code>ä¸­çš„æ¯ä¸ªæ¡ç›®æœ€å¤šæœ‰ 6 ä¸ªtokenï¼ˆæˆ‘ä»¬éœ€è¦æ·»åŠ å¡«å……ä»¥ä½¿æœ€åä¸€ä¸ªæ¡ç›®ä¸å…¶ä»–æ¡ç›®çš„å¤§å°ç›¸åŒï¼‰ ï¼‰å¹¶ä¸”æ¯ä¸ªæ¡ç›®ä¹‹é—´æœ‰ 2 ä¸ªtokené‡å ã€‚</p>
<p>è®©æˆ‘ä»¬ä»”ç»†çœ‹çœ‹æ ‡è®°åŒ–çš„ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(inputs.keys())</span><br><span class="line"></span><br><span class="line">dict_keys([<span class="string">&#x27;input_ids&#x27;</span>, <span class="string">&#x27;attention_mask&#x27;</span>, <span class="string">&#x27;overflow_to_sample_mapping&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>æ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œæˆ‘ä»¬å¾—åˆ°äº†è¾“å…¥ ID å’Œæ³¨æ„åŠ›æ©ç ã€‚<font color="red">æœ€åä¸€ä¸ªé”®ï¼Œ <code>overflow_to_sample_mapping</code> ï¼Œæ˜¯ä¸€ä¸ªæ˜ å°„ï¼Œå®ƒå‘Šè¯‰æˆ‘ä»¬æ¯ä¸ªç»“æœå¯¹åº”äºå“ªä¸ªå¥å­â€”â€”è¿™é‡Œæˆ‘ä»¬æœ‰ 7 ä¸ªç»“æœï¼Œå®ƒä»¬éƒ½æ¥è‡ªæˆ‘ä»¬ä¼ é€’ç»™åˆ†è¯å™¨çš„ï¼ˆå”¯ä¸€çš„ï¼‰å¥å­ï¼š</font></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(inputs[<span class="string">&quot;overflow_to_sample_mapping&quot;</span>])</span><br><span class="line"></span><br><span class="line">[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p><font size="5">å¤šä¸ªå¥å­æˆªæ–­æˆå¤šå—</font></p>
<p>å½“æˆ‘ä»¬ä¸€èµ·æ ‡è®°å¤šä¸ªå¥å­æ—¶ï¼Œè¿™æ›´æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œè¿™ä¸ªï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sentences = [</span><br><span class="line">    <span class="string">&quot;This sentence is not too long but we are going to split it anyway.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;This sentence is shorter but will still get split.&quot;</span>,</span><br><span class="line">]</span><br><span class="line">inputs = tokenizer(</span><br><span class="line">    sentences, truncation=<span class="literal">True</span>, return_overflowing_tokens=<span class="literal">True</span>, max_length=<span class="number">6</span>, stride=<span class="number">2</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(inputs[<span class="string">&quot;overflow_to_sample_mapping&quot;</span>])</span><br></pre></td></tr></table></figure>
<p>gets us: è®©æˆ‘ä»¬ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]</span><br></pre></td></tr></table></figure>
<p>è¿™æ„å‘³ç€ç¬¬ä¸€ä¸ªå¥å­åƒä»¥å‰ä¸€æ ·è¢«åˆ†æˆ 7 ä¸ªå—ï¼Œæ¥ä¸‹æ¥çš„ 4 ä¸ªå—æ¥è‡ªç¬¬äºŒä¸ªå¥å­ã€‚</p>
<p><font size="5">ç»¼åˆ:</font></p>
<p>ç°åœ¨è®©æˆ‘ä»¬å›åˆ°æˆ‘ä»¬çš„é•¿æœŸèƒŒæ™¯ã€‚é»˜è®¤æƒ…å†µä¸‹<code>question-answering</code>ç®¡é“ä½¿ç”¨çš„æœ€å¤§é•¿åº¦ä¸º 384ï¼Œæ­£å¦‚æˆ‘ä»¬ä¹‹å‰æåˆ°çš„ï¼Œæ­¥é•¿ä¸º 128ï¼Œè¿™å¯¹åº”äºæ¨¡å‹å¾®è°ƒçš„æ–¹å¼ ï¼ˆæ‚¨å¯ä»¥åœ¨è°ƒç”¨æ—¶é€šè¿‡ä¼ é€’<code>max_seq_len</code>å’Œ<code>stride</code>å‚æ•°æ¥è°ƒæ•´è¿™äº›å‚æ•°ï¼‰ç®¡é“ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†åœ¨æ ‡è®°åŒ–æ—¶ä½¿ç”¨è¿™äº›å‚æ•°ã€‚æˆ‘ä»¬è¿˜å°†æ·»åŠ å¡«å……ï¼ˆä»¥å…·æœ‰ç›¸åŒé•¿åº¦çš„æ ·æœ¬ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥æ„å»ºå¼ é‡ï¼‰å¹¶è¯¢é—®åç§»é‡ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">inputs = tokenizer(</span><br><span class="line">    question,</span><br><span class="line">    long_context,</span><br><span class="line">    stride=<span class="number">128</span>,</span><br><span class="line">    max_length=<span class="number">384</span>,</span><br><span class="line">    padding=<span class="string">&quot;longest&quot;</span>,</span><br><span class="line">    truncation=<span class="string">&quot;only_second&quot;</span>,</span><br><span class="line">    return_overflowing_tokens=<span class="literal">True</span>,</span><br><span class="line">    return_offsets_mapping=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>è¿™äº›<code>inputs</code>å°†åŒ…å«æ¨¡å‹æœŸæœ›çš„è¾“å…¥ ID å’Œæ³¨æ„åŠ›æ©ç ï¼Œä»¥åŠæˆ‘ä»¬åˆšæ‰è®¨è®ºçš„åç§»é‡å’Œ<code>overflow_to_sample_mapping</code> ã€‚<font color="red">ç”±äºè¿™ä¸¤ä¸ªä¸æ˜¯æ¨¡å‹ä½¿ç”¨çš„å‚æ•°ï¼Œå› æ­¤åœ¨å°†å…¶è½¬æ¢ä¸ºå¼ é‡ä¹‹å‰ï¼Œæˆ‘ä»¬ä¼šå°†å®ƒä»¬ä»<code>inputs</code>ä¸­å¼¹å‡ºï¼ˆå¹¶ä¸”æˆ‘ä»¬ä¸ä¼šå­˜å‚¨æ˜ å°„ï¼Œå› ä¸ºå®ƒåœ¨è¿™é‡Œæ²¡æœ‰ç”¨ï¼š</font></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">_ = inputs.pop(<span class="string">&quot;overflow_to_sample_mapping&quot;</span>)</span><br><span class="line">offsets = inputs.pop(<span class="string">&quot;offset_mapping&quot;</span>)</span><br><span class="line"></span><br><span class="line">inputs = inputs.convert_to_tensors(<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(inputs[<span class="string">&quot;input_ids&quot;</span>].shape)</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">384</span>])</span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬çš„é•¿ä¸Šä¸‹æ–‡è¢«åˆ†æˆä¸¤éƒ¨åˆ†ï¼Œè¿™æ„å‘³ç€åœ¨å®ƒé€šè¿‡æˆ‘ä»¬çš„æ¨¡å‹ä¹‹åï¼Œæˆ‘ä»¬å°†æœ‰ä¸¤ç»„å¼€å§‹å’Œç»“æŸé€»è¾‘ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">outputs = model(**inputs)</span><br><span class="line"></span><br><span class="line">start_logits = outputs.start_logits</span><br><span class="line">end_logits = outputs.end_logits</span><br><span class="line"><span class="built_in">print</span>(start_logits.shape, end_logits.shape)</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">384</span>]) torch.Size([<span class="number">2</span>, <span class="number">384</span>])</span><br></pre></td></tr></table></figure>
<p><font color="red">å’Œä¹‹å‰ä¸€æ ·ï¼Œæˆ‘ä»¬åœ¨é‡‡ç”¨ softmax ä¹‹å‰é¦–å…ˆå±è”½æ‰ä¸å±äºä¸Šä¸‹æ–‡çš„ tokenã€‚æˆ‘ä»¬è¿˜å±è”½æ‰€æœ‰å¡«å……æ ‡è®°ï¼ˆå¦‚æ³¨æ„åŠ›æ©ç æ‰€æ ‡è®°çš„ï¼‰ï¼š</font></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sequence_ids = inputs.sequence_ids()</span><br><span class="line"><span class="comment"># Mask everything apart from the tokens of the context</span></span><br><span class="line">mask = [i != <span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> sequence_ids]</span><br><span class="line"><span class="comment"># Unmask the [CLS] token</span></span><br><span class="line">mask[<span class="number">0</span>] = <span class="literal">False</span></span><br><span class="line"><span class="comment"># Mask all the [PAD] tokens</span></span><br><span class="line">mask = torch.logical_or(torch.tensor(mask)[<span class="literal">None</span>], (inputs[<span class="string">&quot;attention_mask&quot;</span>] == <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">start_logits[mask] = -<span class="number">10000</span></span><br><span class="line">end_logits[mask] = -<span class="number">10000</span></span><br></pre></td></tr></table></figure>
<p>ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ softmax å°† logits è½¬æ¢ä¸ºæ¦‚ç‡ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start_probabilities = torch.nn.functional.softmax(start_logits, dim=-<span class="number">1</span>)</span><br><span class="line">end_probabilities = torch.nn.functional.softmax(end_logits, dim=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>ä¸‹ä¸€æ­¥ä¸æˆ‘ä»¬å¯¹å°ä¸Šä¸‹æ–‡æ‰€åšçš„ç±»ä¼¼ï¼Œä½†æˆ‘ä»¬å¯¹ä¸¤ä¸ªå—ä¸­çš„æ¯ä¸€ä¸ªéƒ½é‡å¤å®ƒã€‚æˆ‘ä»¬ä¸ºæ‰€æœ‰å¯èƒ½çš„ç­”æ¡ˆèŒƒå›´æ‰“åˆ†ï¼Œç„¶åå–å¾—åˆ†æœ€é«˜çš„èŒƒå›´ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">candidates = []</span><br><span class="line"><span class="keyword">for</span> start_probs, end_probs <span class="keyword">in</span> <span class="built_in">zip</span>(start_probabilities, end_probabilities):</span><br><span class="line">    scores = start_probs[:, <span class="literal">None</span>] * end_probs[<span class="literal">None</span>, :]</span><br><span class="line">    idx = torch.triu(scores).argmax().item()</span><br><span class="line"></span><br><span class="line">    start_idx = idx // scores.shape[<span class="number">1</span>]</span><br><span class="line">    end_idx = idx % scores.shape[<span class="number">1</span>]</span><br><span class="line">    score = scores[start_idx, end_idx].item()</span><br><span class="line">    candidates.append((start_idx, end_idx, score))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(candidates)</span><br><span class="line">[(<span class="number">0</span>, <span class="number">18</span>, <span class="number">0.33867</span>), (<span class="number">173</span>, <span class="number">184</span>, <span class="number">0.97149</span>)]</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>torch.triu(input, diagonal=0, *,out=None) -&gt; Tensor</code></p>
<p>è¿”å›input å¼ é‡ï¼Œå¯¹åº”å¯¹è§’çº¿ (diagonalï¼‰å–å€¼çš„ç»“æœã€‚ å…¶ä½™ä½ç½®ä¸º0</p>
<p>å‚æ•°:</p>
<ul>
<li>input (Tensor): è¾“å…¥å¼ é‡</li>
<li>diagonal (int,å¯é€‰çš„) - è¦è€ƒè™‘çš„å¯¹è§’çº¿</li>
<li>out (Tensor, å¯é€‰çš„ï¼‰- è¾“å‡ºå¼ é‡</li>
</ul>
<p>å‚æ•° diagonal æ§åˆ¶è¦è€ƒè™‘çš„å¯¹è§’çº¿ã€‚å¦‚æœdiagonal = 0ï¼Œåˆ™ä¿ç•™ä¸»å¯¹è§’çº¿ä¹‹ä¸Šå’Œä¹‹ä¸Šçš„æ‰€æœ‰å…ƒç´ ã€‚å…¶ä½™ä½ç½®çš„å…ƒç´ ä¸º0ã€‚æ­£å€¼ä¸åŒ…æ‹¬ä¸»å¯¹è§’çº¿ä¸Šæ–¹çš„å¯¹è§’çº¿ï¼Œç±»ä¼¼åœ°ï¼Œè´Ÿå€¼åŒ…æ‹¬ä¸»å¯¹è§’çº¿ä¸‹æ–¹çš„å¯¹è§’çº¿ã€‚ä¸»å¯¹è§’çº¿æ˜¯iâˆˆ[0,min{d1,d2}âˆ’1] çš„ç´¢å¼•é›†{(i,i)}ï¼Œå…¶ä¸­d1,d2 æ˜¯çŸ©é˜µçš„ç»´åº¦ã€‚</p>
</blockquote>
<p>è¿™ä¸¤ä¸ªå€™é€‰å¯¹åº”äºæ¨¡å‹èƒ½å¤Ÿåœ¨æ¯ä¸ªå—ä¸­æ‰¾åˆ°çš„æœ€ä½³ç­”æ¡ˆã€‚è¯¥æ¨¡å‹å¯¹ç¬¬äºŒéƒ¨åˆ†ä¸­çš„æ­£ç¡®ç­”æ¡ˆæ›´æœ‰ä¿¡å¿ƒï¼ˆè¿™æ˜¯ä¸€ä¸ªå¥½å…†å¤´ï¼ï¼‰ã€‚ç°åœ¨æˆ‘ä»¬åªéœ€å°†è¿™ä¸¤ä¸ªæ ‡è®°èŒƒå›´æ˜ å°„åˆ°ä¸Šä¸‹æ–‡ä¸­çš„å­—ç¬¦èŒƒå›´ï¼ˆæˆ‘ä»¬åªéœ€è¦æ˜ å°„ç¬¬äºŒä¸ªæ ‡è®°èŒƒå›´å³å¯å¾—åˆ°ç­”æ¡ˆï¼Œä½†çœ‹çœ‹æ¨¡å‹åœ¨ç¬¬ä¸€ä¸ªå—ä¸­é€‰æ‹©äº†ä»€ä¹ˆæ˜¯å¾ˆæœ‰è¶£çš„ï¼‰ã€‚</p>
<p>æˆ‘ä»¬ä¹‹å‰è·å–çš„<code>offsets</code>å®é™…ä¸Šæ˜¯ä¸€ä¸ªåç§»é‡åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æœ¬å—æœ‰ä¸€ä¸ªåˆ—è¡¨ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> candidate, offset <span class="keyword">in</span> <span class="built_in">zip</span>(candidates, offsets):</span><br><span class="line">    start_token, end_token, score = candidate</span><br><span class="line">    start_char, _ = offset[start_token]</span><br><span class="line">    _, end_char = offset[end_token]</span><br><span class="line">    answer = long_context[start_char:end_char]</span><br><span class="line">    result = &#123;<span class="string">&quot;answer&quot;</span>: answer, <span class="string">&quot;start&quot;</span>: start_char, <span class="string">&quot;end&quot;</span>: end_char, <span class="string">&quot;score&quot;</span>: score&#125;</span><br><span class="line">    <span class="built_in">print</span>(result)</span><br><span class="line">&#123;<span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;\nğŸ¤— Transformers: State of the Art NLP&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">37</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.33867</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;Jax, PyTorch and TensorFlow&#x27;</span>, <span class="string">&#x27;start&#x27;</span>: <span class="number">1892</span>, <span class="string">&#x27;end&#x27;</span>: <span class="number">1919</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">0.97149</span>&#125;</span><br></pre></td></tr></table></figure>
<p>å¦‚æœæˆ‘ä»¬å¿½ç•¥ç¬¬ä¸€ä¸ªç»“æœï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ä¸è¿™ä¸ªé•¿ä¸Šä¸‹æ–‡çš„ç®¡é“ç›¸åŒçš„ç»“æœ - è€¶ï¼</p>
<h2 id="æ ‡å‡†åŒ–å’Œé¢„æ ‡è®°åŒ–"><a class="markdownIt-Anchor" href="#æ ‡å‡†åŒ–å’Œé¢„æ ‡è®°åŒ–"></a> æ ‡å‡†åŒ–å’Œé¢„æ ‡è®°åŒ–</h2>
<p>Transformer æ¨¡å‹ä¸­ä½¿ç”¨çš„ä¸‰ç§æœ€å¸¸è§çš„å­è¯æ ‡è®°åŒ–ç®—æ³•</p>
<ul>
<li>å­—èŠ‚å¯¹ç¼–ç  [BPE]</li>
<li>WordPiece</li>
<li>Unigram</li>
</ul>
<p>ä»¥ä¸‹æ˜¯æ ‡è®°åŒ–ç®¡é“ä¸­æ­¥éª¤çš„é«˜çº§æ¦‚è¿°ï¼š</p>
<p><img src="en_chapter6_tokenization_pipeline.svg" alt></p>
<h3 id="1normalization"><a class="markdownIt-Anchor" href="#1normalization"></a> 1.Normalization</h3>
<p><font color="red">è§„èŒƒåŒ–æ­¥éª¤æ¶‰åŠä¸€äº›å¸¸è§„æ¸…ç†ï¼Œä¾‹å¦‚åˆ é™¤ä¸å¿…è¦çš„ç©ºæ ¼ã€å°å†™å’Œ/æˆ–åˆ é™¤é‡éŸ³ç¬¦å·ã€‚</font>å¦‚æœæ‚¨ç†Ÿæ‚‰<a target="_blank" rel="noopener" href="http://www.unicode.org/reports/tr15/">Unicode è§„èŒƒåŒ–</a>ï¼ˆä¾‹å¦‚ NFC æˆ– NFKCï¼‰ï¼Œè¿™ä¹Ÿæ˜¯æ ‡è®°ç”Ÿæˆå™¨å¯èƒ½åº”ç”¨çš„å†…å®¹ã€‚</p>
<p>ğŸ¤— Transformers <code>tokenizer</code>æœ‰ä¸€ä¸ªåä¸º<code>backend_tokenizer</code>çš„å±æ€§ï¼Œå®ƒæä¾›å¯¹ ğŸ¤— Tokenizers åº“ä¸­çš„åº•å±‚ tokenizer çš„è®¿é—®ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rom transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;bert-base-uncased&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(tokenizer.backend_tokenizer))</span><br><span class="line"></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;tokenizers.Tokenizer&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>
<p><code>tokenizer</code>å¯¹è±¡çš„<code>normalizer</code>å±æ€§æœ‰ä¸€ä¸ª<code>normalize_str()</code>æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®ƒæ¥æŸ¥çœ‹è§„èŒƒåŒ–æ˜¯å¦‚ä½•æ‰§è¡Œçš„ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(tokenizer.backend_tokenizer.normalizer.normalize_str(<span class="string">&quot;HÃ©llÃ² hÃ´w are Ã¼?&quot;</span>))</span><br><span class="line"><span class="string">&#x27;hello how are u?&#x27;</span></span><br></pre></td></tr></table></figure>
<p>åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œç”±äºæˆ‘ä»¬é€‰æ‹©äº†<code>bert-base-uncased</code>æ£€æŸ¥ç‚¹ï¼Œå› æ­¤è§„èŒƒåŒ–åº”ç”¨äº†å°å†™å¹¶åˆ é™¤äº†é‡éŸ³ç¬¦å·ã€‚</p>
<h3 id="2é¢„æ ‡è®°åŒ–"><a class="markdownIt-Anchor" href="#2é¢„æ ‡è®°åŒ–"></a> 2.é¢„æ ‡è®°åŒ–</h3>
<p><font color="red">æ­£å¦‚æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­çœ‹åˆ°çš„ï¼Œåˆ†è¯å™¨ä¸èƒ½ç›´æ¥åœ¨åŸå§‹æ–‡æœ¬ä¸Šè¿›è¡Œè®­ç»ƒã€‚ç›¸åï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å°†æ–‡æœ¬åˆ†å‰²æˆå°å®ä½“ï¼Œä¾‹å¦‚å•è¯ã€‚è¿™å°±æ˜¯é¢„åˆ†è¯æ­¥éª¤çš„ç”¨æ­¦ä¹‹åœ°ã€‚</font>æ­£å¦‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/course/chapter2">ç¬¬ 2 ç« </a>ä¸­çœ‹åˆ°çš„ï¼ŒåŸºäºå•è¯çš„åˆ†è¯å™¨å¯ä»¥ç®€å•åœ°å°†åŸå§‹æ–‡æœ¬æ‹†åˆ†ä¸ºç©ºæ ¼å’Œæ ‡ç‚¹ç¬¦å·ä¸Šçš„å•è¯ã€‚è¿™äº›å•è¯å°†æ˜¯æ ‡è®°å™¨åœ¨è®­ç»ƒæœŸé—´å¯ä»¥å­¦ä¹ çš„å­æ ‡è®°çš„è¾¹ç•Œã€‚</p>
<p>è¦æŸ¥çœ‹å¿«é€Ÿåˆ†è¯å™¨å¦‚ä½•æ‰§è¡Œé¢„åˆ†è¯åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨<code>tokenizer</code>å¯¹è±¡çš„<code>pre_tokenizer</code>å±æ€§çš„<code>pre_tokenize_str()</code>æ–¹æ³•ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(<span class="string">&quot;Hello, how are  you?&quot;</span>)</span><br><span class="line"></span><br><span class="line">[(<span class="string">&#x27;Hello&#x27;</span>, (<span class="number">0</span>, <span class="number">5</span>)), (<span class="string">&#x27;,&#x27;</span>, (<span class="number">5</span>, <span class="number">6</span>)), (<span class="string">&#x27;how&#x27;</span>, (<span class="number">7</span>, <span class="number">10</span>)), (<span class="string">&#x27;are&#x27;</span>, (<span class="number">11</span>, <span class="number">14</span>)), (<span class="string">&#x27;you&#x27;</span>, (<span class="number">16</span>, <span class="number">19</span>)), (<span class="string">&#x27;?&#x27;</span>, (<span class="number">19</span>, <span class="number">20</span>))]</span><br></pre></td></tr></table></figure>
<p>è¯·æ³¨æ„åˆ†è¯å™¨å¦‚ä½•è·Ÿè¸ªåç§»é‡ï¼Œè¿™å°±æ˜¯å®ƒå¦‚ä½•ä¸ºæˆ‘ä»¬æä¾›ä¸Šä¸€èŠ‚ä¸­ä½¿ç”¨çš„åç§»é‡æ˜ å°„çš„æ–¹å¼ã€‚<font color="red">è¿™é‡Œï¼Œåˆ†è¯å™¨å¿½ç•¥ä¸¤ä¸ªç©ºæ ¼ï¼Œåªç”¨ä¸€ä¸ªç©ºæ ¼æ›¿æ¢å®ƒä»¬ï¼Œä½†åç§»é‡ä¼šåœ¨<code>are</code>å’Œ<code>you</code>ä¹‹é—´è·³è½¬ï¼Œä»¥è§£é‡Šè¿™ä¸€ç‚¹ã€‚</font></p>
<p><font size="5">GPT-2åˆ†è¯å™¨</font></p>
<p>ç”±äºæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ BERT åˆ†è¯å™¨ï¼Œå› æ­¤é¢„åˆ†è¯æ¶‰åŠåˆ°ç©ºæ ¼å’Œæ ‡ç‚¹ç¬¦å·çš„åˆ†å‰²ã€‚å…¶ä»–åˆ†è¯å™¨å¯¹æ­¤æ­¥éª¤å¯ä»¥æœ‰ä¸åŒçš„è§„åˆ™ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨GPT-2åˆ†è¯å™¨ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;gpt2&quot;</span>)</span><br><span class="line">tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(<span class="string">&quot;Hello, how are  you?&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>å®ƒä¹Ÿä¼šæ ¹æ®ç©ºæ ¼å’Œæ ‡ç‚¹ç¬¦å·è¿›è¡Œåˆ†å‰²ï¼Œä½†å®ƒä¼šä¿ç•™ç©ºæ ¼å¹¶ç”¨<code>Ä </code>ç¬¦å·æ›¿æ¢å®ƒä»¬ï¼Œè¿™æ ·å¦‚æœæˆ‘ä»¬è§£ç æ ‡è®°ï¼Œå®ƒå°±èƒ½æ¢å¤åŸå§‹ç©ºæ ¼ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="string">&#x27;Hello&#x27;</span>, (<span class="number">0</span>, <span class="number">5</span>)), (<span class="string">&#x27;,&#x27;</span>, (<span class="number">5</span>, <span class="number">6</span>)), (<span class="string">&#x27;Ä how&#x27;</span>, (<span class="number">6</span>, <span class="number">10</span>)), (<span class="string">&#x27;Ä are&#x27;</span>, (<span class="number">10</span>, <span class="number">14</span>)), (<span class="string">&#x27;Ä &#x27;</span>, (<span class="number">14</span>, <span class="number">15</span>)), (<span class="string">&#x27;Ä you&#x27;</span>, (<span class="number">15</span>, <span class="number">19</span>)),</span><br><span class="line"> (<span class="string">&#x27;?&#x27;</span>, (<span class="number">19</span>, <span class="number">20</span>))]</span><br></pre></td></tr></table></figure>
<p>å¦è¯·æ³¨æ„ï¼Œä¸ BERT åˆ†è¯å™¨ä¸åŒï¼Œæ­¤åˆ†è¯å™¨ä¸ä¼šå¿½ç•¥åŒç©ºæ ¼ã€‚</p>
<p><font size="5">T5 åˆ†è¯å™¨</font></p>
<p>æœ€åä¸€ä¸ªä¾‹å­ï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸‹åŸºäº SentencePiece ç®—æ³•çš„ T5 åˆ†è¯å™¨:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;t5-small&quot;</span>)</span><br><span class="line">tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(<span class="string">&quot;Hello, how are  you?&quot;</span>)</span><br><span class="line"></span><br><span class="line">[(<span class="string">&#x27;â–Hello,&#x27;</span>, (<span class="number">0</span>, <span class="number">6</span>)), (<span class="string">&#x27;â–how&#x27;</span>, (<span class="number">7</span>, <span class="number">10</span>)), (<span class="string">&#x27;â–are&#x27;</span>, (<span class="number">11</span>, <span class="number">14</span>)), (<span class="string">&#x27;â–you?&#x27;</span>, (<span class="number">16</span>, <span class="number">20</span>))]</span><br></pre></td></tr></table></figure>
<p>ä¸ GPT-2 åˆ†è¯å™¨ä¸€æ ·ï¼Œæ­¤åˆ†è¯å™¨ä¿ç•™ç©ºæ ¼å¹¶å°†å…¶æ›¿æ¢ä¸ºç‰¹å®šæ ‡è®° ( <code>_</code> )ï¼Œä½† T5 åˆ†è¯å™¨ä»…æŒ‰ç©ºæ ¼è€Œä¸æ˜¯æ ‡ç‚¹ç¬¦å·è¿›è¡Œåˆ†å‰²ã€‚å¦è¯·æ³¨æ„ï¼Œå®ƒé»˜è®¤åœ¨å¥å­å¼€å¤´ï¼ˆ <code>Hello</code>ä¹‹å‰ï¼‰æ·»åŠ ä¸€ä¸ªç©ºæ ¼ï¼Œå¹¶å¿½ç•¥<code>are</code>å’Œ<code>you</code>ä¹‹é—´çš„åŒç©ºæ ¼ã€‚</p>
<p>ç°åœ¨æˆ‘ä»¬å·²ç»äº†è§£äº†ä¸€äº›ä¸åŒçš„åˆ†è¯å™¨å¦‚ä½•å¤„ç†æ–‡æœ¬ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹æ¢ç´¢åº•å±‚ç®—æ³•æœ¬èº«ã€‚æˆ‘ä»¬é¦–å…ˆå¿«é€Ÿæµè§ˆä¸€ä¸‹å¹¿æ³›é€‚ç”¨çš„ SentencePieceï¼›ç„¶åï¼Œåœ¨æ¥ä¸‹æ¥çš„ä¸‰ä¸ªéƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†ç ”ç©¶ç”¨äºå­è¯æ ‡è®°åŒ–çš„ä¸‰ç§ä¸»è¦ç®—æ³•æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚</p>
<h3 id="3sentencepiece"><a class="markdownIt-Anchor" href="#3sentencepiece"></a> 3.SentencePiece</h3>
<p><a target="_blank" rel="noopener" href="https://github.com/google/sentencepiece">SentencePiece</a>æ˜¯ä¸€ç§ç”¨äºæ–‡æœ¬é¢„å¤„ç†çš„æ ‡è®°åŒ–ç®—æ³•ï¼Œæ‚¨å¯ä»¥å°†å…¶ä¸æˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„ä¸‰èŠ‚ä¸­çœ‹åˆ°çš„ä»»ä½•æ¨¡å‹ä¸€èµ·ä½¿ç”¨ã€‚å®ƒå°†æ–‡æœ¬è§†ä¸º Unicode å­—ç¬¦åºåˆ—ï¼Œå¹¶ç”¨ç‰¹æ®Šå­—ç¬¦â–æ›¿æ¢ç©ºæ ¼ä¸ Unigram ç®—æ³•ç»“åˆä½¿ç”¨ï¼ˆå‚è§<a target="_blank" rel="noopener" href="https://huggingface.co/course/chapter7/7">ç¬¬ 7 èŠ‚</a>ï¼‰ï¼Œå®ƒç”šè‡³ä¸éœ€è¦é¢„æ ‡è®°åŒ–æ­¥éª¤ï¼Œè¿™å¯¹äºä¸ä½¿ç”¨ç©ºæ ¼å­—ç¬¦çš„è¯­è¨€ï¼ˆå¦‚ä¸­æ–‡æˆ–æ—¥è¯­ï¼‰éå¸¸æœ‰ç”¨ã€‚</p>
<p><font color="red">SentencePieceçš„å¦ä¸€ä¸ªä¸»è¦åŠŸèƒ½æ˜¯<strong>å¯é€†æ ‡è®°åŒ–</strong>ï¼šç”±äºæ²¡æœ‰å¯¹ç©ºæ ¼è¿›è¡Œç‰¹æ®Šå¤„ç†ï¼Œå› æ­¤åªéœ€å°†å®ƒä»¬è¿æ¥èµ·æ¥å¹¶ç”¨ç©ºæ ¼æ›¿æ¢<code>_</code>å³å¯å¯¹æ ‡è®°è¿›è¡Œè§£ç  - è¿™ä¼šäº§ç”Ÿæ ‡å‡†åŒ–æ–‡æœ¬ã€‚æ­£å¦‚æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ï¼ŒBERT åˆ†è¯å™¨åˆ é™¤äº†é‡å¤ç©ºæ ¼ï¼Œå› æ­¤å…¶åˆ†è¯æ˜¯ä¸å¯é€†çš„ã€‚</font></p>
<h3 id="4ç®—æ³•ç»¼è¿°"><a class="markdownIt-Anchor" href="#4ç®—æ³•ç»¼è¿°"></a> 4.ç®—æ³•ç»¼è¿°</h3>
<p>åœ¨ä»¥ä¸‹éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥ç ”ç©¶ä¸‰ç§ä¸»è¦çš„å­è¯æ ‡è®°åŒ–ç®—æ³•ï¼šBPEï¼ˆç”± GPT-2 ç­‰ä½¿ç”¨ï¼‰ã€WordPieceï¼ˆä¾‹å¦‚ç”± BERT ä½¿ç”¨ï¼‰å’Œ Unigramï¼ˆç”± T5 ç­‰ä½¿ç”¨ï¼‰ã€‚åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆç®€è¦æ¦‚è¿°ä¸€ä¸‹å®ƒä»¬å„è‡ªçš„å·¥ä½œåŸç†ã€‚å¦‚æœæ‚¨è¿˜æ²¡æœ‰ç†è§£æ­¤è¡¨ï¼Œè¯·åœ¨é˜…è¯»å®Œæ¥ä¸‹æ¥çš„å„èŠ‚åç«‹å³è¿”å›æ­¤è¡¨</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>BPE</th>
<th>WordPiece</th>
<th>Unigram</th>
</tr>
</thead>
<tbody>
<tr>
<td>Training</td>
<td>Starts from a small vocabulary and learns rules to merge tokens</td>
<td>Starts from a small vocabulary and learns rules to merge tokens</td>
<td>Starts from a large vocabulary and learns rules to remove tokens</td>
</tr>
<tr>
<td>Training step</td>
<td>Merges the tokens corresponding to the most common pair</td>
<td>Merges the tokens corresponding to the pair with the best score based on the frequency of the pair, privileging pairs where each individual token is less frequent</td>
<td>Removes all the tokens in the vocabulary that will minimize the loss computed on the whole corpus</td>
</tr>
<tr>
<td>Learns</td>
<td>Merge rules and a vocabulary</td>
<td>Just a vocabulary</td>
<td>A vocabulary with a score for each token</td>
</tr>
<tr>
<td>Encoding</td>
<td>Splits a word into characters and applies the merges learned during training</td>
<td>Finds the longest subword starting from the beginning that is in the vocabulary, then does the same for the rest of the word</td>
<td>Finds the most likely split into tokens, using the scores learned during training</td>
</tr>
</tbody>
</table>
<h3 id><a class="markdownIt-Anchor" href="#"></a> </h3>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>æ–‡ç« ä½œè€…: </span><span class="post-copyright-info"><a href="http://example.com">HUI</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>æ–‡ç« é“¾æ¥: </span><span class="post-copyright-info"><a href="http://example.com/2024/09/20/NLP_Course(6.1)/">http://example.com/2024/09/20/NLP_Course(6.1)/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>ç‰ˆæƒå£°æ˜: </span><span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="http://example.com" target="_blank">HUI</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/87788970_p0_master1200.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/09/20/NLP_Course(6.2)/" title="NLPè¯¾ç¨‹ï¼ˆå…­-ä¸­ï¼‰- ä¸‰ç§æ ‡è®°åŒ–"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">ä¸Šä¸€ç¯‡</div><div class="prev_info">NLPè¯¾ç¨‹ï¼ˆå…­-ä¸­ï¼‰- ä¸‰ç§æ ‡è®°åŒ–</div></div></a></div><div class="next-post pull-right"><a href="/2024/09/20/NLP_Course(5)/" title="NLPè¯¾ç¨‹ï¼ˆäº”ï¼‰- Datasetsåº“"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">ä¸‹ä¸€ç¯‡</div><div class="next_info">NLPè¯¾ç¨‹ï¼ˆäº”ï¼‰- Datasetsåº“</div></div></a></div></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> è¯„è®º</span></div><div class="comment-switch"><span class="first-comment">Valine</span><span id="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/87788970_p0_master1200.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">HUI</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/kalabiqlx" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:kalabiqlx@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>å…¬å‘Š</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#nlp%E8%AF%BE%E7%A8%8B%E5%85%AD-%E4%B8%8A-tokenizer%E5%BA%93"><span class="toc-text"> NLPè¯¾ç¨‹ï¼ˆå…­-ä¸Šï¼‰- Tokenizeråº“</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B9%E6%8D%AE%E5%B7%B2%E6%9C%89%E7%9A%84tokenizer%E8%AE%AD%E7%BB%83%E6%96%B0%E7%9A%84tokenizer"><span class="toc-text"> æ ¹æ®å·²æœ‰çš„tokenizerè®­ç»ƒæ–°çš„tokenizer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E5%87%86%E5%A4%87%E8%AF%AD%E6%96%99%E5%BA%93"><span class="toc-text"> 1.å‡†å¤‡è¯­æ–™åº“</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84tokenizer"><span class="toc-text"> 2.è®­ç»ƒä¸€ä¸ªæ–°çš„Tokenizer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E4%BF%9D%E5%AD%98tokenizer"><span class="toc-text"> 3.ä¿å­˜Tokenizer</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BF%AB%E9%80%9F%E6%A0%87%E8%AE%B0%E5%99%A8%E7%9A%84%E7%89%B9%E6%AE%8A%E8%83%BD%E5%8A%9B"><span class="toc-text"> å¿«é€Ÿæ ‡è®°å™¨çš„ç‰¹æ®Šèƒ½åŠ›</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E6%89%B9%E9%87%8F%E7%BC%96%E7%A0%81"><span class="toc-text"> 1.æ‰¹é‡ç¼–ç </span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2token%E5%88%86%E7%B1%BB%E7%AE%A1%E9%81%93%E5%86%85%E9%83%A8"><span class="toc-text"> 2.tokenåˆ†ç±»ç®¡é“å†…éƒ¨</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E7%AE%A1%E9%81%93%E8%8E%B7%E5%BE%97%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%9C"><span class="toc-text"> é€šè¿‡ç®¡é“è·å¾—åŸºæœ¬ç»“æœ</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8E%E8%BE%93%E5%85%A5%E5%88%B0%E9%A2%84%E6%B5%8B"><span class="toc-text"> ä»è¾“å…¥åˆ°é¢„æµ‹</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E7%BB%84%E5%AE%9E%E4%BD%93"><span class="toc-text"> åˆ†ç»„å®ä½“</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#qa-%E7%AE%A1%E9%81%93%E4%B8%AD%E7%9A%84%E5%BF%AB%E9%80%9F%E6%A0%87%E8%AE%B0%E5%99%A8"><span class="toc-text"> QA ç®¡é“ä¸­çš„å¿«é€Ÿæ ‡è®°å™¨</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BD%BF%E7%94%A8%E9%97%AE%E7%AD%94%E7%AE%A1%E9%81%93"><span class="toc-text"> 1. ä½¿ç”¨é—®ç­”ç®¡é“</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E9%97%AE%E7%AD%94"><span class="toc-text"> 2.ä½¿ç”¨æ¨¡å‹è¿›è¡Œé—®ç­”</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E5%A4%84%E7%90%86%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87"><span class="toc-text"> 3.å¤„ç†é•¿ä¸Šä¸‹æ–‡</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%87%E5%87%86%E5%8C%96%E5%92%8C%E9%A2%84%E6%A0%87%E8%AE%B0%E5%8C%96"><span class="toc-text"> æ ‡å‡†åŒ–å’Œé¢„æ ‡è®°åŒ–</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1normalization"><span class="toc-text"> 1.Normalization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E9%A2%84%E6%A0%87%E8%AE%B0%E5%8C%96"><span class="toc-text"> 2.é¢„æ ‡è®°åŒ–</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3sentencepiece"><span class="toc-text"> 3.SentencePiece</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%E7%AE%97%E6%B3%95%E7%BB%BC%E8%BF%B0"><span class="toc-text"> 4.ç®—æ³•ç»¼è¿°</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-text"> </span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>æœ€æ–°æ–‡ç« </span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/20/NLP_Course(7.1)/" title="NLPè¯¾ç¨‹ï¼ˆä¸ƒ/ä¸€ï¼‰- Tokenåˆ†ç±»">NLPè¯¾ç¨‹ï¼ˆä¸ƒ/ä¸€ï¼‰- Tokenåˆ†ç±»</a><time datetime="2024-09-20T14:40:33.000Z" title="å‘è¡¨äº 2024-09-20 22:40:33">2024-09-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/20/NLP_Course(6.3)/" title="NLPè¯¾ç¨‹ï¼ˆå…­-ä¸‹ï¼‰- é€å—æ„å»ºåˆ†è¯å™¨">NLPè¯¾ç¨‹ï¼ˆå…­-ä¸‹ï¼‰- é€å—æ„å»ºåˆ†è¯å™¨</a><time datetime="2024-09-20T14:39:33.000Z" title="å‘è¡¨äº 2024-09-20 22:39:33">2024-09-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/20/NLP_Course(6.2)/" title="NLPè¯¾ç¨‹ï¼ˆå…­-ä¸­ï¼‰- ä¸‰ç§æ ‡è®°åŒ–">NLPè¯¾ç¨‹ï¼ˆå…­-ä¸­ï¼‰- ä¸‰ç§æ ‡è®°åŒ–</a><time datetime="2024-09-20T14:35:33.000Z" title="å‘è¡¨äº 2024-09-20 22:35:33">2024-09-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/20/NLP_Course(6.1)/" title="NLPè¯¾ç¨‹ï¼ˆå…­-ä¸Šï¼‰- Tokenizeråº“">NLPè¯¾ç¨‹ï¼ˆå…­-ä¸Šï¼‰- Tokenizeråº“</a><time datetime="2024-09-20T14:34:33.000Z" title="å‘è¡¨äº 2024-09-20 22:34:33">2024-09-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/20/NLP_Course(5)/" title="NLPè¯¾ç¨‹ï¼ˆäº”ï¼‰- Datasetsåº“">NLPè¯¾ç¨‹ï¼ˆäº”ï¼‰- Datasetsåº“</a><time datetime="2024-09-20T14:33:33.000Z" title="å‘è¡¨äº 2024-09-20 22:33:33">2024-09-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2024 By HUI</div><div class="framework-info"><span>æ¡†æ¶ </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>ä¸»é¢˜ </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><button id="chat-btn" type="button" title="èŠå¤©"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="ç›´è¾¾è¯„è®º"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.jsdelivr.net/npm/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script><script>(() => {
  const disqus_config = function () {
    this.page.url = 'http://example.com/2024/09/20/NLP_Course(6.1)/'
    this.page.identifier = '/2024/09/20/NLP_Course(6.1)/'
    this.page.title = 'NLPè¯¾ç¨‹ï¼ˆå…­-ä¸Šï¼‰- Tokenizeråº“'
  }

  const disqusReset = () => {
    window.DISQUS && window.DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  btf.addGlobalFn('themeChange', disqusReset, 'disqus')

  const loadDisqus = () =>{
    if (window.DISQUS) disqusReset()
    else {
      const script = document.createElement('script')
      script.src = 'https://.disqus.com/embed.js'
      script.setAttribute('data-timestamp', +new Date())
      document.head.appendChild(script)
    }
  }

  const getCount = async() => {
    try {
      const eleGroup = document.querySelector('#post-meta .disqus-comment-count')
      if (!eleGroup) return
      const cleanedLinks = eleGroup.href.replace(/#post-comment$/, '')

      const res = await fetch(`https://disqus.com/api/3.0/threads/set.json?forum=&api_key=&thread:link=${cleanedLinks}`,{
        method: 'GET'
      })
      const result = await res.json()

      const count = result.response.length ? result.response[0].posts : 0
      eleGroup.textContent = count
    } catch (err) {
      console.error(err)
    }
  }

  if ('Valine' === 'Disqus' || !false) {
    if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
    else {
      loadDisqus()
      GLOBAL_CONFIG_SITE.isPost && getCount()
    }
  } else {
    window.loadOtherComment = loadDisqus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>