<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>SwinTransformer论文精读 | HUI</title><meta name="author" content="HUI"><meta name="copyright" content="HUI"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="原文：https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2103.14030 参考：Swin Transformer论文精读【论文精读】哔哩哔哩_bilibili  Swin Transformer  摘要 本文提出了一种新的vision Transformer，称为 Swin Transformer，它能够作为计算机视觉领域的通用骨干网络。将 Transformer 从语言领域应用到视觉的挑战源于两个">
<meta property="og:type" content="article">
<meta property="og:title" content="SwinTransformer论文精读">
<meta property="og:url" content="http://example.com/2024/09/23/%E8%AE%BA%E6%96%87/SwinTransformer/index.html">
<meta property="og:site_name" content="HUI">
<meta property="og:description" content="原文：https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2103.14030 参考：Swin Transformer论文精读【论文精读】哔哩哔哩_bilibili  Swin Transformer  摘要 本文提出了一种新的vision Transformer，称为 Swin Transformer，它能够作为计算机视觉领域的通用骨干网络。将 Transformer 从语言领域应用到视觉的挑战源于两个">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/172840755.png">
<meta property="article:published_time" content="2024-09-23T07:07:46.000Z">
<meta property="article:modified_time" content="2024-09-27T13:40:03.906Z">
<meta property="article:author" content="HUI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/172840755.png"><link rel="shortcut icon" href="/img/122061154_p0_master1200.jpg"><link rel="canonical" href="http://example.com/2024/09/23/%E8%AE%BA%E6%96%87/SwinTransformer/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'SwinTransformer论文精读',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-09-27 21:40:03'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/bronya.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (false) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/87788970_p0_master1200.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">33</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 時間軸</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 標籤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分類</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清單</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音樂</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 電影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友鏈</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 關於</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/172840755.png')"><nav id="nav"><span id="blog-info"><a href="/" title="HUI"><img class="site-icon" src="/img/319E33068A7ED73BAE7EB48FCE321DD4.jpg"/><span class="site-name">HUI</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 時間軸</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 標籤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分類</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清單</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音樂</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 電影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友鏈</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 關於</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">SwinTransformer论文精读</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-09-23T07:07:46.000Z" title="发表于 2024-09-23 15:07:46">2024-09-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-09-27T13:40:03.906Z" title="更新于 2024-09-27 21:40:03">2024-09-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/">论文</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/CV/">CV</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">11.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>39分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="SwinTransformer论文精读"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2024/09/23/%E8%AE%BA%E6%96%87/SwinTransformer/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2024/09/23/%E8%AE%BA%E6%96%87/SwinTransformer/" itemprop="commentCount"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>原文：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.14030">https://arxiv.org/abs/2103.14030</a></p>
<p>参考：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV13L4y1475U/?spm_id_from=333.999.0.0&amp;vd_source=6f5eec9fed4d83b5f5ededb2b9c7f548">Swin Transformer论文精读【论文精读】哔哩哔哩_bilibili</a></p>
<h1 id="swin-transformer"><a class="markdownIt-Anchor" href="#swin-transformer"></a> Swin Transformer</h1>
<h2 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h2>
<p>本文提出了一种新的vision Transformer，称为 <strong>Swin Transformer</strong>，它能够作为计算机视觉领域的通用骨干网络。将 Transformer 从语言领域应用到视觉的挑战源于两个领域之间的差异，例如视觉实体规模的巨大差异<font color="YellowGreen">（相同语义的实体在不同场景不同图像中尺寸差异大）</font>以及图像中像素与文本中单词相比的高分辨率<font color="YellowGreen">（以像素点为基本单位的话，序列长度会变得非常长）</font>。为了解决这些差异，我们提出了一个<strong>分层 Transformer</strong>，其表示是使用 <strong>Shifted windows</strong> 计算得到的。<font color="red">移位窗口方案通过将自注意力计算限制在非重叠的本地窗口，同时还允许跨窗口连接，带来了更高的效率。</font>这种层次结构非常灵活，能够提供各种层次的尺度信息，并且具有相对于图像大小线性增长的计算复杂性<font color="YellowGreen">（注意力是在窗口内计算的）</font>。 Swin Transformer 的这些品质使其能够兼容广泛的视觉任务，包括<strong>图像分类</strong>（ImageNet-1K 上的 87.3 top-1 准确度）和<strong>密集预测任务</strong>:例如<strong>对象检测</strong>（COCO testdev 上的 58.7 box AP 和 51.1 mask AP）和<strong>语义分割</strong>（ADE20K val 上为 53.5 mIoU）。其性能在 COCO 上大幅超越了之前的最先进水平，为 +2.7 box AP 和 +2.6 mask AP，在 ADE20K 上为 +3.2 mIoU，展示了基于 Transformer 的模型作为视觉backbone的潜力。<strong>分层设计</strong>和<strong>移位窗口</strong>方法也被证明对全MLP架构有益。代码和模型可在 <a target="_blank" rel="noopener" href="https://github.com/microsoft/Swin-Transformer%E4%B8%8A%E5%85%AC%E5%BC%80%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/microsoft/Swin-Transformer上公开获取。</a></p>
<blockquote>
<p><font color="YellowGreen">VIT原论文只把Transformer应用到了分类，而将检测分割等一系列任务留给了后人去探索。Swin Transformer的研究动机之一就是表明Transformer确实可以用于更多的cv领域，且性能远胜于CNN。</font></p>
</blockquote>
<blockquote>
<p><font color="YellowGreen"><strong>两大特点</strong>：</font></p>
<ul>
<li><font color="YellowGreen">分层特征表示</font></li>
<li><font color="YellowGreen">相对于图像大小线性增长的计算复杂性</font></li>
</ul>
</blockquote>
<h2 id="1介绍"><a class="markdownIt-Anchor" href="#1介绍"></a> 1.介绍</h2>
<p><font color="red">在本文中，我们寻求扩展 Transformer 的适用性，使其可以作为视觉领域的通用backbone。</font>将Transformer在语言领域的高性能转移到视觉领域的重大挑战可以通过两种模式之间的差异来解释。这些差异之一涉及<strong>规模</strong>。</p>
<ol>
<li>与作为语言 Transformer 中处理基本元素的单词标记不同，视觉元素在规模上可能存在很大差异，在现有的基于 Transformer 的模型中，tokrn都是固定规模的，不适合视觉应用。</li>
<li>另一个区别是图像中像素的分辨率比文本段落中的单词要高得多。存在许多视觉任务，例如语义分割，需要在像素级进行密集预测，这对于高分辨率图像上的 Transformer 来说是很棘手的，因为其自注意力的计算复杂度与图像大小成二次方。</li>
</ol>
<p>为了克服这些问题，我们提出了一个通用的Transformer主干，称为 <strong>Swin Transformer</strong>，它构建<strong>分层特征图</strong>，并且具有与<strong>图像大小线性相关</strong>的计算复杂度。如图 1(a) 所示，Swin Transformer 通过从小尺寸patch（灰色轮廓）开始并逐渐合并更深 Transformer 层中的相邻patch来构建分层表示。将这些分层特征图输入给<strong>特征金字塔网络</strong> (<strong>FPN</strong>) 或 <strong>U-Ne，Swin Transformer模型可以方便地进行密集预测</strong>。<strong>线性计算复杂度</strong>是通过在分割图像的非重叠窗口（以红色框出）内计算自注意力来实现的。每个窗口中的补丁数量是固定的，因此复杂度与图像大小成线性关系<font color="YellowGreen">（图片增大多少倍，窗口数量就增大多少倍，计算复杂度也相应增大多少倍）</font>。这些优点使 Swin Transformer 适合作为各种视觉任务的通用骨干网络，与之前基于 Transformer 的架构形成鲜明对比，后者生成单一分辨率的特征图并具有二次复杂度。</p>
<blockquote>
<p><font color="YellowGreen">对于目标检测或者分割任务来说，多尺寸的特征是十分重要的.</font></p>
<p><font color="YellowGreen"><strong>目标检测</strong>：当有了一个分层的卷积神经网络之后，每一层的特征图的感受野是不一样的，它能抓住物体不同尺寸的特征。</font></p>
<p><font color="YellowGreen"><strong>分割</strong>：U-Net为了处理物体不同尺寸的问题，提出了一个skip connection的方法，即在上采样的时候不止从BottleNet里拿特征，还从之前下采样得到的特征图那里拿特征。从而恢复图像的细节。</font></p>
</blockquote>
<blockquote>
<p><font color="YellowGreen"><strong>为什么计算小窗口内的自注意力</strong>：</font></p>
<ul>
<li><font color="YellowGreen">利用了卷积神经网络中的归纳偏置作为先验知识，即同一个物体的不同部位或者语义相近的不同物体还是大概率会出现在相连的地方，所以在一个小范围内算自注意力差不多也是够用的。全局算子注意力对于视觉任务来说可能有些浪费资源。</font></li>
<li><font color="YellowGreen">在卷积神经网络中通过池化操作增大每一个卷积核能看到的感受野，使得每次池化后的特征能抓住物体的不同尺寸。Swin Transformer通过<strong>patch merging</strong>来类比池化，将小patch合并为大patch，大patch能看到合并前小patch的内容，从而增大感受野，抓住多尺寸的特征。</font></li>
</ul>
</blockquote>
<p><img src="155856262.png" alt></p>
<p>图 1. (a) 所提出的 Swin Transformer 通过合并更深层中的图像块（以灰色显示）来构建分层特征图，并且由于仅在每个局部窗口内计算自注意力（以红色显示），因此具有于输入图像大小线性相关的计算复杂性）。因此，它可以作为图像<strong>分类</strong>和<strong>密集识别任务</strong>的通用主干。 (b) 相比之下，之前的视觉 Transformers产生单个低分辨率的特征图，并且由于全局自注意力的计算，输入图像大小的计算复杂度是二次方的。</p>
<p><font color="red">Swin Transformer 的一个<strong>关键设计因素</strong>是<strong>连续自注意力层之间窗口的移动</strong>，如图2所示。移动的窗口连接了前一层的窗口，提供了它们之间的连接，从而显着增强了建模能力（参见表4）。</font>这种策略在现实世界的如下方面也很有效：<font color="red">同一个窗口内的所有query patches共享相同的key set，这有利于硬件中的内存访问</font>。相比之下，早期基于滑动窗口的自注意力方法由于不同query像素的key set不同，因此在通用硬件上延迟较低。我们的实验表明，window shift方法的延迟比滑动窗口方法低得多，但建模能力相似（参见表 5 和表 6）。事实证明，移位窗口方法对于全MLP架构也是有益的 。</p>
<blockquote>
<p><font color="YellowGreen"><strong>窗口的移动</strong>：</font></p>
<p><font color="YellowGreen">在第L层的特征图中，首先通过像特征图划分为小窗口来有效降低序列长度，从而减小计算复杂度.图中<strong>灰框</strong>的patch是最小的基本单元即4*4的<strong>patch</strong>，<strong>红色的框</strong>是一个中型的计算的单元即一个<strong>window</strong>（窗口），在Swin Transformer中默认一个window有7x7=49个patch，图2仅是示意图。所谓的<strong>shift</strong>操作就是往右下角移动2个patch，然后再划分新的窗口。好处在于建立了windows之间的联系，如果没有shift，那么这些窗口都是不重叠的。若每个自注意力都在各自的窗口内进行，那么就一个patch无法注意到别的窗口里的patch的信息，达不到使用Transformer的初衷（更好的理解上下文）了，就没有全局建模的能力。</font></p>
<p>于是乎，加上patch merging操作，到最后一层每个patch的感受野就非常之大了，所谓的窗口内的自注意力操作可以等价为全局自注意力操作了</p>
</blockquote>
<p><img src="163425144.png" alt></p>
<p>图 2. 在所提出的 Swin Transformer 架构中计算自注意力的移动窗口方法的图示。在l层（左）中，采用常规窗口划分方案，并在每个窗口内计算自注意力。在下一层l+1（右）中，窗口分区发生移动，产生新的窗口。新窗口中的自注意力计算跨越了l层中先前窗口的边界，提供了它们之间的连接。</p>
<p>Swin Transformer 在图像分类、目标检测和语义分割等识别任务上取得了强大的性能。它的性能显着优于 ViT/DeiT和 ResNe(X)t 模型，并且三个任务的延迟相似。</p>
<h2 id="2相关工作"><a class="markdownIt-Anchor" href="#2相关工作"></a> 2.相关工作</h2>
<p><strong>卷积神经网络及其变体</strong></p>
<p><strong>以自注意力为骨干的架构</strong>：同样受到自注意力层和 Transformer 架构在 NLP 领域成功的启发，一些作品采用自注意力层来取代流行的 ResNet中的部分或全部空间卷积层。在这些工作中，自注意力是在每个像素的局部窗口内计算的，以加速优化，并且它们实现了比对应的 ResNet 架构稍微更好的精度/FLOPs 权衡。然而，它们昂贵的内存访问导致它们的实际延迟明显大于卷积网络。我们建议不使用滑动窗口，而是在连续层之间移动窗口，这样可以在通用硬件中更有效地实现。</p>
<p><strong>自注意力/Transformers 来补充 CNN</strong>：另一项工作是使用自注意力层或 Transformer 来增强标准 CNN 架构。自注意力层可以通过提供远程编码依赖或异构交互的能力来补充主干网络或头部网络。</p>
<p><strong>基于 Transformer 的视觉主干</strong>：虽然 ViT 需要大规模训练数据集（即 JFT-300M）才能表现良好，但 DeiT引入了几种训练策略，使 ViT 使用较小的 ImageNet-1K 数据集也能有效。 <font color="red">ViT 在图像分类上的结果令人鼓舞，但其架构不适合用作密集视觉任务或输入图像分辨率很高时的通用骨干网络。由于其低分辨率特征图以及复杂性随着图像大小的二次方增加。有一些工作通过直接上采样或反卷积将 ViT 模型应用于对象检测和语义分割的密集视觉任务，但性能相对较低。</font>与我们的工作同时进行的是一些修改 ViT 架构以实现更好的图像分类。根据经验，我们发现我们的 Swin Transformer 架构可以在图像分类的这些方法之间实现最佳的速度准确度权衡，尽管我们的工作重点是通用性能而不是专门针对分类。另一项并行工作探索了在 Transformers 上构建多分辨率特征图的类似思路。它的复杂性仍然与图像大小成二次方，而我们的复杂性是线性的并且也在本地运行，这已被证明有利于对视觉信号的高相关性进行建模。我们的方法既高效又有效，在COCO上实现了最先进的准确性。</p>
<blockquote>
<p><font color="YellowGreen">ViT不适合作为视觉通用模型的backbone，尽管在分类任务上表现不错，但在目标检测、分割等的视觉任务上，在处理高分辨率图像时由于计算复杂性随着图像大小的二次方增加，导致了计算资源的巨大增长。若用降采样的方法依旧保持少量的patch数，那么高分辨率带来的优势就没有了。</font></p>
</blockquote>
<h2 id="3方法"><a class="markdownIt-Anchor" href="#3方法"></a> 3.方法</h2>
<h3 id="31整体架构"><a class="markdownIt-Anchor" href="#31整体架构"></a> 3.1整体架构</h3>
<p><img src="172840755.png" alt></p>
<p>图 3.(a) Swin Transformer (<strong>Swin-T</strong>) 的架构； (b) 两个连续的 Swin 变压器块（用方程 (3) 表示的符号）。 W-MSA 和 SW-MSA 是分别具有正则和shifted window配置的多头自注意力模块。</p>
<p>图 3 是Swin Transformer的整体架构的微型版本 (SwinT)。它首先通过patch分割模式（如 ViT）将输入的RGB 图像分割成不重叠的patch。每个patch都被视为一个“toekn”，其特征被设置为原始像素 RGB 值的串联。在我们的实现中，我们使用的patch大小为4×4，因此每个patch的特征维度为4×4×3=48。线性嵌入层应用于此原始值特征，将其投影到任意维度（记为C)。</p>
<p>在这些patch tokens上应用了几个经过修改的自注意力机制的 Transformer 块（Swin Transformer 块）。Transformer块维持token的数量 (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>H</mi><mn>4</mn></mfrac><mo>×</mo><mfrac><mi>W</mi><mn>4</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{H}{4} \times \frac{W}{4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>)不变，并与线性嵌入一起称为“<strong>阶段1</strong>”。</p>
<p><strong>为了产生分层表示</strong>，随着网络变得更深，通过patch merging层来减少token的数量。第一个patch合并层连接每组2×2相邻patch的特征，并在4C维连接特征上应用线性层。这将标记数量减少了2×2=4 倍（分辨率下采样 2 倍），并且输出维度设置为 2C。随后应用 Swin Transformer块进行特征转换，分辨率保持在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>H</mi><mn>8</mn></mfrac><mo>×</mo><mfrac><mi>W</mi><mn>8</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{H}{8} \times \frac{W}{8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 。补丁合并和特征转换的第一个块被表示为“阶段 2”。该过程重复两次，即“阶段 3”和“阶段 4”，输出分辨率分别为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>H</mi><mn>16</mn></mfrac><mo>×</mo><mfrac><mi>W</mi><mn>16</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{H}{16} \times \frac{W}{16}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">6</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">6</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>H</mi><mn>32</mn></mfrac><mo>×</mo><mfrac><mi>W</mi><mn>32</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{H}{32} \times \frac{W}{32}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 。这些阶段共同产生分层表示，具有与典型卷积网络相同的特征图分辨率，例如VGG和ResNet 。因此，所提出的架构可以方便地替换现有方法中用于各种视觉任务的主干网络。</p>
<p><strong>Swin Transformer块</strong>：通过将 Transformer 模块中的<strong>标准多头自注意力</strong>（MSA）模块替换为<strong>基于移位窗口</strong>（第 3.2 节中描述）的模块而构建的，其他层保持不变。如图 3(b) 所示，Swin Transformer 模块由基于移位窗口的 MSA 模块组成，后跟中间带有 GELU 非线性的 2 层 MLP。在每个MSA模块和每个MLP之前应用LayerNorm (LN) 层，并在每个模块之后应用残差连接。</p>
<blockquote>
<p><font color="YellowGreen"><strong>举例</strong>：</font></p>
<p><font color="YellowGreen">假设images大小为[224,224,3],，在Swin Transformer中patch大小为4*4，打成patch之后图像大小为[56,56,48],线性嵌入层将通道维度变为Transformer能够接受的数C，在Swin-T为96，故输入Swin Transformer bloclk的图序列大小为[56x56=3196,96]，3196是Transformer不能接受的序列长度，所以Swin Transformer通过基于窗口的模式来减少计算量，每个窗口有7x7=49个patch，即序列长度只有49。由于Transformer block的输入输出维度不变，输出还是[3196,96],处理一下变为[56,56,96]。</font></p>
<p><img src="122533716.png" alt></p>
<p><font color="YellowGreen"><strong>patch merging</strong>:为了获得多尺寸特征，需要有类似于卷积神经网络中的池化操作，这里即patch merging。patch merging类似于pixel shuffle上采样的反过程。由于下采样两倍，所以隔一个选一个（下图中的数字不是值，只是一个序号），之后通过一个1x1卷积将通道维度由4C变为2C（为了与卷积神经网络一致，在下采样两倍后，通道维度变为原先的两倍）</font></p>
<p><img src="120719543.png" alt></p>
<p><font color="YellowGreen">因为Swin Transformer不是单纯用于分类任务，图中只给出了backbone网络。在做分类任务时，Swin Transformer没有用VIT中[CLS] token作为输出，而是将最后输出7x7的特征图做了全局池化操作变为了[1，1，768]</font></p>
</blockquote>
<h3 id="32-基于shifted-window的自注意力"><a class="markdownIt-Anchor" href="#32-基于shifted-window的自注意力"></a> 3.2 基于Shifted Window的自注意力</h3>
<p>标准Transformer架构及其对图像分类的应用都进行全局自注意力(计算token与所有其他token之间的关系)。<font color="red">全局计算导致toekn数量二次方的复杂度，使其不适合许多需要大量token来进行密集预测或表示高分辨率图像的视觉问题。</font></p>
<p><strong>非重叠窗口中的自注意力</strong>: 为了有效建模，我们建议在窗口内部计算自注意力。窗口被布置为以不重叠的方式均匀地划分图像。假设每个窗口包含M×M个patch，则<strong>全局MSA模块</strong>和基于h×w个补丁图像的窗口的计算复杂度为(我们在确定复杂性时省略了 SoftMax 计算)。：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Ω</mtext><mo stretchy="false">(</mo><mi>M</mi><mi>S</mi><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mn>4</mn><mi>h</mi><mi>w</mi><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><mo stretchy="false">(</mo><mi>h</mi><mi>w</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mi>C</mi></mrow><annotation encoding="application/x-tex">Ω(MSA) = 4hwC^{2} + 2(hw)^{2}C
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Ω</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9474379999999999em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mopen">(</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Ω</mtext><mo stretchy="false">(</mo><mi>W</mi><mo>−</mo><mi>M</mi><mi>S</mi><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mn>4</mn><mi>h</mi><mi>w</mi><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><msup><mi>M</mi><mn>2</mn></msup><mi>h</mi><mi>w</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">Ω(W-MSA) = 4hwC^{2} + 2M^{2}hwC
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Ω</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9474379999999999em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8641079999999999em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span></p>
<p>其中前者与patch数hw成二次方，后者在M固定（默认设置为7）时呈线性。<font color="red">全局自注意力计算通常无法承受过大的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>w</mi></mrow><annotation encoding="application/x-tex">hw</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span>，而基于窗口的自注意力是可扩展的。</font></p>
<blockquote>
<p><font color="YellowGreen">继续以特征图[56,56,48]举例，Swin Transformer中窗口大小是7x7个patch，所以特征图[56,56,48]被划分为8x8=64个窗口。</font></p>
<p><img src="134539198.png" alt></p>
<p><font color="YellowGreen">公式(1):<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>w</mi><mo>∗</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">hw*c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span>经过(c,c)的系数矩阵得到qkv，计算量为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi>h</mi><mi>w</mi><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">3hwC^{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><msup><mi>k</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">qk^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>,AV的计算量各为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>h</mi><mi>w</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mi>C</mi></mrow><annotation encoding="application/x-tex">(hw)^2C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>，再经过线性投射层(c,c)的计算量为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>w</mi><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">hwC^{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>，加起来即为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>h</mi><mi>w</mi><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><mo stretchy="false">(</mo><mi>h</mi><mi>w</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mi>C</mi></mrow><annotation encoding="application/x-tex">4hwC^{2} + 2(hw)^{2}C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mopen">(</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></font></p>
<p><font color="YellowGreen">公式(2):对于每个窗口而言，hw都替换为M，计算量为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><msup><mi>M</mi><mn>2</mn></msup><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><mo stretchy="false">(</mo><mi>M</mi><msup><mo stretchy="false">)</mo><mn>4</mn></msup><mi>C</mi></mrow><annotation encoding="application/x-tex">4M^2C^{2} + 2(M)^{4}C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>，一共有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>w</mi><mi mathvariant="normal">/</mi><msup><mi>M</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">hw/M^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord">/</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>个窗口，总和为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>h</mi><mi>w</mi><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><msup><mi>M</mi><mn>2</mn></msup><mi>h</mi><mi>w</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">4hwC^{2} + 2M^{2}hwC</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>。</font></p>
</blockquote>
<p><strong>连续块中的移位窗口</strong> <font color="red">基于窗口的自注意力模块缺乏跨窗口的连接，这限制了其建模能力。</font>为了引入跨窗口连接，同时保持非重叠窗口的高效计算，我们提出了一种<strong>移位窗口</strong>方法，该方法在连续 Swin Transformer 块中的两个分区配置之间交替。</p>
<blockquote>
<p>如图3(b)所示,两个Swin Transformer 块中一个是W-MSA,另一个是SW-MSA，这也是为什么图3(a)中Swin Transformer 块都是x2的原因。</p>
</blockquote>
<p>如图 2 所示，第一个模块使用从左上角像素开始的常规窗口划分策略，将 8 × 8 特征图均匀划分为大小为4×4 (M=4) 的2×2窗口。然后，下一个模块采用与前一层的窗口配置不同的窗口配置，通过将窗口从规则划分的窗口中移动（[<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>M</mi><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{M}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>]，[<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>M</mi><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{M}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>]）个像素。使用移位窗口分区方法，连续的 Swin Transformer 块计算如下</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.15999999999999992em" columnalign="left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msup><mover accent="true"><mi>z</mi><mo>^</mo></mover><mi>l</mi></msup><mo>=</mo><mi>W</mi><mo>−</mo><mi>M</mi><mi>S</mi><mi>A</mi><mo stretchy="false">(</mo><mi>L</mi><mi>N</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mrow><mi>l</mi><mtext>−</mtext><mn>1</mn></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><msup><mi>z</mi><mrow><mi>l</mi><mtext>−</mtext><mn>1</mn></mrow></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msup><mi>z</mi><mi>l</mi></msup><mo>=</mo><mi>M</mi><mi>L</mi><mi>P</mi><mo stretchy="false">(</mo><mi>L</mi><mi>N</mi><mo stretchy="false">(</mo><msup><mover accent="true"><mi>z</mi><mo>^</mo></mover><mi>l</mi></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><msup><mover accent="true"><mi>z</mi><mo>^</mo></mover><mi>l</mi></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msup><mover accent="true"><mi>z</mi><mo>^</mo></mover><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mi>S</mi><mi>W</mi><mo>−</mo><mi>M</mi><mi>S</mi><mi>A</mi><mo stretchy="false">(</mo><mi>L</mi><mi>N</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mi>l</mi></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><msup><mi>z</mi><mi>l</mi></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msup><mi>z</mi><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mi>M</mi><mi>L</mi><mi>P</mi><mo stretchy="false">(</mo><mi>L</mi><mi>N</mi><mo stretchy="false">(</mo><msup><mover accent="true"><mi>z</mi><mo>^</mo></mover><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><msup><mover accent="true"><mi>z</mi><mo>^</mo></mover><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{l}
\hat{z} ^{l} = W-MSA(LN(z^{l−1})) + z^{l−1} \\
z^{l} = MLP(LN(\hat{z}^{l})) + \hat{z}^{l}\\
\hat{z} ^{l+1} = SW-MSA(LN(z^{l})) + z^{l}\\
z^{l+1} = MLP(LN(\hat{z}^{l+1})) + \hat{z}^{l+1}
\end{array}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.836431999999999em;vertical-align:-2.1682159999999997em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.6682159999999997em;"><span style="top:-4.819108em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">A</span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.6099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span></span></span></span><span style="top:-2.400892em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">A</span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span></span></span></span><span style="top:-1.1917840000000004em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.1682159999999997em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>z</mi><mo>^</mo></mover><mi>l</mi></msup></mrow><annotation encoding="application/x-tex">\hat{z} ^{l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>z</mi><mi>l</mi></msup></mrow><annotation encoding="application/x-tex">z^{l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span></span></span></span></span>分别表示块L的 (S)W-MSA 模块和MLP模块的输出特征；W-MSA和SW-MSA 分别表示使用<strong>常规</strong>(<font color="YellowGreen">不移位</font>)和<strong>移位窗口</strong>配置的基于窗口的多头自注意力。<font color="red">移位窗口分割方法在前一层中引入相邻非重叠窗口之间的连接，并且被发现在图像分类、对象检测和语义分割中有效，如表4所示。</font></p>
<p><strong>对于shifted window的高效batch配置</strong>： 计算移位窗口分区的一个问题是，它将导致更多的窗口，从移位配置中的[<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>h</mi><mi>M</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{h}{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>]，[<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>w</mi><mi>M</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{w}{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.040392em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>]到([<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>h</mi><mi>M</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{h}{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>]+1，[<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>w</mi><mi>M</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{w}{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.040392em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>]+1)<font color="YellowGreen">(以图2为例，4个变9个)</font>，并且一些窗口将小于M×M(为了使窗口大小 (M, M) 可除以 (h, w) 的特征图大小，如果需要，可以在特征图上使用右下填充)。<font color="red">一个简单的解决方案是将较小的窗口填充到 M×M 的大小，并在计算注意力时屏蔽掉填充的值。</font>当常规分区中的窗口数量较少时，例如2×2，这种朴素解决方案增加的计算量是相当可观的（2×2→3×3，增加了 2.25 倍）。在这里，我们提出了一种更有效的批量计算方法，通过向左上方向循环移位，如图 4 所示。经过这种移位，批处理窗口可能由多个在特征图中不相邻的子窗口组成，因此采用屏蔽机制将自注意力计算限制在每个子窗口内。通过循环移位，批处理窗口的数量保持与常规窗口划分相同，因此也是高效的。这种方法的低延迟如表 5 所示。</p>
<p><img src="094545448.png" alt></p>
<center>图 4. 移位窗口分区中自注意力的高效批量计算方法的图示。</center>
<blockquote>
<p><strong>问题</strong>：移位窗口导致窗口数量变多且窗口大小不一，不同的窗口大小不能统一输入Transformer做自注意力，因此可以做零填充然后算注意力的时候屏蔽掉填充。但是会导致计算量的显著提高。</p>
<p><strong>解决办法</strong>：<strong>循环移位</strong>+<strong>掩码</strong>，<strong>循环移位</strong>把原图中ABC三块区域移动拼接到另一边去形成新的图，这样还是四个窗口且窗口大小同。问题在于原先的ABC三个区域与他们所拼接的区域是不应该算自注意力的，这就要用到<strong>掩码</strong>。在做完masked MSA之后要将循环移位后的区域还原回去，否则会破坏原图像的语义信息。</p>
<p><strong>masked MSA</strong>：</p>
<p><img src="161222.jpg" alt></p>
<p>作者给出的示意图及可视化代码</p>
<p><img src="161041221.png" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">window_partition</span>(<span class="params">x, window_size</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: (B, H, W, C)</span></span><br><span class="line"><span class="string">        window_size (int): window size</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        windows: (num_windows*B, window_size, window_size, C)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    B, H, W, C = x.shape</span><br><span class="line">    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)</span><br><span class="line">    windows = x.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>).contiguous().view(-<span class="number">1</span>, window_size, window_size, C)</span><br><span class="line">    <span class="keyword">return</span> windows</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">window_size = <span class="number">7</span></span><br><span class="line">shift_size = <span class="number">3</span></span><br><span class="line">H, W = <span class="number">14</span>, <span class="number">14</span></span><br><span class="line">img_mask = torch.zeros((<span class="number">1</span>, H, W, <span class="number">1</span>))  <span class="comment"># 1 H W 1</span></span><br><span class="line">h_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -window_size),</span><br><span class="line">            <span class="built_in">slice</span>(-window_size, -shift_size),</span><br><span class="line">            <span class="built_in">slice</span>(-shift_size, <span class="literal">None</span>))</span><br><span class="line">w_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -window_size),</span><br><span class="line">            <span class="built_in">slice</span>(-window_size, -shift_size),</span><br><span class="line">            <span class="built_in">slice</span>(-shift_size, <span class="literal">None</span>))</span><br><span class="line">cnt = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> h <span class="keyword">in</span> h_slices:</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> w_slices:</span><br><span class="line">        img_mask[:, h, w, :] = cnt</span><br><span class="line">        cnt += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">mask_windows = window_partition(img_mask, window_size)  <span class="comment"># nW, window_size, window_size, 1</span></span><br><span class="line">mask_windows = mask_windows.view(-<span class="number">1</span>, window_size * window_size)</span><br><span class="line"></span><br><span class="line">attn_mask = mask_windows.unsqueeze(<span class="number">1</span>) - mask_windows.unsqueeze(<span class="number">2</span>)</span><br><span class="line">attn_mask = attn_mask.masked_fill(attn_mask != <span class="number">0</span>, <span class="built_in">float</span>(-<span class="number">100.0</span>)).masked_fill(attn_mask == <span class="number">0</span>, <span class="built_in">float</span>(<span class="number">0.0</span>))</span><br><span class="line"></span><br><span class="line">plt.matshow(img_mask[<span class="number">0</span>, :, :, <span class="number">0</span>].numpy())</span><br><span class="line">plt.matshow(attn_mask[<span class="number">0</span>].numpy())</span><br><span class="line">plt.matshow(attn_mask[<span class="number">1</span>].numpy())</span><br><span class="line">plt.matshow(attn_mask[<span class="number">2</span>].numpy())</span><br><span class="line">plt.matshow(attn_mask[<span class="number">3</span>].numpy())</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<p>**相对位置偏差 **：在计算自注意力时，，在计算相似度时将相对位置偏差 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>∈</mo><msup><mi>R</mi><mrow><msup><mi>M</mi><mn>2</mn></msup><mo>×</mo><msup><mi>M</mi><mn>2</mn></msup></mrow></msup></mrow><annotation encoding="application/x-tex">B ∈ R^{M^{2}×M^{2}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9869199999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9869199999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> 包含到每个头：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>M</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mi mathvariant="normal">/</mi><msqrt><mi>d</mi></msqrt><mo>+</mo><mi>B</mi><mo stretchy="false">)</mo><mi>V</mi><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">Attention(Q, K, V ) = SoftMax(QK^T/\sqrt{d} + B)V,
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.231095em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981095em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal">d</span></span></span><span style="top:-2.941095em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.058904999999999985em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mpunct">,</span></span></span></span></span></p>
<p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo>∈</mo><msup><mi>R</mi><mrow><msup><mi>M</mi><mn>2</mn></msup><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">Q, K, V ∈ R^{M^{2}×d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9869199999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9869199999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>是Q、K和V矩阵； d 是Q/K维度，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>M</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">M^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>是窗口中的patch数。由于沿每个轴的相对位置位于 [−M+1, M−1] 范围内，因此我们参数化一个较小尺寸的偏置矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>B</mi><mo>^</mo></mover><mo>∈</mo><msup><mi>R</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mi>M</mi><mtext>−</mtext><mn>1</mn><mo stretchy="false">)</mo><mo>×</mo><mo stretchy="false">(</mo><mn>2</mn><mi>M</mi><mtext>−</mtext><mn>1</mn><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\hat{B} ∈ R^{(2M−1)×(2M−1)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9858699999999999em;vertical-align:-0.0391em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="mord mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mbin mtight">×</span><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="mord mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>，并且B中的值取自<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>B</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9467699999999999em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span>.</p>
<p>我们观察到与没有此偏差项或使用绝对位置嵌入的对应项相比有显着改进，如表 4 所示。向输入进一步添加绝对位置嵌入会稍微降低性能，因此在我们的实现中没有采用。预训练中学习到的相对位置偏差也可用于初始化模型，以便通过双三次插值对不同的窗口大小进行微调。</p>
<blockquote>
<p>在VIT中采用的是1D绝对位置编码,且在embeddding过程中直接与 patch embedding相加</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + <span class="number">1</span>, embed_dim)) </span><br><span class="line"></span><br><span class="line"><span class="comment"># patch emded + pos_embed ：图像块嵌入 + 位置嵌入</span></span><br><span class="line">x = x + <span class="variable language_">self</span>.pos_embed</span><br></pre></td></tr></table></figure>
<p><img src="155828.png" alt="Image 1 of 29"></p>
<p>而在Swin Transformer中如公式所示，是在QKV的过程中将<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mi mathvariant="normal">/</mi><msqrt><mi>d</mi></msqrt></mrow><annotation encoding="application/x-tex">QK^T/\sqrt{d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.18222em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.93222em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal">d</span></span></span><span style="top:-2.89222em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.10777999999999999em;"><span></span></span></span></span></span></span></span></span>得到的张量根据相对位置索引加上对应的位置偏置，之后再与V算softmax</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>M</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mi mathvariant="normal">/</mi><msqrt><mi>d</mi></msqrt><mo>+</mo><mi>B</mi><mo stretchy="false">)</mo><mi>V</mi><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">Attention(Q, K, V ) = SoftMax(QK^T/\sqrt{d} + B)V,
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.231095em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981095em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal">d</span></span></span><span style="top:-2.941095em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.058904999999999985em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mpunct">,</span></span></span></span></span></p>
</blockquote>
<h3 id="33-架构变量"><a class="markdownIt-Anchor" href="#33-架构变量"></a> 3.3 架构变量</h3>
<p>我们构建了名为<strong>Swin-B</strong>的基本模型，其模型大小和计算复杂度与 ViTB/DeiT-B 类似。我们还引入了 Swin-T、Swin-S和Swin-L，它们的模型大小和计算复杂度分别约为0.25×、0.5×和2×的Swin-B。请注意，Swin-T 和 Swin-S 的复杂度分别与ResNet-50 (DeiT-S)和ResNet-101相似。默认情况下，窗口大小设置为M = 7。对于所有实验，每个头的query维度为 d = 32，每个 MLP的扩展层为 α = 4。这些模型变体的架构超参数是：</p>
<p>T：Tiny，S：Small，B：Base，L：Large</p>
<ul>
<li>Swin-T：C = 96，层数 = {2, 2, 6, 2}</li>
<li>Swin-S：C = 96，层数 ={2, 2, 18, 2}</li>
<li>Swin-B：C = 128，层数 ={2, 2, 18, 2}</li>
<li>Swin-L：C = 192，层数 ={2, 2, 18, 2}</li>
</ul>
<p>其中C是第一阶段隐藏层的通道数。表1列出了 ImageNet 图像分类模型变体的模型大小、理论计算复杂度 (FLOP) 和吞吐量。</p>
<h2 id="4实验"><a class="markdownIt-Anchor" href="#4实验"></a> 4.实验</h2>
<p>我们在ImageNet-1 图像分类、COCO目标检测和ADE20K语义分割三个任务上进行实验。接下来，我们首先将所提出的 Swin Transformer 架构与之前在这三个任务上的最新技术进行比较。然后，去掉Swin Transformer的重要设计元素再做对比。</p>
<h3 id="41-imagenet-1k-上的图像分类"><a class="markdownIt-Anchor" href="#41-imagenet-1k-上的图像分类"></a> 4.1. ImageNet-1K 上的图像分类</h3>
<p><strong>设置</strong>对于图像分类，我们在 ImageNet-1K 上对Swin Transformer进行基准测试，其中包含来自1,000个类别的128万张训练图像和5万张验证图像。报告了单一作物的top-1准确度。我们考虑两种训练设置：</p>
<ul>
<li><strong>常规 ImageNet-1K训练</strong> 我们使用 AdamW优化器进行 300 个周期，使用余弦衰减学习率和 20 个周期的linear warm-up。批量大小为 1024，初始学习率为 0.001，应用 0.05 的权重衰减。我们在训练中包含了[Training data-efficient image transformers &amp; distillation through attention (<a target="_blank" rel="noopener" href="http://arxiv.org">arxiv.org</a>)](<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2012.12877#:~:text=View">https://arxiv.org/abs/2012.12877#:~:text=View</a> a PDF of the paper titled Training data-efficient image)的大多数增强和正则化策略，除了重复增强和EMA，它们不会提高性能。其中重复增强对于稳定 ViT训练至关重要。</li>
<li><strong>在 ImageNet-22K 上进行预训练并在 ImageNet-1K 上进行微调</strong> 我们还在更大的 ImageNet-22K 数据集进行预训练，该数据集包含 1420 万张图像和 22K 类。我们使用 AdamW 优化器进行 90 个周期，使用线性衰减学习率和 5 个周期的linear warm-up。使用的批量大小为 4096，初始学习率为 0.001，权重衰减为 0.01。在 ImageNet-1K 微调中，我们训练模型30个周期，批量大小为1024，恒定学习率为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mtext>−</mtext><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{−5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span>，权重衰减为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mtext>−</mtext><mn>8</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{−8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span>。</li>
</ul>
<p><strong>常规 ImageNet-1K 训练的结果</strong> 表 1(a) 展示了使用常规 ImageNet-1K 训练与其他主干网络（包括基于 Transformer 和基于 卷积的网络）的比较。与之前最先进的基于 Transformer 的架构（即 DeiT）相比，在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>22</mn><msup><mn>4</mn><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">224^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">2</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>的图像输入的情况下Swin Transformers 明显超过了具有类似复杂性的DeiT架构：<strong>Swin-T</strong> (81.3%) 比 <strong>DeiT-S</strong> (79.8% 提高了1.5%）。在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>22</mn><msup><mn>4</mn><mn>2</mn></msup><mi mathvariant="normal">/</mi><mn>38</mn><msup><mn>4</mn><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">224^2/384^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mord">2</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mord">3</span><span class="mord">8</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 输入<strong>Swin-B</strong> (83.3%/84.5%) 比<strong>DeiT-B</strong> (81.8%/83.1%) 分别增加 1.5%/1.4%。与最先进的卷积神经网络（即 RegNet和EfficientNet ）相比，Swin Transformer 实现了稍微更好的速度与精度权衡。<font color="red">值得注意的是，虽然 RegNet和 EfficientNet是通过彻底的架构搜索获得的，但所提出的 Swin Transformer 是根据标准Transformer改编的，并且具有进一步改进的强大潜力。</font></p>
<p><strong>ImageNet-22K 预训练的结果</strong> 我们还在 ImageNet22K 上预训练了更大容量的 <strong>Swin-B</strong> 和 <strong>Swin-L</strong>。 ImageNet-1K 图像分类的微调结果如表 1(b) 所示。对于 Swin-B，ImageNet22K 预训练比在 ImageNet-1K 上从头开始训练带来了 1.8%∼1.9% 的增益。与之前 ImageNet-22K 预训练的最佳结果相比，我们的模型实现了明显更好的速度与精度权衡：Swin-B 获得了 86.4% 的 top-1 精度，比具有类似推理吞吐量的 ViT 高出 2.4% （84.7 与 85.9 图像/秒）和略低的 FLOP（47.0G 与 55.4G）。较大的 Swin-L 模型实现了87.3% 的top-1准确率，比Swin-B模型高出 0.9%。</p>
<p><img src="174731969.png" alt></p>
<center>表 1. ImageNet-1K 分类上不同主干网的比较。</center>
<h3 id="42-coco上的物体检测"><a class="markdownIt-Anchor" href="#42-coco上的物体检测"></a> 4.2 COCO上的物体检测</h3>
<p>对象检测和实例分割实验 COCO 2017上进行，其中包含118K训练集图像、5K验证集图像和20K测试集图像。使用验证集进行消融研究，并在测试集上比较。对于消融研究，我们考虑四种典型的目标检测框架：<strong>Cascade Mask R-CNN</strong>、<strong>ATSS、RepPoints v2</strong>和<strong>Sparse RCNN</strong>。对于这四个框架，我们使用相同的设置：多尺度训练（调整输入大小，使短边在80到800之间，而长边最多1333）、AdamW 优化器（初始学习率为 0.0001，权重衰减为 0.05，批量大小为16），以及3x调度（36个时期）。对于模型的比较，我们采用改进的HTC（表示为HTC++），具有instaboost 、更强的多尺度训练 、6x调度（72epoch）、soft-NMS 和ImageNet-22K预训练模型作为初始化。</p>
<p>我们将我们的 Swin Transformer与标准卷积神经网络，即ResNe(X)t，以及之前的 Transformer 网络，例如DeiT相比较。比较是通过仅更改backbones而其他设置不变来进行的。<font color="red">请注意，虽然 Swin Transformer 和 ResNe(X)t 由于其分层特征图而直接适用于上述所有框架，但 DeiT 只产生单一分辨率的特征图，不能直接应用。为了公平比较，我们按照使用反卷积层构建 DeiT 的分层特征图。</font></p>
<p><img src="175923601.png" alt></p>
<center>表2.COCO对象检测和实例分割的结果。†表示使用额外的反卷积层来生成分层特征图。 *表示多尺度测试。</center>
<p><strong>与 ResNe(X)t 的比较</strong> 表 2(a) 列出了 Swin-T 和 ResNet-50在四种目标检测框架上的结果。我们的 Swin-T 架构比 ResNet-50 带来一致的 +3.4∼4.2 box AP 增益，但模型尺寸、FLOP 和延迟稍大。表 2(b) 比较了 Swin Transformer 和 ResNe(X)t使用 <strong>Cascade Mask RCNN</strong> 在不同模型容量下的表现。 Swin Transformer 实现了51.9 box AP 和 45.0 mask AP 的高检测精度，与具有相似模型大小、FLOPs 和延迟的 ResNeXt101-64x4d 相比，显着提高了+3.6 box AP和+3.3mask AP。在使用改进的 HTC框架的 52.3 box AP 和 46.0 mask AP 的较高基线上，Swin Transformer 的增益也很高，为 +4.1 box AP 和 +3.1 mask AP（参见表 2©）。关于推理速度，虽然 ResNe(X)t 是由高度优化的 Cudnn 函数构建的，但我们的架构是使用并非全部优化良好的内置PyTorch函数实现的。彻底的内核优化超出了本文的范围。</p>
<p><strong>与DeiT的比较</strong> 使用 Cascade Mask R-CNN 框架的 DeiT-S 的性能如表 2(b) 所示。 Swin-T 的结果比 DeiT-S 高出 +2.5 box AP 和 +2.3 mask AP，模型大小相似（86M vs 80M），并且推理速度显着更高（15.3 FPS vs. 10.4 FPS）。DeiT 的推理速度较低主要是由于其输入图像大小的二次复杂度。</p>
<p><strong>与之前最先进的模型的比较</strong> 表2© 将我们的最佳结果与之前最先进模型的结果进行了比较。我们的最佳模型在 COCO test-dev 上实现了 58.7 box AP 和 51.1 mask AP，超过了之前的最佳结果+2.7box AP和+2.6 mask AP。</p>
<h3 id="43-ade20k-上的语义分割"><a class="markdownIt-Anchor" href="#43-ade20k-上的语义分割"></a> 4.3. ADE20K 上的语义分割</h3>
<p><strong>设置</strong>：ADE20K是一个广泛使用的语义分割数据集，涵盖了广泛的 150 个语义类别。它总共有 25K 张图像，其中 20K 用于训练，2K 用于验证，另外 3K 用于测试。我们利用 mmseg中的 UperNet作为我们的基础框架，因为它的效率很高。更多详细信息请参阅附录。</p>
<p><strong>结果</strong> 表 3 列出了不同方法/主干对的 mIoU、模型大小 (#param)、FLOP 和 FPS。从这些结果可以看出，在类似的计算成本下，Swin-S 比 DeiT-S 高+5.3 mIoU（49.3 vs. 44.0）。它还比 ResNet-101 高 +4.4 mIoU，比 ResNeSt-101 高 +2.4 mIoU 。我们使用 ImageNet-22K 预训练的 Swin-L 模型在 val 集上达到了 53.5 mIoU，比之前的最佳模型高出 +3.2 mIoU（模型尺寸更大的SETR为 50.3 mIoU）。</p>
<p><img src="194549393.png" alt></p>
<p>表 3. ADE20K 验证集和测试集的语义分割结果。 † 表示使用额外的反卷积层来生成分层特征图。 ‡ 表示模型已在 ImageNet-22K 上进行预训练。</p>
<h3 id="44-消融研究"><a class="markdownIt-Anchor" href="#44-消融研究"></a> 4.4. 消融研究</h3>
<p>在本节中，我们将使用 ImageNet-1K 图像分类、COCO 目标检测上的 Cascade Mask R-CNN 以及 ADE20K 语义分割上的 UperNet 来消除所提出的 Swin Transformer 中的重要设计元素。</p>
<p><img src="183415571.png" alt></p>
<p>表 4. 使用 Swin-T 架构在三个基准上对<strong>移位窗口方法</strong>和<strong>相对位置嵌入方法</strong>进行的消融研究。 <strong>w/o shift</strong>：所有self-attention模块均采用常规窗口划分，无移位；<strong>abs.pos.</strong>：ViT的绝对位置嵌入；<strong>rel.pos.</strong>：带有附加相对位置偏差项的默认设置（参见方程（4））； <strong>app.</strong>：等式中的第一个缩放点积项。 （4）。</p>
<p><strong>移位窗口</strong> 表 4 报告了三个任务中移位窗口方法的消融情况。采用移位窗口的 Swin-T 在每个阶段都优于常规窗口的方法，在 ImageNet-1K 上的 top-1 准确率提高了 1.1% ，COCO 上+2.8 box AP/+2.2 mask AP，ADE20K 上+2.8 mIoU。结果表明了使用移位窗口在前面层中的窗口之间建立连接的有效性。移位窗口的延迟开销也很小，如表 5 所示。</p>
<p><img src="183442002.png" alt></p>
<center>表 5. V100 GPU 上不同自注意力计算方法和实现的实际速度。</center>
<p><strong>相对位置偏差</strong> 表 4 显示了不同位置嵌入方法的比较。具有相对位置偏差的 Swin-T与没有位置编码和绝对位置嵌入的情况相比在 ImageNet-1K上产生了+1.2%/+0.8%的top-1准确率、在 COCO 上获得了+1.3/+1.5 box AP 和 +1.1/+1.3 mask AP 的效果，在 ADE20K上获得了+2.3/+2.9 mIoU的效果，表明相对位置偏差的有效性。<font color="red">另请注意，虽然包含绝对位置嵌入提高了图像分类精度 (+0.4%)，但它损害了对象检测和语义分割（COCO 上为 -0.2 box/mask AP，ADE20K 上为 -0.6 mIoU）。</font></p>
<p><font color="red">虽然最近的 ViT/DeiT 模型放弃了图像分类中的平移不变性，尽管它长期以来被证明对于视觉建模至关重要，但我们发现鼓励某些平移不变性的归纳偏差对于通用视觉建模来说仍然是可取的，特别是对于对象检测和语义分割的密集预测任务。</font></p>
<p><strong>不同的自注意力方法</strong> 不同自注意力计算方法和实现的实际速度在表 5 中进行了比较。我们的<strong>循环实现</strong>比<strong>简单的填充</strong>具有更高的硬件效率，特别是对于更深的阶段。总体而言，它分别为Swin-T、Swin-S和Swin-B带来了13%、18%和18%的加速。</p>
<p>在四个网络阶段中，基于移位窗口方法构建的自注意力模块比朴素/内核实现中的滑动窗口效率高40.8×/2.5×、20.2×/2.5×、9.3×/2.1× 和 7.6×/1.8×。总体而言，基于移位窗口构建的Swin Transformer架构比Swin-T、Swin-S和Swin-B构建于滑动窗口的变体分别快 4.1/1.5、4.0/1.5、3.6/1.5 倍。表 6 比较了它们在这三个任务上的准确性，表明它们在视觉建模方面同样准确。</p>
<p>与最快的 Transformer 架构之一的 Performer相比，所提出的基于移位窗口的自注意力计算和整体 Swin Transformer 架构稍快（参见表 5），同时实现了与使用 Swin-T 的 ImageNet-1K 上的 Performer 相比+2.3% top-1 准确率（参见表 6）。</p>
<p><img src="183526085.png" alt></p>
<center>表 6. Swin Transformer 在三个基准上使用不同方法进行自注意力计算的准确性。</center>
<h2 id="5结论"><a class="markdownIt-Anchor" href="#5结论"></a> 5.结论</h2>
<p>这篇论文提出了 Swin Transformer，这是一种新的愿景 Transformer，它产生一个<strong>分层特征表示</strong>并具有<strong>相对于输入图像大小的线性相关的计算复杂性</strong>。 Swin Transformer 在 COCO 目标检测和 ADE20K 语义分割上实现了最先进的性能，显着超越了之前的最佳方法。我们希望 Swin Transformer 在各种视觉问题上的强大表现将鼓励视觉和语言信号的统一建模。作为 Swin Transformer 的关键要素，基于shifted window的自注意力在视觉问题上被证明是有效且高效的，我们也期待研究其在自然语言处理中的使用。</p>
<h2 id="a1架构细节"><a class="markdownIt-Anchor" href="#a1架构细节"></a> A1.架构细节</h2>
<p>详细的架构规范如表 7 所示，其中所有架构均假设输入图像大小为 224×224。 “Concat n×n”表示patch中n×n相邻特征的串联。此操作会导致特征图按n的速率进行下采样。 “96-d”表示输出维度为96的线性层。“win.sz.7×7” 表示窗口尺寸为7×7的多头自注意力模块。</p>
<p><img src="230212365.png" alt></p>
<center>表 7. 详细架构规范</center>
<h2 id="a2详细的实验设置"><a class="markdownIt-Anchor" href="#a2详细的实验设置"></a> A2.详细的实验设置</h2>
<h3 id="a21-imagenet-1k-上的图像分类"><a class="markdownIt-Anchor" href="#a21-imagenet-1k-上的图像分类"></a> A2.1 ImageNet-1K 上的图像分类</h3>
<p><font color="red">图像分类是通过在最后阶段的输出特征图上应用全局平均池化层，然后接上线性分类器来执行的。</font>我们发现这种策略与使用 ViT和 DeiT中的利用[CLS] token一样准确。在评估中，报告了使用单一裁剪的 top-1 准确度。</p>
<p><strong>常规 ImageNet-1K 训练</strong> 训练设置大多遵循[Training data-efficient image transformers &amp; distillation through attention (<a target="_blank" rel="noopener" href="http://arxiv.org">arxiv.org</a>)](<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2012.12877#:~:text=View">https://arxiv.org/abs/2012.12877#:~:text=View</a> a PDF of the paper titled Training data-efficient image)。对于所有模型变体，我们采用默认的输入图像分辨率为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>22</mn><msup><mn>4</mn><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">224^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">2</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>。<font color="red">对于其他分辨率（例如<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>38</mn><msup><mn>4</mn><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">384^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">8</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>），则在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>22</mn><msup><mn>4</mn><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">224^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">2</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>分辨率下训练的模型进行微调，而不是从头开始训练，以减少GPU消耗。</font></p>
<p>当使用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>22</mn><msup><mn>4</mn><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">224^{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">2</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>的分辨率图像从头开始训练时，我们使用AdamW优化器进行 300 个epochs，使用余弦衰减学习率和 20 个时期的linear warm-up。使用的批量大小为1024，初始学习率为 0.001，权重衰减为 0.05，最大范数为1的梯度裁剪。我们在训练中包含了的大多数增强和正则化策略，包括<strong>RandAugment</strong> 、<strong>Mixup</strong>、<strong>Cutmix</strong>、<strong>随机擦除</strong>和<strong>随机深度</strong>，但没有重复增强和指数移动平均 (EMA) ，因为他们不会提高性能。但是重复增强对于稳定 ViT 训练至关重要。<font color="red">对于较大的模型，采用越来越多的随机深度增强，Swin-T、Swin-S 和 Swin-B 分别为 0.2、0.3、0.5。</font></p>
<p>为了对更高分辨率的输入图像采用微调，我们采用了30个epochss的adamW优化器，学习率为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mtext>−</mtext><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{−5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span>，权重衰减为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mtext>−</mtext><mn>8</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{−8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span>，以及与第一阶段相同的数据增强和正则化，除了将随机深度比设置为 0.1。</p>
<p><strong>ImageNet-22K 预训练</strong> 我们还在更大的 ImageNet-22K 数据集上进行预训练，该数据集包含 1420 万张图像和 22K 类。训练分两个阶段进行。对于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>22</mn><msup><mn>4</mn><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">224^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">2</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>分辨率输入的第一阶段，我们使用 AdamW 优化器进行 90 个epochs，使用线性衰减学习率和 5 个时期的linear warm-up。使用的批量大小为 4096，初始学习率为 0.001，权重衰减为 0.01。在使用 2242/3842 输入进行 ImageNet-1K 微调的第二阶段，我们训练模型 30 个epochs，批量大小为 1024，恒定学习率为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mtext>−</mtext><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{−5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span>，权重衰减为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mtext>−</mtext><mn>8</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{−8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span>。</p>
<h3 id="a22-coco-上的物体检测"><a class="markdownIt-Anchor" href="#a22-coco-上的物体检测"></a> A2.2 COCO 上的物体检测</h3>
<p>对于消融研究，我们在Sparse RCNN方法下考虑四种典型的目标检测框架：Cascade Mask R-CNN、ATSS、RepPoints v2和 mmdetection 。对于这四个框架，我们使用相同的设置：多尺度训练调整输入大小，使短边在 80到800之间，而长边最多 1333）、AdamW优化器（初始学习率为 0.0001，权重衰减为 0.05，批量大小为 16），以及<strong>3x 调度</strong>（36个epochs，学习率在第27和33epoch衰减了10倍）。</p>
<p>对于系统级比较，我们采用改进的 HTC（表示为 HTC++），具有 instaboost、更强的多尺度训练（调整输入大小，使短边在 400 到 1400 之间，而长边在side 最多 1600），6x 调度（72 个 epoch，学习率在 63和69epoch衰减 0.1 倍），softNMS ，以及在最后阶段的输出附加一个额外的全局自注意力层ImageNet-22K 预训练模型作为初始化。我们对所有 Swin Transformer 模型都采用比率为 0.2 的随机深度。</p>
<h3 id="a23-ade20k-上的语义分割"><a class="markdownIt-Anchor" href="#a23-ade20k-上的语义分割"></a> A2.3 ADE20K 上的语义分割</h3>
<p>ADE20K是一个广泛使用的语义分割数据集，涵盖了150个语义类别。它总共有25K张图像，其中20K用于训练，2K 用于验证，另外 3K 用于测试。我们利用 mmsegmentation中的 UperNet作为我们的基础框架，以实现其高效率。在训练中，我们采用 AdamW优化器，初始学习率为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mtext>−</mtext><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">6×10^{−5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">6</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span>，权重衰减为 0.01，使用线性学习率衰减和 1,500 次迭代的linear warm-up。模型在 8个GPU上进行训练，每个 GPU2个图像，进行16万次迭代。对于图像增强，我们采用mmsegmentation 中的默认设置，即随机水平翻转、比率范围 [0.5, 2.0] 内的随机重新缩放和随机光度失真 。所有 Swin Transformer 模型都应用比率为 0.2 的随机深度。 Swin-T、Swin-S 在标准设置上进行训练，与之前的方法一样，输入为 512×512。带‡的Swin-B和Swin-L表示这两个模型是在ImageNet-22K上预训练的，并使用640×640的分辨率图像进行训练。在推论中，采用了训练分辨率的[0.5,0.75,1.0,1.25,1.5,1.75]×分辨率的多尺度测试。在报告测试分数时，按照常见做法，训练图像和验证图像都用于训练。</p>
<h2 id="a3-更多实验"><a class="markdownIt-Anchor" href="#a3-更多实验"></a> A3 更多实验</h2>
<h3 id="a31-不同输入尺寸的图像分类"><a class="markdownIt-Anchor" href="#a31-不同输入尺寸的图像分类"></a> A3.1 不同输入尺寸的图像分类</h3>
<p>表 8 列出了 Swin Transformers 在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>22</mn><msup><mn>4</mn><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">224^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">2</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>38</mn><msup><mn>4</mn><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">384^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">8</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>不同输入图像尺寸下的性能。一般来说，输入分辨率越大，top-1 精度越高，但推理速度越慢。</p>
<p><img src="231908960.png" alt></p>
<center>表 8. ImageNet-1K 分类上具有不同输入图像大小的 Swin Transformer。</center>
<h3 id="a32-coco-上-resnext-的不同优化器"><a class="markdownIt-Anchor" href="#a32-coco-上-resnext-的不同优化器"></a> A3.2 COCO 上 ResNe(X)t 的不同优化器</h3>
<p>表 9 比较了 COCO 目标检测上 ResNe(X)t 主干的 AdamW 和 SGD 优化器。本次比较中使用了 Cascade Mask R-CNN 框架。虽然 SGD 被用作 Cascade Mask R-CNN 框架的默认优化器，但我们通常通过用 AdamW 优化器替换它来观察到准确性的提高，特别是对于较小的主干网。因此，与提出的 Swin Transformer 架构相比，我们使用 AdamW 作为 ResNe(X)t 主干。</p>
<p><img src="232015038.png" alt></p>
<center>表 9. 使用 Cascade Mask R-CNN 框架进行 COCO 对象检测的 ResNet(X)t 主干网的 SDG 和 AdamW 优化器的比较。</center>
<h3 id="a33-swin-mlp-mixer"><a class="markdownIt-Anchor" href="#a33-swin-mlp-mixer"></a> A3.3 Swin MLP-Mixer</h3>
<p>我们将所提出的分层设计和移位窗口方法应用于 MLP-Mixer 架构，称为<strong>Swin-Mixer</strong>。表 10 显示了 Swin-Mixer 与原始 MLPMixer 架构 MLP-Mixer 和后续性能方法ResMLP相比较的结果。使用稍小的计算预算（10.4G 与 12.7G），Swin-Mixer 的性能明显优于 MLP-Mixer（81.3% vs. 76.4%）。与 ResMLP相比，它还具有更好的速度精度权衡。这些结果表明所提出的分层设计和移位窗口方法是可推广的。</p>
<p><img src="232045265.png" alt></p>
<center>表 10. Swin MLP-Mixer 在 ImageNet-1K 分类上的性能。 D 表示每个头的通道数。</center>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">HUI</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/09/23/%E8%AE%BA%E6%96%87/SwinTransformer/">http://example.com/2024/09/23/%E8%AE%BA%E6%96%87/SwinTransformer/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">HUI</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/172840755.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/09/25/%E8%AE%BA%E6%96%87%E4%BB%A3%E7%A0%81/SwinTransformer-code/" title="SwinTransformer代码详解"><img class="cover" src="/img/183711454.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">SwinTransformer代码详解</div></div></a></div><div class="next-post pull-right"><a href="/2024/09/22/huggingface%E8%AF%BE%E7%A8%8B/Diffusion_Course(1)/" title="Diffusion课程（一）- 介绍"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Diffusion课程（一）- 介绍</div></div></a></div></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div class="comment-switch"><span class="first-comment">Valine</span><span id="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/87788970_p0_master1200.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">HUI</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">33</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/kalabiqlx" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:kalabiqlx@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#swin-transformer"><span class="toc-text"> Swin Transformer</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-text"> 摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E4%BB%8B%E7%BB%8D"><span class="toc-text"> 1.介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-text"> 2.相关工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3%E6%96%B9%E6%B3%95"><span class="toc-text"> 3.方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84"><span class="toc-text"> 3.1整体架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32-%E5%9F%BA%E4%BA%8Eshifted-window%E7%9A%84%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-text"> 3.2 基于Shifted Window的自注意力</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#33-%E6%9E%B6%E6%9E%84%E5%8F%98%E9%87%8F"><span class="toc-text"> 3.3 架构变量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4%E5%AE%9E%E9%AA%8C"><span class="toc-text"> 4.实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#41-imagenet-1k-%E4%B8%8A%E7%9A%84%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB"><span class="toc-text"> 4.1. ImageNet-1K 上的图像分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#42-coco%E4%B8%8A%E7%9A%84%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B"><span class="toc-text"> 4.2 COCO上的物体检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#43-ade20k-%E4%B8%8A%E7%9A%84%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2"><span class="toc-text"> 4.3. ADE20K 上的语义分割</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#44-%E6%B6%88%E8%9E%8D%E7%A0%94%E7%A9%B6"><span class="toc-text"> 4.4. 消融研究</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5%E7%BB%93%E8%AE%BA"><span class="toc-text"> 5.结论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#a1%E6%9E%B6%E6%9E%84%E7%BB%86%E8%8A%82"><span class="toc-text"> A1.架构细节</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#a2%E8%AF%A6%E7%BB%86%E7%9A%84%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE"><span class="toc-text"> A2.详细的实验设置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#a21-imagenet-1k-%E4%B8%8A%E7%9A%84%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB"><span class="toc-text"> A2.1 ImageNet-1K 上的图像分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#a22-coco-%E4%B8%8A%E7%9A%84%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B"><span class="toc-text"> A2.2 COCO 上的物体检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#a23-ade20k-%E4%B8%8A%E7%9A%84%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2"><span class="toc-text"> A2.3 ADE20K 上的语义分割</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#a3-%E6%9B%B4%E5%A4%9A%E5%AE%9E%E9%AA%8C"><span class="toc-text"> A3 更多实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#a31-%E4%B8%8D%E5%90%8C%E8%BE%93%E5%85%A5%E5%B0%BA%E5%AF%B8%E7%9A%84%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB"><span class="toc-text"> A3.1 不同输入尺寸的图像分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#a32-coco-%E4%B8%8A-resnext-%E7%9A%84%E4%B8%8D%E5%90%8C%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-text"> A3.2 COCO 上 ResNe(X)t 的不同优化器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#a33-swin-mlp-mixer"><span class="toc-text"> A3.3 Swin MLP-Mixer</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/10/08/huggingface%E8%AF%BE%E7%A8%8B/Audio_Course(5.1)/" title="Audio课程（五）- 自动语音识别(ASR)"><img src="/img/43670b.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Audio课程（五）- 自动语音识别(ASR)"/></a><div class="content"><a class="title" href="/2024/10/08/huggingface%E8%AF%BE%E7%A8%8B/Audio_Course(5.1)/" title="Audio课程（五）- 自动语音识别(ASR)">Audio课程（五）- 自动语音识别(ASR)</a><time datetime="2024-10-08T14:50:33.000Z" title="发表于 2024-10-08 22:50:33">2024-10-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/08/huggingface%E8%AF%BE%E7%A8%8B/Audio_Course(4)/" title="Audio课程（四）- 构建音频流派分类器"><img src="/img/43670b.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Audio课程（四）- 构建音频流派分类器"/></a><div class="content"><a class="title" href="/2024/10/08/huggingface%E8%AF%BE%E7%A8%8B/Audio_Course(4)/" title="Audio课程（四）- 构建音频流派分类器">Audio课程（四）- 构建音频流派分类器</a><time datetime="2024-10-08T14:47:33.000Z" title="发表于 2024-10-08 22:47:33">2024-10-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/08/huggingface%E8%AF%BE%E7%A8%8B/Audio_Course(3)/" title="Audio课程（三）- 音频Transformer架构"><img src="/img/43670b.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Audio课程（三）- 音频Transformer架构"/></a><div class="content"><a class="title" href="/2024/10/08/huggingface%E8%AF%BE%E7%A8%8B/Audio_Course(3)/" title="Audio课程（三）- 音频Transformer架构">Audio课程（三）- 音频Transformer架构</a><time datetime="2024-10-08T14:39:33.000Z" title="发表于 2024-10-08 22:39:33">2024-10-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/08/huggingface%E8%AF%BE%E7%A8%8B/Audio_Course(2)/" title="Audio课程（二）- 音频应用的入门介绍"><img src="/img/43670b.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Audio课程（二）- 音频应用的入门介绍"/></a><div class="content"><a class="title" href="/2024/10/08/huggingface%E8%AF%BE%E7%A8%8B/Audio_Course(2)/" title="Audio课程（二）- 音频应用的入门介绍">Audio课程（二）- 音频应用的入门介绍</a><time datetime="2024-10-08T14:38:33.000Z" title="发表于 2024-10-08 22:38:33">2024-10-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/08/huggingface%E8%AF%BE%E7%A8%8B/Audio_Course(1)/" title="Audio课程（一）- 音频数据处理"><img src="/img/43670b.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Audio课程（一）- 音频数据处理"/></a><div class="content"><a class="title" href="/2024/10/08/huggingface%E8%AF%BE%E7%A8%8B/Audio_Course(1)/" title="Audio课程（一）- 音频数据处理">Audio课程（一）- 音频数据处理</a><time datetime="2024-10-08T14:30:33.000Z" title="发表于 2024-10-08 22:30:33">2024-10-08</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/172840755.png')"><div id="footer-wrap"><div class="copyright">&copy;2024 By HUI</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat-btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.jsdelivr.net/npm/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script><script>(() => {
  const disqus_config = function () {
    this.page.url = 'http://example.com/2024/09/23/%E8%AE%BA%E6%96%87/SwinTransformer/'
    this.page.identifier = '/2024/09/23/%E8%AE%BA%E6%96%87/SwinTransformer/'
    this.page.title = 'SwinTransformer论文精读'
  }

  const disqusReset = () => {
    window.DISQUS && window.DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  btf.addGlobalFn('themeChange', disqusReset, 'disqus')

  const loadDisqus = () =>{
    if (window.DISQUS) disqusReset()
    else {
      const script = document.createElement('script')
      script.src = 'https://.disqus.com/embed.js'
      script.setAttribute('data-timestamp', +new Date())
      document.head.appendChild(script)
    }
  }

  const getCount = async() => {
    try {
      const eleGroup = document.querySelector('#post-meta .disqus-comment-count')
      if (!eleGroup) return
      const cleanedLinks = eleGroup.href.replace(/#post-comment$/, '')

      const res = await fetch(`https://disqus.com/api/3.0/threads/set.json?forum=&api_key=&thread:link=${cleanedLinks}`,{
        method: 'GET'
      })
      const result = await res.json()

      const count = result.response.length ? result.response[0].posts : 0
      eleGroup.textContent = count
    } catch (err) {
      console.error(err)
    }
  }

  if ('Valine' === 'Disqus' || !false) {
    if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
    else {
      loadDisqus()
      GLOBAL_CONFIG_SITE.isPost && getCount()
    }
  } else {
    window.loadOtherComment = loadDisqus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>